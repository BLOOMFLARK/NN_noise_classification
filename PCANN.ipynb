{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from sklearn.decomposition import PCA, IncrementalPCA\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torchvision import transforms, models\n",
    "\n",
    "\n",
    "class PCANet(torch.nn.Module):\n",
    "    def __init__(self, num_filters: list, filters_sizes: list, batch_size=256):\n",
    "        self.params = {\n",
    "            'num_filters': num_filters,\n",
    "            'filters_sizes': filters_sizes,\n",
    "        }\n",
    "        self.W_1 = None\n",
    "        self.W_2 = None\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.conv2d(x, self.W_1)\n",
    "        N, C, H, W = x.shape\n",
    "        x = x.view(-1, 1, H, W)\n",
    "        \n",
    "        x = F.conv2d(x, self.W_2)\n",
    "        N, C, H, W = x.shape\n",
    "        x = x.view(N*C, H, W)\n",
    "        \n",
    "        x_flat = x.view(N*C, H*W)\n",
    "        print(\"N = {}, C = {}, H = {}, W = {}\".format(N, C, H, W), x_flat.shape)\n",
    "        x_flat = torch.nn.Linear(H*W, 2, bias=True)(x_flat)\n",
    "        return x_flat\n",
    "            \n",
    "    @staticmethod        \n",
    "    def _extract_image_patches(imgs: torch.Tensor, filter_size, stride=1, remove_mean=True):\n",
    "        # imgs.shape = (N, C, H, W) -> (N, 1, H, W) \n",
    "        # так должно быть, но сюда могут прийти не grayscale изображения первого шага, а со второго\n",
    "        # на котором применено L1 фильтров -> L1 каналов\n",
    "        N, n_channels, H, W = imgs.shape\n",
    "        \n",
    "        if n_channels > 1:\n",
    "            # изображение вида (N, C, H, W) - N C-канальных изображений\n",
    "            # приводим к виду (N*C, 1, H, W) - N*C одно-канальных изображений\n",
    "            imgs = imgs.view(-1, 1, H, W)\n",
    "        print('images shape', imgs.shape)\n",
    "            \n",
    "        k = filter_size\n",
    "        patches = torch.nn.functional.unfold(imgs, k, padding=k//2) # (N, k^2, H*W)\n",
    "        print('patches_shape, ', patches.shape)\n",
    "        print('should be patches shape, ', (imgs.shape[0], k**2, H*W))\n",
    "        \n",
    "        if remove_mean:\n",
    "            patches -= patches.mean(dim=1, keepdim=True) # последнее измерение - количество патчей\n",
    "        \n",
    "        print('filter_size', k)\n",
    "        X = patches.view(k**2, -1) # (k^2, N*H*W)\n",
    "\n",
    "        return X\n",
    "    \n",
    "    def _convolve(self, imgs: torch.Tensor, filter_bank: torch.Tensor) -> torch.Tensor:\n",
    "        weight = filter_bank\n",
    "        output = F.conv2d(imgs, weight) #, padding=padding)\n",
    "        return output\n",
    "    \n",
    "    def _first_stage(self, imgs: torch.Tensor, train: bool) -> torch.Tensor:\n",
    "        # (N, C, H, W) image\n",
    "        # (train_size, 1, H, W) - grayscale\n",
    "        assert imgs.dim() == 4 and imgs.nelement() > 0\n",
    "\n",
    "        print('PCANet first stage...')\n",
    "\n",
    "        if train:\n",
    "            # достаем все патчи из всех N изображений\n",
    "            filter_size1 = self.params['filters_sizes'][0]\n",
    "            X = self._extract_image_patches(\n",
    "                imgs, filter_size1)\n",
    "            \n",
    "            n_filters = self.params['num_filters'][0]\n",
    "            \n",
    "            eigenvectors = self.get_pca_eigenvectors(X, n_components=n_filters, batch_size=self.batch_size)\n",
    "            self.W_1 = torch.FloatTensor(eigenvectors).view(n_filters, 1, filter_size1, filter_size1)\n",
    "         \n",
    "        I = self._convolve(imgs, self.W_1)  # (N, 1, H, W) * (L1, k1, k1) -> (N, L1, H', W')\n",
    "        return I\n",
    "    \n",
    "    @staticmethod\n",
    "    def conv_output_size(w, filter_size, padding=0, stride=1):\n",
    "        return int((w - filter_size + 2 * padding) / stride + 1)\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_pca_eigenvectors(X, n_components, batch_size=100):\n",
    "        ipca = IncrementalPCA(n_components=n_components, batch_size=batch_size)\n",
    "        print('pca fitting ...')\n",
    "        ipca.fit(X @ X.t())\n",
    "        eigenvectors = ipca.components_\n",
    "        print('eigenvectors shape:', eigenvectors.shape)\n",
    "        return eigenvectors\n",
    "        \n",
    "    def _second_stage(self, I: torch.Tensor, train):\n",
    "        print('PCANet second stage...')\n",
    "        # I: (N, L1, H, W)\n",
    "        if train:\n",
    "            N, L1, H, W = I.shape\n",
    "            I = I.view(-1, 1, H, W)\n",
    "            filter_size2 = self.params['filters_sizes'][1]\n",
    "            n_filters = self.params['num_filters'][1]\n",
    "            \n",
    "            H_new = self.conv_output_size(I.shape[2], filter_size2)\n",
    "            W_new = self.conv_output_size(I.shape[3], filter_size2)\n",
    "            \n",
    "            X = self._extract_image_patches(I, filter_size2)\n",
    "            print('X_SHAPE ', X.shape)\n",
    "            eigenvectors = self.get_pca_eigenvectors(X, n_components=n_filters, batch_size=self.batch_size)\n",
    "            self.W_2 = torch.FloatTensor(eigenvectors).view(n_filters, 1, filter_size2, filter_size2)\n",
    "        return self._convolve(I, self.W_2)\n",
    "    \n",
    "    def run(self, images):\n",
    "        # Создаем фильтры\n",
    "        # images: (N, 1, H, W)\n",
    "        I = self._first_stage(images, train=True)\n",
    "        II = self._second_stage(I, train=True)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num_filters': [8, 8], 'filters_sizes': [5, 3]}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = PCANet([8, 8],[5, 3])\n",
    "net.params\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "net = net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1234\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "num_epochs = 100\n",
    "batch_size = 50\n",
    "lr = 1e-3\n",
    "\n",
    "loss = torch.nn.CrossEntropyLoss()\n",
    "#optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((64, 64)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_transforms = transforms.Compose([\n",
    "    transforms.Resize((64, 64)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "train_dataset = torchvision.datasets.ImageFolder(train_dir, train_transforms)\n",
    "val_dataset = torchvision.datasets.ImageFolder(val_dir, val_transforms)\n",
    "\n",
    "all_train = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=train_size, shuffle=False, num_workers=batch_size)\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=batch_size, shuffle=True, num_workers=batch_size)\n",
    "\n",
    "val_dataloader = torch.utils.data.DataLoader(\n",
    "    val_dataset, batch_size=batch_size, shuffle=False, num_workers=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss = np.zeros(num_epochs)\n",
    "train_loss = np.zeros(num_epochs)\n",
    "\n",
    "val_acc = np.zeros(num_epochs)\n",
    "train_acc = np.zeros(num_epochs)\n",
    "\n",
    "\n",
    "def train_model(model, loss, optimizer, scheduler, num_epochs):\n",
    "    best_val_loss = np.inf\n",
    "    best_train_loss = np.inf\n",
    "    best_val_model = {}\n",
    "    best_train_model = {}\n",
    "    \n",
    "    model.run(train_all_dataloader)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        print('Epoch {}/{}:'.format(epoch, num_epochs - 1), flush=True)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                dataloader = train_dataloader\n",
    "                scheduler.step()\n",
    "                model.train()  # training mode\n",
    "                history_acc = train_acc\n",
    "                history_loss = train_loss\n",
    "            else:\n",
    "                dataloader = val_dataloader\n",
    "                model.eval()   # evaluate mode (dropout + bn)\n",
    "                history_acc = val_acc\n",
    "                history_loss = val_loss\n",
    "\n",
    "            running_loss = 0.\n",
    "            running_acc = 0.\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloader:\n",
    "                #print(inputs, labels)\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward and backward\n",
    "                with torch.set_grad_enabled(phase=='train'):\n",
    "                    preds = model(inputs)\n",
    "                    loss_value = loss(preds, labels)\n",
    "                    preds_class = preds.argmax(dim=1)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss_value.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss_value.cpu().item()\n",
    "                running_acc += (preds_class.cpu() == labels.cpu().data).float().mean()\n",
    "            \n",
    "            epoch_loss = running_loss / len(dataloader)\n",
    "            epoch_acc = running_acc / len(dataloader)\n",
    "            history_acc[epoch] = epoch_acc\n",
    "            history_loss[epoch] = epoch_loss\n",
    "\n",
    "            # запоминаем модель по лоссу\n",
    "            if phase == 'val' and best_val_loss > epoch_loss:\n",
    "                best_val_model = model.state_dict()\n",
    "                best_val_loss = epoch_loss\n",
    "            if phase == 'train' and best_train_loss > epoch_loss:\n",
    "                best_train_model = model.state_dict()\n",
    "                best_train_loss = epoch_loss\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}\\n best: {}'.format(phase, epoch_loss, epoch_acc, best_val_loss), flush=True)\n",
    "    result_dict = {'best_val_model': best_val_model,\n",
    "                   'best_train_model': best_train_model}\n",
    "    return result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dict = train_model(model, loss, optimizer, scheduler, num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss\n",
    "plt.plot(num_epochs, train_loss, val_loss)\n",
    "plt.legend(['train', 'val'])\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('cross entropy loss')\n",
    "plt.title('loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy\n",
    "plt.plot(num_epochs, train_acc, val_acc)\n",
    "plt.legend(['train', 'val'])\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('cross entropy loss')\n",
    "plt.title('accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = torch.randn(10, 1, 10, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCANet first stage...\n",
      "images shape torch.Size([10, 1, 10, 10])\n",
      "patches_shape,  torch.Size([10, 25, 100])\n",
      "should be patches shape,  (10, 25, 100)\n",
      "filter_size 5\n",
      "pca fitting ...\n",
      "eigenvectors shape: (8, 25)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 8, 6, 6])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "I = net._first_stage(imgs=imgs, train=True)\n",
    "I.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCANet second stage...\n",
      "images shape torch.Size([80, 1, 6, 6])\n",
      "patches_shape,  torch.Size([80, 9, 36])\n",
      "should be patches shape,  (80, 9, 36)\n",
      "filter_size 3\n",
      "X_SHAPE  torch.Size([9, 2880])\n",
      "pca fitting ...\n",
      "eigenvectors shape: (8, 9)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([80, 8, 4, 4])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net._second_stage(I, train=True).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N = 80, C = 8, H = 4, W = 4 torch.Size([640, 16])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-0.7040,  0.3876],\n",
       "        [ 0.5826,  1.0300],\n",
       "        [ 0.2970,  0.7326],\n",
       "        ...,\n",
       "        [ 0.5815, -0.1781],\n",
       "        [-0.7312,  1.2732],\n",
       "        [-1.1729,  0.5596]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.forward(imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
