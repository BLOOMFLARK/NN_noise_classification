{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "PCANN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BLOOMFLARK/NN_noise_classification/blob/master/PCANN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8az9TUBPNn3",
        "colab_type": "code",
        "outputId": "5e88e8db-94a2-4788-866c-ceb697df6bff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 189
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ytS5Jr-kE3H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn.functional as F\n",
        "from sklearn.decomposition import PCA, IncrementalPCA\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "from torchvision import transforms, models, datasets\n",
        "\n",
        "import random"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7sEWez9FeqEM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "SEED = 1234\n",
        "\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZOKuZLzPKT1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class PCANet(torch.nn.Module):\n",
        "    def __init__(self, num_filters: list, filters_sizes: list, batch_size=256):\n",
        "        super(PCANet, self).__init__()\n",
        "        self.params = {\n",
        "            'num_filters': num_filters,\n",
        "            'filters_sizes': filters_sizes,\n",
        "        }\n",
        "        self.W_1 = None\n",
        "        self.pool1 = torch.nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.act1 = torch.nn.ReLU()\n",
        "        self.W_2 = None\n",
        "        # self.pool2 = torch.nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.fc = torch.nn.Linear(968, 2, bias=True)\n",
        "        #self.fc = torch.nn.Linear(30250, 2, bias=True)\n",
        "        # self.fc2 = torch.nn.Linear(100, 2, bias=True)\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.conv2d(x, self.W_1)\n",
        "        x = self.act1(x)\n",
        "        x = self.pool1(x)\n",
        "        N1, C1, H1, W1 = x.shape\n",
        "\n",
        "        x = F.conv2d(x, self.W_2)\n",
        "        x = self.act1(x)\n",
        "        x = self.pool1(x)\n",
        "        N, C, H, W = x.shape\n",
        "\n",
        "        x_flat = x.view(N, C * H * W)\n",
        "\n",
        "        x_flat = self.fc(x_flat)\n",
        "        # x_flat = self.act1(x_flat)\n",
        "        # x_flat = self.fc2(x_flat)\n",
        "        return x_flat\n",
        "            \n",
        "    @staticmethod        \n",
        "    def _extract_image_patches(imgs: torch.Tensor, filter_size, stride=1, remove_mean=True):\n",
        "        # imgs.shape = (N, C, H, W) -> (N, 1, H, W) \n",
        "        # так должно быть, но сюда могут прийти не grayscale изображения первого шага, а со второго\n",
        "        # на котором применено L1 фильтров -> L1 каналов\n",
        "        N, n_channels, H, W = imgs.shape\n",
        "        stride=1\n",
        "        \n",
        "        if n_channels > 1:\n",
        "            # изображение вида (N, C, H, W) - N C-канальных изображений\n",
        "            # приводим к виду (N*C, 1, H, W) - N*C одно-канальных изображений\n",
        "            imgs = imgs.view(-1, 1, H, W)\n",
        "        print('images shape', imgs.shape)\n",
        "            \n",
        "        k = filter_size\n",
        "        pad = tuple([k // 2 for i in range(4)]) # (k//2 , k//2, k//2, k//2)\n",
        "        imgs_padded = torch.nn.functional.pad(imgs, pad=pad, mode='constant', value=0)\n",
        "\n",
        "        patches = (imgs_padded.unfold(1 + 1, k, stride).unfold(1 + 2, k, stride)) # (N, C, H, W, k, k)\n",
        "        patches = patches.flatten(1 + 1, 1 + 2).flatten(-2) # (N, 1, H*W, k^2)\n",
        "        patches = patches.squeeze(1) # (N, H*W, k^2)\n",
        "\n",
        "        print('patches_shape, ', patches.shape)\n",
        "        print('should be patches shape, ', (imgs.shape[0], H*W, k**2))\n",
        "        \n",
        "        if remove_mean:\n",
        "            patches -= patches.mean(dim=2, keepdim=True) # последнее измерение - патч\n",
        "        \n",
        "        print('filter_size', k)\n",
        "        X = patches.view(-1, k**2) # (N*H*W, k^2)\n",
        "\n",
        "        return X.permute(1, 0) # (k^2, N*H*W)\n",
        "\n",
        "    \n",
        "    def _convolve(self, imgs: torch.Tensor, filter_bank: torch.Tensor) -> torch.Tensor:\n",
        "        weight = filter_bank\n",
        "        output = F.conv2d(imgs, weight, padding=1)\n",
        "        return output\n",
        "    \n",
        "    def _first_stage(self, imgs: torch.Tensor, train: bool) -> torch.Tensor:\n",
        "        # (N, C, H, W) image\n",
        "        # (train_size, 1, H, W) - grayscale\n",
        "        assert imgs.dim() == 4 and imgs.nelement() > 0\n",
        "\n",
        "        print('PCANet first stage...')\n",
        "\n",
        "        if train:\n",
        "            # достаем все патчи из всех N изображений\n",
        "            filter_size1 = self.params['filters_sizes'][0]\n",
        "            X = self._extract_image_patches(\n",
        "                imgs, filter_size1)\n",
        "            \n",
        "            n_filters = self.params['num_filters'][0]\n",
        "            \n",
        "            eigenvectors = self.get_pca_eigenvectors(X, n_components=n_filters, batch_size=self.batch_size)\n",
        "            self.W_1 = torch.FloatTensor(eigenvectors).view(n_filters, 1, filter_size1, filter_size1)\n",
        "         \n",
        "        I = self._convolve(imgs, self.W_1)  # (N, 1, H, W) * (L1, k1, k1) -> (N, L1, H', W')\n",
        "        return I\n",
        "    \n",
        "    @staticmethod\n",
        "    def conv_output_size(w, filter_size, padding=1, stride=1):\n",
        "        return int((w - filter_size + 2 * padding) / stride + 1)\n",
        "    \n",
        "    @staticmethod\n",
        "    def get_pca_eigenvectors(X, n_components, batch_size=100):\n",
        "        ipca = IncrementalPCA(n_components=n_components, batch_size=batch_size)\n",
        "        print('pca fitting ...')\n",
        "        ipca.fit(X @ X.t())\n",
        "        eigenvectors = ipca.components_\n",
        "        print('eigenvectors shape:', eigenvectors.shape)\n",
        "        return eigenvectors\n",
        "        \n",
        "    def _second_stage(self, I: torch.Tensor, train):\n",
        "        print('PCANet second stage...')\n",
        "        # I: (N, L1, H, W)\n",
        "        if train:\n",
        "            N, L1, H, W = I.shape\n",
        "            filter_size2 = self.params['filters_sizes'][1]\n",
        "            n_filters2 = self.params['num_filters'][1]\n",
        "            n_filters1 = self.params['num_filters'][0]\n",
        "            \n",
        "            H_new = self.conv_output_size(I.shape[2], filter_size2)\n",
        "            W_new = self.conv_output_size(I.shape[3], filter_size2)\n",
        "            \n",
        "            X = self._extract_image_patches(I, filter_size2)\n",
        "\n",
        "            print('X_SHAPE ', X.shape)\n",
        "            print(H_new, W_new)\n",
        "\n",
        "            eigenvectors = self.get_pca_eigenvectors(X, n_components=n_filters2, batch_size=self.batch_size)\n",
        "            \n",
        "            W_2 = torch.FloatTensor(eigenvectors).view(n_filters2, 1, filter_size2, filter_size2) # (L2, 1, k2, k2)\n",
        "            self.W_2 = W_2.repeat(1, n_filters1, 1, 1) # (L2, L1, k2, k2) - повторяет L1 раз для конкретного l из L2\n",
        "\n",
        "        return self._convolve(I, self.W_2)\n",
        "    \n",
        "    def binarize(self, X):\n",
        "        X[X > 0] = 1\n",
        "        X[X <= 0] = 0\n",
        "        return X\n",
        "    \n",
        "    def binary_to_dec(self, bin_II):\n",
        "        N, L1, H, W = bin_II.shape\n",
        "        print(f\"bin_II shape: {bin_II.shape}\")\n",
        "        assert L1 == self.params['num_filters'][0]\n",
        "        power_series = torch.arange(0, L1).float()\n",
        "        power_series = torch.pow(2, power_series)\n",
        "        power_series = power_series.view(1, L1, 1, 1)\n",
        "        power_series = power_series.repeat(N, 1, 1, 1)\n",
        "        decimal_images = torch.sum(bin_II * power_series, dim=1) # (N, L1, H, W) -> (N, H, W)\n",
        "        decimal_images = decimal_images.view(N, 1, H, W)\n",
        "        return decimal_images\n",
        "    \n",
        "    def get_histograms(self, dec_II):\n",
        "        # dec_II: (N, 1, H, W)\n",
        "        print(f\"dec_II shape: {dec_II.shape}\")\n",
        "        L2 = self.params['num_filters'][1]\n",
        "        N, _, H, W = dec_II.shape\n",
        "        b_size_h = H // 2 \n",
        "        b_size_w = W // 2\n",
        "        #blocks_shape: torch.Size([1200, 1, 2, 2, 28, 28])\n",
        "        #features: torch.Size([512])\n",
        "        step_h = H // 2 # stride h\n",
        "        step_w = W // 2 # stride w\n",
        "\n",
        "        blocks = dec_II.unfold(2, b_size_h, step_h).unfold(3, b_size_w, step_w) # (N, 1, n_blocks, b_size_h, b_size_w)\n",
        "        print(f\"blocks_shape: {blocks.shape}\")\n",
        "        N, _, n_blocks = blocks.shape[0:3]\n",
        "        blocks = blocks.flatten(2, 3).squeeze(1).view(N, n_blocks, -1) # (N, n_blocks, b_size_h * b_size_w)\n",
        "\n",
        "        final_features = torch.tensor([])\n",
        "        for i in range(N):\n",
        "            features = torch.tensor([])\n",
        "            for n_box in range(n_blocks):\n",
        "                feature_histogram = torch.histc(blocks[i, n_box], bins=2**L2)\n",
        "                features = torch.cat((features, feature_histogram), dim=0)\n",
        "            features = features.unsqueeze(0)\n",
        "            final_features  = torch.cat((final_features, features), dim=0)\n",
        "\n",
        "        print(f\"final_features: {final_features.shape}\")\n",
        "        return final_features\n",
        "\n",
        "\n",
        "    def get_features(self, images, to_fit=True):\n",
        "\n",
        "        # Images на втором этапе\n",
        "        II = self.run(images, to_fit) # (N, L1, H, W)\n",
        "        # Бинаризуем изображение\n",
        "        bin_II = self.binarize(II)\n",
        "        # (N, L1, H, W) -> (N, 1, H, W), перевод в десятичное число\n",
        "        dec_II = self.binary_to_dec(bin_II) # (N, 1, H, W)\n",
        "\n",
        "        features = self.get_histograms(dec_II)\n",
        "\n",
        "        return features\n",
        "    \n",
        "    def train_with_hist(self, train_data, val_data):\n",
        "        from sklearn.svm import LinearSVC, SVC\n",
        "        from sklearn.ensemble import RandomForestClassifier\n",
        "        from sklearn.metrics import roc_auc_score, accuracy_score, precision_score, recall_score\n",
        "\n",
        "        X_train, y_train = train_data\n",
        "        train_features = self.get_features(X_train).cpu().numpy()\n",
        "        classifier = RandomForestClassifier(n_estimators=70)\n",
        "\n",
        "        print(\"Training classifier\")\n",
        "        classifier.fit(train_features, y_train)\n",
        "        \n",
        "        print(\"------------========== TRAIN =========--------------\")\n",
        "        y_pred = classifier.predict(train_features)\n",
        "        acc = accuracy_score(y_train, y_pred)\n",
        "        roc_auc = roc_auc_score(y_train, y_pred)\n",
        "        prec = precision_score(y_train, y_pred)\n",
        "        rec = recall_score(y_train, y_pred)\n",
        "        print(f\"Accuracy: {acc}\\nROC-AUC: {roc_auc}\\nPrecision: {prec}\\nRecall: {rec}\")\n",
        "        print(\"------------=======================--------------\")\n",
        "\n",
        "        X_test, y_test = val_data\n",
        "        test_features = self.get_features(X_test, to_fit=False).cpu().numpy()\n",
        "\n",
        "        print(\"------------========== TEST =========--------------\")\n",
        "        y_pred = classifier.predict(test_features)\n",
        "        acc = accuracy_score(y_test, y_pred)\n",
        "        roc_auc = roc_auc_score(y_test, y_pred)\n",
        "        prec = precision_score(y_test, y_pred)\n",
        "        rec = recall_score(y_test, y_pred)\n",
        "        print(f\"Accuracy: {acc}\\nROC-AUC: {roc_auc}\\nPrecision: {prec}\\nRecall: {rec}\")\n",
        "\n",
        "    def run(self, images, to_fit=True):\n",
        "        # Создаем фильтры\n",
        "        # images: (N, 1, H, W)\n",
        "        I = self._first_stage(images, train=to_fit)\n",
        "        print(\"I \", I.shape)\n",
        "        II = self._second_stage(I, train=to_fit)\n",
        "        return II\n",
        "\n",
        "    def fit(self, loss, optimizer, device, train_data, test_data, num_epochs=100):\n",
        "        self.val_loss = np.zeros(num_epochs)\n",
        "        self.train_loss = np.zeros(num_epochs)\n",
        "\n",
        "        self.val_acc = np.zeros(num_epochs)\n",
        "        self.train_acc = np.zeros(num_epochs)\n",
        "\n",
        "        if self.W_1 is None or self.W_2 is None:\n",
        "            self.run(train_data[0])\n",
        "        \n",
        "        self.W_1 = self.W_1.to(device)\n",
        "        self.W_2 = self.W_2.to(device)\n",
        "\n",
        "        for epoch in range(num_epochs):\n",
        "            print('Epoch {}/{}:'.format(epoch, num_epochs - 1), flush=True)\n",
        "\n",
        "            # Each epoch has a training and validation phase\n",
        "            for phase in ['train', 'val']:\n",
        "                if phase == 'train':\n",
        "                    #data = train_data\n",
        "                    data = train_data\n",
        "                    self.train()  # training mode\n",
        "                    history_acc = self.train_acc\n",
        "                    history_loss = self.train_loss\n",
        "                else:\n",
        "                    #data = test_data\n",
        "                    data = test_data\n",
        "                    self.eval()   # evaluate mode (dropout + bn)\n",
        "                    history_acc = self.val_acc\n",
        "                    history_loss = self.val_loss\n",
        "\n",
        "                running_loss = 0.\n",
        "                running_acc = 0.\n",
        "\n",
        "                # Iterate over data.\n",
        "                inputs, labels = data\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward and backward\n",
        "                with torch.set_grad_enabled(phase=='train'):\n",
        "                    preds = self(inputs)\n",
        "                    loss_value = loss(preds, labels)\n",
        "                    preds_class = preds.argmax(dim=1)\n",
        "\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss_value.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # statistics\n",
        "                running_loss += loss_value.cpu().item()\n",
        "                running_acc += (preds_class.cpu() == labels.cpu().data).float().mean()\n",
        "            \n",
        "                epoch_loss = running_loss\n",
        "                epoch_acc = running_acc\n",
        "                history_acc[epoch] = epoch_acc\n",
        "                history_loss[epoch] = epoch_loss\n",
        "\n",
        "                # запоминаем модель по лоссу\n",
        "\n",
        "                print('{} Loss: {:.4f} Acc: {:.4f}\\n'.format(phase, epoch_loss, epoch_acc), flush=True)\n",
        "    \n",
        "    def plot_loss(self):\n",
        "        num_epochs = self.train_loss.shape[0]\n",
        "        # Loss\n",
        "        plt.plot(range(num_epochs), self.train_loss, self.val_loss)\n",
        "        plt.legend(['train', 'val'])\n",
        "        plt.xlabel('epoch')\n",
        "        plt.ylabel('cross entropy loss')\n",
        "        plt.title('loss')\n",
        "\n",
        "    def plot_acc(self):\n",
        "        num_epochs = self.train_acc.shape[0]\n",
        "        # Loss\n",
        "        plt.plot(range(num_epochs), self.train_acc, self.val_acc)\n",
        "        plt.legend(['train', 'val'])\n",
        "        plt.xlabel('epoch')\n",
        "        plt.ylabel('accuracy')\n",
        "        plt.title('accuracy')\n",
        "        \n",
        "        \n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-LOy9ObSRBc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "40fa1c7e-f0e1-43e6-b04d-9a60c768991a"
      },
      "source": [
        "net = PCANet([8, 8], [7, 7])\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "net = net.to(device)"
      ],
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQspJTNDEZPM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 150\n",
        "lr = 1e-3\n",
        "\n",
        "loss = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
        "#optimizer = torch.optim.SGD(net.parameters(), lr=lr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A6otLLXYXbuF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MNIST_train = datasets.MNIST('sample_data', train=True, transform=None, target_transform=None, download=True)\n",
        "MNIST_test = datasets.MNIST('sample_data', train=False, transform=None, target_transform=None, download=True)\n",
        "\n",
        "X_train = MNIST_train.data[:11000, :, :]\n",
        "y_train = MNIST_train.targets[:11000]\n",
        "X_test = MNIST_test.data[:1650, :, :]\n",
        "y_test = MNIST_test.targets[:1650]\n",
        "\n",
        "X_train = X_train.unsqueeze(1).float() # (11000, 1, 28, 28)\n",
        "X_test = X_test.unsqueeze(1).float() # (1650, 1, 28, 28)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PlbCWEHGgmOg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "net.fit(loss,\n",
        "        optimizer,\n",
        "        device,\n",
        "        train_data=(X_train, y_train),\n",
        "        test_data=(X_test, y_test),\n",
        "        num_epochs=500)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FPsdw5ttiKRU",
        "colab_type": "code",
        "outputId": "463709cc-111d-4721-c5a4-81671b74f19f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "net.plot_loss()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nOzdd3hUVfrA8e+bTjohCQFCb1IElCAggiL2Aq4NbNssa2/rWnbXsuruz1V3Lauo6GJZFdeyNgRRlKIISO+9BEJLD+ltzu+PM8lMkkkYIJNJeT/PM8/cuffOnRNl5r2nvUeMMSillGq7AvxdAKWUUv6lgUAppdo4DQRKKdXGaSBQSqk2TgOBUkq1cRoIlFKqjdNAoNQRiMhuETnL3+VQylc0ECilVBungUAppdo4DQRKeUlEQkXkeRHZ73w8LyKhzmPxIjJTRHJFJFtEfhCRAOexB0Rkn4jki8gWEZng379EqZqC/F0ApVqQPwGjgGGAAT4H/gw8DPweSAMSnOeOAoyI9AduB0YYY/aLSA8gsGmLrVTDtEaglPeuAR43xqQbYzKAvwDXOY+VA52A7saYcmPMD8Ym8qoEQoGBIhJsjNltjNnhl9IrVQ8NBEp5rzOQ6vY61bkP4BlgO/CNiOwUkQcBjDHbgbuBx4B0EflARDqjVDOigUAp7+0Huru97ubchzEm3xjze2NML2AicG9VX4Ax5n1jzGnO9xrg701bbKUapoFAKe/NAP4sIgkiEg88ArwLICIXiUgfEREgD9sk5BCR/iJyprNTuQQoBhx+Kr9SHmkgUMp7TwLLgbXAOmClcx9AX2AuUAAsBqYaY+Zh+weeAjKBg0Ai8FDTFluphokuTKOUUm2b1giUUqqN00CglFJtnAYCpZRq4zQQKKVUG9fiUkzEx8ebHj16+LsYSinVoqxYsSLTGJPg6ViLCwQ9evRg+fLl/i6GUkq1KCKSWt8xbRpSSqk2TgOBUkq1cRoIlFKqjWtxfQRKKXUsysvLSUtLo6SkxN9F8amwsDCSk5MJDg72+j0aCJRSbUJaWhpRUVH06NEDmxuw9THGkJWVRVpaGj179vT6fT5rGhKRriIyT0Q2isgGEbnLwzkiIi+KyHYRWSsiJ/uqPEqptq2kpIQOHTq02iAAICJ06NDhqGs9vqwRVAC/N8asFJEoYIWIfGuM2eh2zvnYrI19gZHAK85npZRqdK05CFQ5lr/RZzUCY8wBY8xK53Y+sAnoUuu0ScA7xloCxIpIJ1+VSTUTeftg6xx/l0Ip5dQko4acC3afBCytdagLsNftdRp1g4VqbV4/E96/0t+lUKpJ5ebmMnXq1KN+3wUXXEBubq4PSuTi80AgIpHAJ8DdxpjDx3iNm0RkuYgsz8jIaNwCqqZXcNDfJVCqydUXCCoqKhp836xZs4iNjfVVsQAfBwIRCcYGgfeMMf/zcMo+oKvb62TnvhqMMdOMMSnGmJSEBI+pMlRLpIsiqTbkwQcfZMeOHQwbNowRI0YwduxYJk6cyMCBAwG45JJLGD58OIMGDWLatGnV7+vRoweZmZns3r2bAQMGcOONNzJo0CDOOecciouLG6VsPussdq7d+m9gkzHmn/Wc9gVwu4h8gO0kzjPGHPBVmVQz46iEQB3BrJreX77cwMb9x9RAUa+BnaN59OJB9R5/6qmnWL9+PatXr2b+/PlceOGFrF+/vnqY5/Tp04mLi6O4uJgRI0Zw2WWX0aFDhxrX2LZtGzNmzOD111/nyiuv5JNPPuHaa6897rL78ls4BrgOWCciq537/gh0AzDGvArMAi4AtgNFwG98WB7V3JhKdCqLaqtOOeWUGmP9X3zxRT799FMA9u7dy7Zt2+oEgp49ezJs2DAAhg8fzu7duxulLD77FhpjfgQaHMdk7ILJt/mqDKqZc1T6uwSqjWrozr2pREREVG/Pnz+fuXPnsnjxYsLDwznjjDM8zgUIDQ2t3g4MDGy0piHNNaT8xzj8XQKlmkxUVBT5+fkej+Xl5dG+fXvCw8PZvHkzS5YsadKyab1c+Y/RGoFqOzp06MCYMWMYPHgw7dq1o2PHjtXHzjvvPF599VUGDBhA//79GTVqVJOWTQOB8h9tGlJtzPvvv+9xf2hoKLNnz/Z4rKofID4+nvXr11fvv++++xqtXNo0pPxHm4aUahY0ECj/0RqBUs2CBgLlP9pHoFSzoIFA+Y82DSnVLGggUP6jTUNKNQsaCJT/aNOQUs2CBgLlPw5tGlKqPpGRkU32WRoIlP9ojUCpZkEnlCn/0c5i1YY8+OCDdO3aldtus+nVHnvsMYKCgpg3bx45OTmUl5fz5JNPMmnSpCYvmwYC5T/aWaz8ZfaDcHBd414z6UQ4/6l6D0+ePJm77767OhB8+OGHzJkzhzvvvJPo6GgyMzMZNWoUEydObPK1lTUQKP/RpiHVhpx00kmkp6ezf/9+MjIyaN++PUlJSdxzzz0sXLiQgIAA9u3bx6FDh0hKSmrSsmkgUP6jNQLlLw3cufvSFVdcwccff8zBgweZPHky7733HhkZGaxYsYLg4GB69OjhMf20r2kgUP6jfQSqjZk8eTI33ngjmZmZLFiwgA8//JDExESCg4OZN28eqampfimXBgLlPxoIVBszaNAg8vPz6dKlC506deKaa67h4osv5sQTTyQlJYUTTjjBL+Xy5ZrF04GLgHRjzGAPx2OAd7FLVwYBzxpj3vRVeVQzpE1Dqg1at87VSR0fH8/ixYs9nldQUNBURfLpPIK3gPMaOH4bsNEYMxQ4A/iHiIT4sDyqudHOYqWaBZ8FAmPMQiC7oVOAKLHjpCKd51b4qjyqGdIagVLNgj9nFr8EDAD2A+uAu4zx3GgsIjeJyHIRWZ6RkdGUZVS+ZCptmomKUn+XRLURxhh/F8HnjuVv9GcgOBdYDXQGhgEviUi0pxONMdOMMSnGmJSEhISmLKPyJeOAbx+GJxM1GCifCwsLIysrq1UHA2MMWVlZhIWFHdX7/Dlq6DfAU8b+X9kuIruAE4Cf/Vgm1ZQcDljxtt2uKIGgUP+WR7VqycnJpKWl0dpbFcLCwkhOTj6q9/gzEOwBJgA/iEhHoD+w04/lUU2tRmdx006pV21PcHAwPXv29HcxmiVfDh+dgR0NFC8iacCjQDCAMeZV4AngLRFZh/0VeMAYk+mr8qhmyFGJHTOA27NSqqn5LBAYY646wvH9wDm++nzVArjXCHQEkVJ+o+sRKP8xDqjquGvFHXhKNXcaCJT/uNcCdHKZUn6jgUD5j3FQ3TegeYeU8hsNBMp/HNpHoFRzoIFA+Y/RpiGlmgMNBMp/anQWa9OQUv6igUD5j/s8Am0aUspvNBAo/zGVOnxUqWZAA4HyH4dbc5D2ESjlNxoIlP8Yt6Yh7SNQym80ECj/cf/x1z4CpfxGA4HyH51ZrFSzoIFANa3a/QI6fFQpv9NAoJpWfRlHHRoIlPIXDQSqadVoDtJcQ0o1BxoIVNNy/8E3OnxUqebAZ4FARKaLSLqIrG/gnDNEZLWIbBCRBb4qi2pGajcNaR+BUn7nyxrBW8B59R0UkVhgKjDRGDMIuMKHZVHNRX0jhXT4qFJ+47NAYIxZCGQ3cMrVwP+MMXuc56f7qiyqGakzd6CqRqCBQCl/8WcfQT+gvYjMF5EVIvJLP5ZFNZXaNQJtGlLK73y2eL2Xnz0cmAC0AxaLyBJjzNbaJ4rITcBNAN26dWvSQqpGVqNGUM+2UqpJ+bNGkAbMMcYUGmMygYXAUE8nGmOmGWNSjDEpCQkJTVpI1ciMDh9VqrnxZyD4HDhNRIJEJBwYCWzyY3lUU6ivs1j7CJTyG581DYnIDOAMIF5E0oBHgWAAY8yrxphNIvI1sBZwAG8YY+odatroyorAUQFh0U32kYr6RwppjUApvzliIBCRCKDYGOMQkX7ACcBsY0x5Q+8zxlx1pGsbY54BnvG2sI3qtXGQtQ0ey/PLx7dZpQWubUeF27bWCJTyF2+ahhYCYSLSBfgGuA47R6Bly9pmn3VlrKZVmOHarnS7l9CmIaX8xptAIMaYIuBSYKox5gpgkG+L1YSKc/xdgralKMu1veZ917Y2DSnlN14FAhEZDVwDfOXcF+i7IjUB96GKuan+K0dbVJhpnyMSa+7PPwRZO5q+PEoprwLB3cBDwKfGmA0i0guY59ti+Vix24Tn3D3+K0dbVJgBEgiRtQLBnIfgXyf7p0xKtXFH7Cw2xiwAFgCISACQaYy509cF86n8A67tHfNg4CT/laWtKcqE8A4QFOrvkiilnI5YIxCR90Uk2jl6aD2wUUT+4Pui+VDObvucNARWvgNlhX4tTptSmAkR8RAY4u+SKKWcvGkaGmiMOQxcAswGemJHDrU8VSOEdv0AweEw4gY7WiX/oH/L1ZaU5EFYLAT4M7uJUsqdN4EgWESCsYHgC+f8gZY35nLvMph+HuxaaGsB3U+FWGfeopVvw4Kn7XbqYlj0ov/K2Rq9Pxk+v91uV5ZBUIjWCJRqRry5LXsN2A2sARaKSHfgsC8L5RMBgbBvBbwzydYGxv8JgtvZY4tesM87voc9i+32qXeAiH/K2tps/do+T3rJzh0Ii7EdxkqpZuGINQJjzIvGmC7GmAuMlQqMb4KyNa4uJ8NZj9rx6qfcZF9Hdqx5TlUQAPjnQPhXStOWsS2oLIeAYAgM9ndJlFJO3qSYiMHmCRrn3LUAeBxoebkZRt0G7XtA7zPt63btITAUKkvrnpu/v0mL1mrVTi9dWWaDQIDWCJRqLrzpI5gO5ANXOh+HgTd9WSifCQiAARdDSIR9LVK3VqAaV1l+zdeOchsItI9AqWbDmz6C3saYy9xe/0VEVvuqQE0uJhnyGphUVl7s6ktQR6/IbfKew2GbhgJD6q8ROBw2YCulmow337hiETmt6oWIjAGKfVekJhbdqeHjBYeaphytlXsup7ICZx9BUP01AveMpEqpJuFNILgFeFlEdotIKvAScLNvi9WEwmLs82n3wAkX1T2+7Vt4e2LNO9v6GOOarKYs90BQkufsIwgBqeefngYCpZqcN6OGVhtjhgJDgBONMScZY9b4vmhNJDTKPgdHwJT34OYfbSdylVn3wa4FcHDtka+14k14Yagdpqos90Cw/mOb5ykwuP703xoIlGpy9fYRiMi99ewHwBjzTx+VqWn1Gm/nEXQ+yb5OOhHaxdVNT529y84/6HpK/dfas8Q+p2+GLsN9U96WpiTXtT33MfscGGxrBp5oIFCqyTVUI4g6wqNBIjJdRNJFpMHlJ0VkhIhUiMjl3he7EfUeD/dth75nufa51wiqzLwb/n02LJ8Om76Egoy65wQ4x8Y7Gly8rW0pL6m7r6ERQ+9dAbMf8F15lFJ11FsjMMb85Tiv/Ra2P+Gd+k4QkUDg79iVz/wnMqHm62FXwb7lns/9+Q1I3wA9x8Gvvqx5rGokTGl+3fe1VeUexhUENNA0tG+5fZz/d9+WSylVzWfj9IwxC4Ej9bDeAXwCpPuqHMck5Xp4YHfd/QkDbBAAyNtX93jVursFzevP8auK4roJ5gKDceiKZEo1G34bsO1cA/kXwCtenHuTiCwXkeUZGR6aZBq/cLZ5KDi85v5Bl7i2wzvUfV9Vv0JhE5SxpSgvtv8d71jp2hcYzIyluiCQUs2FNykmAo3xycrizwMPGGMccoTkbsaYacA0gJSUlKbLfHrDXJuttDATsrZDwgmuYyV58OaFcMnLdtnFmXfDfuePndYIXMqLISgMOvS26T1yduusYqWaGW9mFm8TkU+AN40xGxvxs1OAD5xBIB64QEQqjDGfNeJnHJ+Og+yjSnEuDJkCaz+AzC328dO/oO+5sPa/rvOytjV9WZsr95nZVRlHA4KQqkzmKdfD8n/7p2xKKcC7pqGhwFbgDRFZ4mymiT7eDzbG9DTG9DDG9AA+Bm5tVkHAk3axcOlrdkGbKnn74Kda6xfk7oGc1KYtW3NV4RYIqjrTA0OoXtLCPdAqpfzCmwll+caY140xpwIPYDORHhCRt0WkT33vE5EZwGKgv4ikicj1InKziLT8WckRbguvb50Nu3+w233PgfOco112/9j05WqO3GsEVZ3GgcFUNwbW1yz4RKJrnQillE951UcAXAj8BugB/AN4DxgLzAL6eXqfMeYqbwthjPm1t+c2C11PgZhurmR1IVFw4mVw8Qs2adr3T8D+VTD0Kk2gVl4MQTWbhkxAMKU451zU119QWQrfPgJj7mqCQirVtnnVRwDMA54xxvzktv9jERlXz3tat97j4Z51kLnddiL3P891LCAAkobAstft44bvILkNL3BTXuzK5+QMio7AYP5RcSUlhHDziVfC57f5sYBKKW9uV4cYY66vFQQAMMbc6YMytRzxfWoGgSqdhrq237sCds6Hx2Jg96ImK1qzUVFSp7PYIUHkE85TFVfb9YuVUn7lTSBIFJEvRSTTmTLicxHp5fOStWT9znVtF2fbdZLBJqVra8qL3AKB/edWKbpMpVLNiTeB4H3gQyAJ6Ax8BMzwZaFavJ7OFrOBk2DCI679m2dByWH/lMlfykvsPAKo7iyuQJepVKo58SYQhBtj/mOMqXA+3gXCfF2wFi0gEP50EC6bXnONg/JC+PE5/5XLH9xrBM7how7T8ARCpVTT8iYQzBaRB0Wkh4h0F5H7gVkiEicicb4uYIsV3A4CgyCut2tfVCc7rDRzW/1J11qbGn0EzqahSg/ZWcNim7BQSil33owautL5/Lta+6dgZwVpf0FDAoOg22g7kig4zI6Nf8k5imjSVDjpGv+Wz5eMsYEgqFaNoLJWxpJHcyF9E7wyuokLqJQCLwKBMaZnUxSkVfvt1/Z5y9c1J0l9fisM+gWEhHt+X0tXUWqfg50tiVWjhiorqFEZFdH8Q0r50RGbhkQkWETuFJGPnY/bRXTYxzHxtLrZtjn2B7M1NhVVOBelqeosHmIrlyWxfeueG6AdyEr5izd9BK8Aw4GpzsdwvEgdrTwId+tSueF7CI+HVe/B1FHw7qXgqe28JauqEVTd7Q+dAg9nURrZpe65tdcsUEo1GW++fSOci9dX+V5EWs/i9U3tng12ha6ojjZ53YKn7P7snfDDP+CMB13nZmyxaxxIQMNrJTdXtWsEAIFBlFd6qP1oIFDKb7z59lWKSG9jzA4A52QyX6xP0DbEJLu2x91nn8sK7BoGC5+Bvmfbhe9L8+Fltx//R7JbXvNJVY0gKLTG7kqHBgKlmhNvvn33AfNEZCcgQHdsAjp1vAKDYfxDdrsoG/YshtfPhMiOUHCo5rlr/wvDrm76Mh6PSs+BoMJTIAjUQKCUvzT47XNmHh0K9AX6O3dvMcaU+rpgbU54HFz9X3jl1LpBAOCzWyC6C/Q6venLdqyqawQ15x9WVHpYr1hrBEr5TYOdxc4lKq8yxpQaY9Y6HxoEfKXjIJj8Ltz4PTyQCif/subxJVP9U65jVd1H4EWNIEAHoinlL97chi0SkZeA/wKFVTuNMSvrf4s6ZgMudm1f/CIMuhR6jIXv/mJXQsvbBzFdbA6f9Z/YTKdJg/1X3oZUBYJAL/oIgjVriVL+4k0gGOZ8ftxtnwHObPziqBpE7NoHYCee/fQiTB0Ntyyyk9F2LYSIBLh5kR2F1NxUlNnnWjWCck9NQ0opv/FmHsH1xpjx7g/ghiO9SUSmO9NWr6/n+DUislZE1onITyIy1NN5yqnLyTDufijNg+cH2yAwZAqUFsCnN8GhjXad5NICf5fUxdPwUerWCApLKyit0IFoSvmLN4HgYw/7PvLifW8BHlZtqbYLON0YcyLwBDDNi2u2bWN/D6HRdvvSN+DS1+CcJ+zCN6+MhheG2DxGzWWWcj3DR2v3EQx6dA4T/1XPoj1tLW23Un5Qb9OQiJwADAJiRORSt0PReJGG2hizUER6NHDcfcWzJUByfecqp+Aw+N0C2z/QcaDdl/JbOLwfVr9nRxvlH4DMrZDQv+FrNYV6Oos99RFsOZQP8R6GzT7VFSb+q27HuVKq0TRUI+gPXATEAhe7PU4GbmzkclwPzK7voIjcJCLLRWR5RkZGI390CxPXyxUEwE4yO+tRuG8r3LTA7tvwqa0VfHoLvDwSPrgGyoqOfO38g5CX1nhlrazqI6h531BvH8E1H1enqq5h/f8ar0xKqTrqrREYYz4HPheR0caYxb4qgIiMxwaC0xooyzScTUcpKSnNpN2jGeo8zC6EM/8p26Sy5n27P2MzrHwbRt3S8Ps/uBr2rYDf/QCdhhx/eY6iRgDYz7zsDfj4t7WuoyOWlfIlb/oItovIH0VkmrMDeLqITG+MDxeRIcAbwCRjTFZjXLPNu/CfgIElL9vXd66yi+Ps+L7h9+Xts0EAIPWnhs89EkelnSm9zznCONCLeQRVPE0sqwooSimf8CYQfA7EAHOBr9wex0VEugH/A64zxmw93uspp6iOcOE/IOEEGHy5bUrqfSZs+wbWfOD5PQ4HPOfW3JR/oP7rL38Tvrij4TL8+E94uids/My+rpU+osJT0rkqGgiUanLezCMIN8Y8cLQXFpEZwBlAvIikAY8CwQDGmFeBR4AOwFQRAagwxqQc7ecoD0bcYB9Vxv8R1n0IK962qaBry021z0knQlGO7Suoz8y77fPFL9p5DlWydtghrSm/gZ0LGixepaOBeQSeAkFpAWyeBf3Pr/mZSqlG4U2NYKaIXHC0FzbGXGWM6WSMCTbGJBtj/m2MedUZBDDG3GCMaW+MGeZ8aBDwlfA4GHYN7PkJPr0ZSvJcx4xxrZp24XMQ3bn+GsHS11zbJbk1j6182waJ4lyISmqwOA03DXnIsJq3Bz64CrbPbfC6Sqlj400guAsbDEpE5LCI5IuIDu5uaboMt89rZsBT3eDf59i77E9vhhVv2mMJ/e2P+K4Fto2/tvlPubZr1xoK0u1z1g67HVn/TOd6O4uh4eRzVTUXpVSjOmIgMMZEGWMCjDFhxpho5+vopiicakQDL4FfvAbtnKuk7V1q77LXOvsNeo6DsGgI72Bfz/urfV74LGyZbQNDcTb0c84RrDcQbLfbySNgygyY8GidonhcmKaas+knqnPdQ8W5dfcppY6bN2sWi4hcKyIPO193FZEWuFxWGxcYZPsH7t8JD+6F+7bB6Q/YH9xRt8KvvrTnnersCM7eCWnL4fsnYMYUOwQVoJcz91HtiV/VgWCbPRbZEU64AMbeW6co7n0Ejtq1gzJniowYD/MLtUaglE9401k8FXBgk8w9ARQALwMjfFgu5Ssi9s6faNuJPP6PNY936A19zrLt8bsW2n2hMXBog92uWg/hm4ehvMhO9rruMyh0BoL0Tbbm0EDTkHsfQZ3+gqr+i5guUHtu28p34MAauHE+BHjTqqmU8oY336aRxpjbgBIAY0wOEOLTUin/inR29iacACnXQ+lh2PQlxHaz+3qMtT/8M++B3T/A5i+h0Dnju2oOQmRivZd3Hz5aZ5Zxn7MhpputrdQWHG4DQWle3WNKqWPmTSAod65UZgBEJAFbQ1CtVWSCfe4xFnqOBYztQO57rq1RTH635vnfPQHGYX+oi52dzA2MHCoorajeLquo9U8pMgHuWQeJA2ruj+oMFz1vtwuzbL6l9E3H8McppWrzJhC8CHwKJIrIX4Efgb/5tFTKv8qdE7giE20z0ejbbQrsMXfZ/e1i7YI4YJPeZe+w273dlqhooEaQXVhWvV3mzdoEv/4KbvjW1ZFdlAkLn4GpozQYKNUIjthHYIx5T0RWABOwQzouMcbot6816zjIPienQGgUnPvXuudc84lNEFeSC8udGUcGXgKbZ9rtBvoIagSC2jUCT3o401BVNT9NPxc69LXbK/8D5+l9iVLHw6sVw40xm4HNPi6Lai5Ouha6ntJwKuuq5qPwONe+vme5tiMS6n1rlrc1gpOuq5mwLjze7SLb7POB1fW/XynlFa8CgWpjRLxfz0AE+l9oh322a+/aXyvjqLusAlc20QZrBJNeqvm6qmnIXeoiWPZvGHG9d+VVStWhY/DU8bvqffjVF3Y7uuH1hYwx5BSVERVq70GOav3ikHDP+7+617U+slLqqHkzoSxCxK4WIiL9RGSiiAT7vmiqRbptKTywu97Dh0sqKK80JETZGkNx2TGsVRzoYfTyIY9LYyulvOBNjWAhECYiXYBvgOuw6xErVVdoZM0molryisoBiIuwP+aTpy05uus/nAW3L7Pb7gHh9TNh9lEnyVVK4V0gEGNMEXApMNUYcwV2LWOljlq5M71EuxAPWUa9ERgE7XvAJa/A3evg7vUQkQgYWPoqPJlkZyArpbzmVSAQkdHANbgWpDnGb7Fq66pmFYcGHWf31LCr7aS12K41Ry5VFMOsP9i5EB//1q7BoJRqkDffxruBh4BPjTEbRKQXMM+3xVKtVVXncGhQI95LxDvnFPz2G7j0dbui2fMnwvpP4Ms7oayo8T5LqVbImzTUC4wxE40xf3d2GmcaY+480vucaxuni4jHXjxnVtMXRWS7iKwVkZOPofyqhalKMhdyvDUCdxe/aJfn7HoKDLkSBk6yuZCq1jb44CqoKLVrKSul6vBm1ND7IhItIhHAemCjiPzBi2u/BZzXwPHzgb7Ox03AK15cU7VwFdU1gkYMBOFxdmnOqmUsfzENzn8a7t0M5z8DO+fDk4l2ER7T0FoISrVN3nwbBxpjDgOXALOBntiRQw0yxiwEPCxzVW0S8I6xlgCxItLJi/KoFqyqRtCogaC24DAY+Ts7+3nEDa5Zzus+tAGhKiWGUgrwbmZxsHPewCXAS8aYchFpjNuqLsBet9dpzn11FswVkZuwtQa6devWCB+t/KW6szi4icYbBATADXNhw6ewfzVs/Azm/AlWv29XayvOtiu3dejdNOVRqhnyJhC8BuwG1gALRaQ70KRrFhtjpgHTAFJSUrRu34JVDx9tqkAAdrjpaffY7f2rbNrsjC2QtgyCwuBfJ8OQKTa5naMCUn7TdGVTqhnwJvvoi9hU1FVSRWR8I3z2PqCr2+tk5z7VilXVCCJD6/7T+2LNfkb1jCMxOsx3Beh8Elz3P7v+cf4B+/zm+Xbt5qr1mzd+ZtNr9zoDwmJ8VxalmokjBgIRiWRTWF4AACAASURBVAEeBcY5dy0AHgeOd5moL4DbReQDYCSQZ4yp0yykWpeqzuIID4HgzhmrGNwlmpl3jPV9QdrF2gfAozl2Wc70TTbV9ZoZ8OEv7bF+58GER1ypuZVqhbxpGpqOHS10pfP1dcCb2JnG9RKRGcAZQLyIpGGDSTCAMeZVYBZwAbAdKAK0Pt4GVHUWR4R6bhpKP1zqcb9Pidi1mKvWYx77e9unkL0Dlr0Br42zE9iST7EL8iSd6Bqh1NR2LoDcVBh8ef1J+Ly15WvI3Aqjb4MAnSPalnkTCHobYy5ze/0XETliEnhjzFVHOG6A27z4fNWKVDj7CCJCPP/Ta9T5BccqJBxOusZuj74dvn0E1n3sSl3Ra7xdua33mXYN54AmLPOnv7NNWus+gl99eezXMQZmTLbbPcZAl+GNUz7VInnzL7hYRE6reiEiY4Bi3xVJtTb7covp8eBX/LQjk/KqPoIwz4HAp8NKj0V4nF0X4aE0uH0FnPlnyNoO3/wJXhkNr42FRS/CwfW+n8FcUQb5B+32vlXHd62SXNf2D/+EooZGeqvWzptv3c3AyyKyW0R2Ay8Bv/NpqVSrsiI1B4CrX1/K9vQCwHNnMUBggPDPb7bUWOC+WQgIhPg+MO4PcM96uHUpXPCsnbH87cPw6hh4qht8cA2s/RCKcxq/DHl7AWOX6SzLh/JiSP0Jfnzu6K7jcMDh/a7Xm2fC51o5b8sabBoSkUDgOmPMUBGJBnBOLlPKawFuzenTFu4EPHcWA2w9VMDWQ9spLKvk4YsGNkXxjk3iCfZxyo32Ln3H93Bwnc1vtHkmSCB0PxX6XwD9z4O4Xsf/mTm77HNyil2qszDTjngC24QV6MUyITu+hw+uhYufr7k/e9fxl0+1WA3WCIwxlcBpzu3DGgTUsch1rkHgLuIIaahLK1pQXqCoJNuZfN7/2bQWN3wHp90NRVkw5yF48SR4eSTMut/ewR/rampZNohWt+cXZbqO5e6BHfPgy7uc5+6wTVa1U2rsXQblhbB3ac39jmZWA1NNypvO4lUi8gXwEVBYtdMY8z+flUq1KjmFdX/4wuupEVQJ8NeonOMVEGDv2JNT7LDT7F2wZTZs/xZWvg0/vwbB4ba20Pcc+4jr6d21N39pJ8clDbGvC9Jdx3J2wbvOMR1nPgzvXQ7ZO2HIZIjq6Hbebvu87A1AAGegyNoGm78C44CvH4I7VjS47rRqXbwJBGFAFnCm2z4DaCBQXsnyEAiCAxv+oW+xgaC2uJ4w+lb7KM6F3T/CrgW2iWb2/fbRoS/0mWBHIXU/FUKj6l4ndy/s+gHOeNDmUALYt8J13L1pJ2OLqw8gd4/t39j6NQy7xhUIwAahbXNcr7+4wwaC4hw4vM/maAoO16GlbYA3M4t1fL86LjlFHgLBEYZctpY4UEO7WBhwkX2Abb7Z9g1sn2sX0Fn6qk2d3SXFzmnoNhqSR0BIhD2GgaFTbI4ksDWNKhmbXduZW+wPOtg5B9u+gYVP2/kP7oHg9Pttyo1CZ82iotSu5QA2gLxxFoy73wazgkNw8i998V/l6FSUwfdPwJZZcNq9rmG+6rh4M7P4beAuY0yu83V74B/GmN/6unCqdcguLGNY11guODGJv82yP1gBAW2kRtCQDr2hwy0w6ha7otrepTZl9s75sPAZ54+52EBQVmDXWWjfw7b7RyTAwbUQEgUJ/e1IpSrpm2sGgj2L7famLyHfbbRQVBLcucqeu3kmfHaL69imL20fx4ZPYa9zXenGmMR2vLbOhp+cGW8+v1UDQSPxpmloSFUQADDG5IjIST4sk2plsgvLSIoOIz7S+zbnNhAGagoOc5vd/CiUHIa0nyFthf1B7jjINu2ArS51Psne6XcbCR36wL7l9lj7nvZHvarz9+B6SHMeW/ZGzc+M7OgaadSrVvqwdR/Z56ogAHBoA3Qd0Wh/8jEJ8OYnSx0tb+YRBDhrAQCISBzeBRClABsI2keEEB3mxfBGpyPVGFq9sGg7e/mMB+CCp2H4ryDQ7WuX6Bxae8pNtgkJIDwehl5l2/cB4nrDhv/ZdZwTBtSd2+A+3DS6k+1YDom0r0s8pBL7+gH/r+VQY5W5Nv5vpBF5Ewj+ASwWkSdE5AngJ+Bp3xZLtRbGGLILy+gQEVLvbOL24XUDRFtoGTou4/4A13xsO3wHToLL34Qp70Pfs1znXPORa3vCw0e+5qSX4f6dEOZMxlcVFABCY2zn9Mx77AzqfSsgY6udQDfvb43zN3mj1G0Ee3C7pvvcVs6bNYvfwSaYO+R8XGqM+Y+vC6Zah6KySkorHLSPCKl3NvGTl5xYZ1+b6CM4HqGR0PdsGzFFYPCltpmos9vS3x16Q89xEN7BTmyrMvp2OPWOutcMDLZDRk+61r4e+3vXsZE3ubZfGAqvnwkvj7DNUAv+DmWFNIkSt0Cgw1sbjVdNPMaYjcBGH5dFtULZzqGjcQ0EgkAPtyNtvWXomInAXWts+gmAa/9n+wtE4JbFNqPqgIsbvsa5f7XDVIMj4Lu/2JrBGQ/ZYLLiTVfyPXcfXw+/eNWV2ttXSvNd27r+dKNpZhm+VGtTHQjC628a8nT3r9/x49C+ByQOsNuBwa4mlI4DjxwEqoRG2clxd66GW5fYuQRdTraT1dwlDLB9GVtnw9+7w8Jnax4vL7bt+iWHXZ3Wx6OqaSiqk02c99ZFthNbHZc22+lbUl7JpJcWcf1pPblyRNcjv0Edk2znHIK4yLo1gn9ddRK5RWU4PPzoV3jaqZpe7VnPkYlw/jN2FFPeXug9wY54+ntPcJTbMf6H90Fsd4hJhk9vhiFX2jv5TV/YZqmMLTDmTug+5ugmq5Xkwcr/QGSSbdqa80fY/QO8cipc/y10PaVx//Y2pM0Ggu3pBWw5lM/9n6zl4qGdaXeE3Dfq2GQXuGoEtVNMXzy0MwCfrEir876DeSU8P3crd57ZV0cQNTfu/QVVTr8f5v3VbtceWbT6Pdf24pfs8/ZvbU3i2k+8/9w5f4TSPPuomlRX5d9nw2PHu2hi29Vmm4a2HHS1Na7a44OUwQqAwjI7nj0yLAippwPYU8rpL9bs5/m521ieqv9vWoSxv4e71sLDmXDPBrhvm202asj2ubB0Ghz2coXa/EOubU93/4/F2AlwZYW6vsJR8mkgEJHzRGSLiGwXkQc9HO8mIvNEZJWIrBWRCzxdxxe2HnIFgqW79B+Nr5RV2BmuDS0409DaA5XaRNQyBARC++62TyIm2TYh3fidXcznaues546DbZoLd7P/AP88AT650U54y6tbOwTszGv3uQ0dens+77sn4MNfwdM9j32hoPKSY3tfC+azpiHnWgYvA2cDacAyEfnCOQKpyp+BD40xr4jIQOw6xj18VSZ36/fnMahzNOWVDjbs1+zavlJaHQjqb3q7Yngys9YdoGd8BDPX1rw71FGkLVhIhF3Mp30PGHsfnHwdRHexncY/T7NzID672Z677kP7+PF5Z/9CF+h5Ogy+DPb8BDPvda3HcN2n9vmOlbYzOiAIpo60+yTANjsBrP0AUn4Le5ZCfF+72lxDVr3rWqDn3k0Q3blR/3N4raLUBsT6gp0P+LKP4BRguzFmJ4CIfABMouYwVANEO7djgP00gfJKBytTc5k8oiupWYUcyCsmu7CMrYfyGdWrA+8s3s0pPeM4ISn6iNdSDasKBA1lG02MDuOrO8fy9Neb6xxz6PChli8wqOaEtu6j7cMYm9yu79k2aMx/yiaTkwBI/RHW/tfmE3LX9xybpRU8/1BmbXNtH1hrZ1NPP8fOvv71rPrXl84/VHOVtnUfwZi7ju3vPV4z74XV78IDqb4fjuvky0DQBdjr9joNGFnrnMeAb0TkDiACOAsPROQm4CaAbt26HXOBjDGICCtTcygur2RkzzhKKxysSM3h5CfsXcSr1w7nkc83MKBTNLPvGnvMn6Ws0opKQoMCqvsHpv86Bef69XUEe5hQUFpez8mq5ROxKTSqXPGmfTYG5j4K6ZvsdtUd/sBJMOFRz9e6cZ5NvLf0Ffs6IsHOedi1wL7esxgeb2+XFz28345kiu/vCgz/6OdWrkDbdzHiRv8k2dv8pfP5K7vgURNUi/09augq4C1jzD9EZDTwHxEZbIyp8e03xkwDpgGkpKQc0y3ihv153P/xWu47tz+vzN9B+/BgTusbz/b0Ag6XuNqob37X5njPLSrjxMfmMO26FEb37nCMf54qq3AQ4tY/cOYJHes9N8RDP0JJeQtaqUw1DhE4+/Ga+0oL7Gzq+nQ52fY/LH3F5liK62UDSPbOmufNus8+//hPCAyFX31pk/tVOf9pm8fp7YvssqMnXwf7V9u5GDHJtuYCUFlhM8Ru/9auGHfBM8f/d4MdblvVF/L5rRARD/3ObZxrN8CXgWAf4D5AP9m5z931wHkAxpjFIhIGxAPpNLLDxRUUlFbwmzeXAfD05UOICgumU2zdfCWBAcKBPNthNHX+dr7bdIjDJeU8ffnQI37OitRsisscnNY3vnH/gBaqtMLRYP+AO0/NRyUtaclK5TsNBYEqgcFw9zo7GW62s6Yx+V3bafyphyGvlaW22ahKz9Nt4r2wGNuXse0bG1ymnW6PD5gIk53ZdeY+6hoKu28F5O2Dq96vef3SAggKq5ksEGwtpzDDNkWd9RgknOCaT7FmRs1z3deP8CFfBoJlQF8R6YkNAFOAq2udsweYALwlIgOwq6Fl+KIwo3t3YNadY3lp3naGd2vPWQPtnWnX9nUDwW3j+/Did7at0Rh440fbSTWiRxxd48IZ1av+GsLjMzexP7eYpQ9N0PHv2BpBQyOG3IV4aBpKzSrip+2ZnNpHA6vyQqyz6fi8p2x/wgkX2RpG1cI+Y+6yE9kqSmDvzzD3MbueQ3QXuOg51w9yv3PtfIhNX7iuvekL2PAZVJbZIHDKTXDu/8FHv7I5l3JS7cipkjz4/kn7/pBIW4b+59l04eVFsOItV5qObd/A8F/DxS/UzQ4LkH/QtV2c67M+AzE+7IxzDgd9HggEphtj/ioijwPLjTFfOEcKvQ5EYjuO7zfGfNPQNVNSUszy5Y0wVd3J4TDMWn+APomRBIgQEhjA1kP53PSfFfW+Z/dTF3rcX1HpYNCjcyitcDDzjtMY3CWm0crZUt0xYxUb9uXx/X1nHPHcnRkFnPmPBR6P1fffXCmvOByuBH3eyD8E/z4LKsth0KU299J7l9vFg8AGk19+bmshGVvg5VPsGhGXvm6bd/avtCOeKsth42dH/ryHs+AJ5w3m6Nvt6muvjrGfc/m/bfmf7mnTkdduNvOSiKwwxqR4OubTPgJjzCzskFD3fY+4bW8ExviyDEcSECBcNKTmMLHuHcL54f7x7Mos5JfTf67znqpO59p2ZBRWj5L5fnO6BgKgrKLSY9u/J70SInnyksH8+bP1Hq7j8Po6StVxhKVR64jqaCfIuX/PJ78LM6bY5qJz/upazyG+n73r3zwTXkqxtYAr/+NaknT5dJu+uyFPuLUyDJ0CER3skNfcVNssseh5m1spcdDR/R1e0m+WByJC17hwxvVL4C8TBzGlVi6iVXtz+Wpt3dmQa9LsQm7xkSF8v7nRuzlapNKjaBoCuHZUd07z0AxU2MCkM6V8ovbNXmQi3Pi9bcZx77MQgSnv2bkSg34BN//gCgJg5zL87gfoWDfdeg0BQXDzIteku6Qhtv9h7qM2CyxAj9OO/+/ywN+jhpq9X53ag12ZhXywzDUS9qppSyitcNA/aRx9EqMAOFxSzpIdWcRFhDBlRDdenr+d4rLKNp/D6Fju5IM8dBoXlFbQPiKksYqlVONraPGfTkPglh+dHcih9kdfxE6I2zrHdhhXlEDSYNd7xv/Rrl+96AX7utd4O9HOBzQQeKFbXDi/PrUHU07pyuNfbmT5btup8+gXG+gWF8GkYZ257t9LKa80nD84ib4dIzEG9uYU0a9jlJ9L71+lFQ7aBR9dMAzyUI1vKA2FUi1G7dFPwe1g0CWezw2JgIn/gtfH22VIf+lFX8Mx0kDghcAA4bGJtm3u1euGU1BSwcSXFrFoexaLyGLGz3sIDhRuGteLiUM7V+fHee7brWQVlDGyVxz3nt2v3qRrrVlZhYOYdt6vVQyeh5FqIFBtUpeT4Tdf2yGxPqSB4ChFhwUTHRbMs1cMYfPBfAT4v9mb+dXoHvzxApttMa+oHIDZ6+3Qr593ZzNhQEeKSisY2jWWiHpW6mqNqmYWH40gD8NINRCoNqv7aJ9/RNv5RWpkZ/RP5Iz+iQBcM6p7jUVXYtwWY1/80JmM/r/vueTlRQAM7BTN/249lbCjbC5pqY6lj+BQXt3sjwUlGgiU8hUdNdQIPK3F+/4NI/nu96fTKaYdo3rFERoUwIVDOrHxwGH+t3IfJeWV7M4sxNHK0ywf7aghgGWpNi14uFtHe1ZBKcVlOstYKV/QGoGPuM+Eff+GUVQ4DMGBwp6sIl5dsIPn5m4lI7+Ui4Z04qWrT/ZjSX0jp7CMRTsyKS73fh5BlQsGd+KrdQcY0SOOBVvtRPPHvtzIU19vZvMT5/uiuEq1aVojaAIBAUKIMwPnlSO6sie7CIfDMKZPB75ad4A9WUUs2JrBrHUHKCqr2wSSV1xevcBLS3Htv5dy+/uryC0q9zrXUJXnpwxj3WPnkFwr/UeJZiJVyie0RtDELhnWmXVpufxydA9iw4MZ/+x8xj0zr/r4b8f05JGLB7I9vYB5m9Mpq3Qwdd52goMCeHzSYCYO9e1iGfXNmj7aa+zMKKx+fbQ1guDAAIIDA0iMCjuuciilvKOBoIlFhQXXyGL65CWDeWHuNq5I6crOzELeW5pKXEQw//p+e3W6ik4xYcSGh3D3B6tIjAqtTnqXV1TO/K3pDEmOpWd8xHGX7WBeCee/sJA/XziQy4YnH/N1DpdUUOyWPtrTOgPeSIwOrbNv3NPzuGJ4MndM6HvM5VNK1aSBwM8mj+jG5BE2Y+KhwyX8tD2TZ7/ZyoldYnj56pOJjwqhXXAgRWWVnP/CD/z5s/XMunMs+3OLmTJtCQcPlxAZGsRzk4exM6OA2PBgLh7amfAQ+7+2KqmgN3f5M9fuJ6eonN9/tIaJwzp7/AF/+6fdvP7DTh6+aCDnDkqqcayswuFM4V0MwLNXDKWkvJIJAxKP6b9NVaqJoV1jWbPXpu/Yk13EP77dqoFAqUakgaAZ6Rgdxtd3j6Os0kHnmLAaP94RoUE8evFArn97Ofd8uJpVqTmUVlTywpRhPDV7Mze+48rIunBbJi9ffTLGGK5/eznLdmVzx4Q+3DSu/jVQKx2G/7ql0Vi/L4+TurWvc947i3eTllPMtIU76wSCU5/6nmFdY7h6pA1sPeMjGN697jW81TUunN1PXYjDYZg6fzvPfrMV4KhnKiulGqadxc1MQlQoXWLbebyDnzCgI5ee1IWv1h6goLSC/1w/kknDuvDtvafz7BVD+fy2Mdw+vg9frT3AitQcPl6Rxveb06k0hr/N2szSnVn1fu7s9QfYll7A45PsDOqfd2XXOWd3ZiE7MgpJjAplRWoO+3KLq4+l55eQWVDK3E3prNpj7947xzZOG39AgHB6P1etolOM9h0o1Zg0ELQwT18+hHevH8mce8ZVp7mODA3i8uHJDO0ay63je5MYFcoNby/j0S82cEqPOJb/+Sw6x4Tx5Feb6p23MHPNATpGh3LtyO70SojwGAiqMqo+dZnNjrhgSwZpOUVk5Jeydm9e9XlvLdpNYIA0amdvxxhXf8HOzEKm/7iLwyXljXZ9pdoyDQQtTFBgAKf1jadTTN2V1QDCQ4J4fvIwyisNHaPDeG7KMMJDgrj/vBNYty+P/yxJrfOelXty+H5zOucP7kRAgDCyZxw/786m0mH4+9eb+XhFGmADQZ/ESMb3T6RLbDs+W72Pc59byJinvuerdQcIEOgS24780go6RoUS2IgrtCVGhTHzjtO4+XTbvPX4zI38Z3FqdV4npdSx82kfgYicB7yAXaHsDWPMUx7OuRJ4DLtC2RpjTO3lLNVROrVPPKseOZtAkerlMicN68wnK9N49IsNfLPxIMO6xtIpph3ZhWW8/dNukmLCuNPZAXtKzzhm/LyX1xbu4JX5OwgKEJLbt2Pprix+M6YnIsK4fgnM+HlP9Wd+tnof3eLCGdc3gf8sSSXJB803g7vEsNStpvLMnC18umofs+4cq4vWKHUcfBYIRCQQeBk4G0gDlonIF85VyarO6Qs8BIwxxuSIyLENL1F11B7xIyK8/ssU/v3jLj5ZmcaSnTur76ZP7hbL05cPJc6Z7398/0SCAoSnv95Cl9h2OIxhyrQlAJx5gv1fdEZ/GwgmDu3M3pwiVu3JpU9CJCd0slkSfXWfXumoOalse3oBC7ZmcLZzDWql1NHzZY3gFGC7MWYngIh8AEwCNrqdcyPwsjEmB8AYo8t6+VBYcCC3je/DbeP7UFbhILeojNCgwBpJ8gBiw0O44MROzFp3gEcuHkhIUAC/eXMZnWLCSHGOAjq9XwK/HN2dm8b1Yta6A6zak0vvxEhOSLKBIK/YN+333eLqzpd4bcEOhiTH0DFaO5GPhjGGtJxiusaF+7soys98WZ/uAux1e53m3OeuH9BPRBaJyBJnU1IdInKTiCwXkeUZGRk+Km7bEhIUQGJ0WJ0gUOX5ycPY8Pi5nDsoifH9E3nrNyOYecdp1Smiw4IDeXzSYJLbh3P+4E6EBAUwJDmmeiGe60Z190m5zx3Ukbn3nl4j/cTy1BzG/n0e2w7lV8+bUEc2Z8NBxj49j283HvJ3UZSf+bthNQjoC5wBXAW8LiKxtU8yxkwzxqQYY1ISEhKauIhtU0CA1MgRdEb/RDpE1p3pC3a8/9KHJnDhiZ2ICgtm598u4DdjevqkXCJCn8RIfjm6ZqApq3Rw9nML+cjZsa2OLDWrCIAb31nOhS/+0Ooz4ar6+TIQ7APcV31Pdu5zlwZ8YYwpN8bsArZiA4NqYdpHhFTPfQhoxNFC9blxbC+2/fV8Pr55NH/7xYl0jbM1hMe/3Mjpz8xjw/68Vls7KK2oJKug9Liv4958t2H/YTIa4ZqqZfJlIFgG9BWRniISAkwBvqh1zmfY2gAiEo9tKtrpwzKpVkJECA4MIKVHHFeP7Mbsu8bxxCWDSW7fjtSsIi588Ud++9YyPly2l9KK1rOOgTGGy19ZzPAn5x73PIr0/Jo//Huzi47reqrl8lkgMMZUALcDc4BNwIfGmA0i8riITHSeNgfIEpGNwDzgD8aY+qe/KlWPyNAgrhvVna/vHlc9gmjelgzu/2Qtd7y/ii/W7Gf9vpZfS1i9N5d1++zkvQ+X7T3C2Q2rEwhyNBC0VT6dR2CMmQXMqrXvEbdtA9zrfCjVKKZeYxf6uXPGKr7deIhvnA+Aswd2pFd8BOcOTmJQ5+ijXivB3zbsP1y9vcOZ6vvhz9YzYYBr6dQjmbXuAIEBQvrhmkuCbj1U0HgFVS2KJp1TrU7VHIpXrh0OQGZBKe8sTmXqvO38sC2Dbzce4rWFO0mICuWkrrEM6hzDiB7t6ZMYSWIzH4K65WA+UaFBdI8PZ39uMemHS/jPklSyCku9DgS3vrcSgOiwIOIjQ8gsKAPglfk7SOnentcW7mRocgx/unBg9XsOHS7h1QU7eOj8AX6fvGeMYUVqDruzirjs5C7HvX6G0kCg2oD4yFDuPbsf957dD2MMczYcYnt6Pqv35rEmLbe6tgDQISKEk7rF0icxim5x4XRp345e8REkt/ecCLCpbTmUT7+kKBIiQ9meUcCaNNtMtM7Z7DVl2hLG9Innzgl9mfzaYgZ0iuaxiYOq319Q6loB73BJBb8d05Ppi3ZV77v+bZvF9udd2dWBIKuglHOeW0hecTnnDkqqXg/DX95ZnMqjX2wAYECnKAZ1jvFreVoDDQSqTRERzhucBNgU2sYYMgvKWJuWy8b9h9maXsD6fXks2JpBeaWrPyE8JJBuceF0jQuna/twusW1o0v7cLrEtqNL+3bEtPM8H6Mx5ZeUs3pPLteN7o4xsHBbBqv35gCwN7uYFak5LN2VzdJd2Vwzslv19iMXDeSW91bQvUME5w6qOQP7ghOTmL5oF0OSY9iw/3CN3E3vLkkl/XAJ6/blVY8wyi0qq1OuSofBYcwxL0B0tH7akVm9vT29QANBI9BAoNo0ESEhKpQJAzoyYYDrR7LSYTh4uIS07CK2ZxSw7VABaTlFpGYV8uO2zBorsAFEhQXRJbYdnWPbkRQTRlJ0WPVzp5gwOsaEERUadFy1im83HqKs0sEFJyaxem8eRWWVzNucQXCgUF5peGne9upzpy10Db6bvmgXczbYWo97Cu8use0Y2jWWS0/uwq1n9KbCYTjv+R+qj//5s/V1ynDzuytZ8Icz6N4hgrVpufTrGMUt765gyc5sNj3hcT5oo9uTXczYvvH8tCOLbdqv0Sg0ECjlQWCA2Lv92HaMrNUUUlWL2JdbzL6cYvblFpGWY7cP5JWwem8u2YV175wjQgLp6ClIRIeRGB1Gh4gQ4iNDaRdStwO7vNLBGz/soldCBCd1bU9Juc25tPHAYS4e2pkv1+xn/pYMOseEkVVYxmtugeDJrzZVb//lS1eGl9+d3ovgwAD+eeWw6n1z7h7H5a/+RH6JqwkJ4MqUZD5cbifrnf7MfK4d1Y13l+zhqlO6MW+Lne1fWlHp8853Ywx7s4sY2TOOfTnFbE/XQNAYNBAodZSqahEJUaEM61pnIjwAJeWVpB8u5eDhEg7kFXPocAkH80o5eLiYg3klLNmRRXp+KRUeZvNGhATSITKUDpEhdIgIJSw4gE0HDrMjo5AXpgwjIEAYkuxqDhnXN561abmkZhUxunc86fkl/LAtk57xEXSICGF5ag5Dk2Po0r4ds9YdpGN0KF/fNY72ziSD7vonRTHjxlFc9K8f7bX7JbBwa0adc99dN6JsgwAADOpJREFUYjPPumeg3ZNVRI/4CJ82EeUUlVNQWkHXuHBO6BTFrHUHuXTqIi4a0pnfnuab2extgQYCpXwgLDiQbh3C6dah/oRuDochs7CUg3klZOSXklVQRmahfc4qKCWr0NY6issq6Bgdxu/P6c8FJ3YCICosmNjwYHKLyjn/xE6k55fyzJwtjO1r13n+YVsmye3b8ZsxPfjtW8sZ2asDN4ztyax1BxmaHOsxCFQZ3CWGdY+dQ1RYMCXllbzw3TZuOK0nry2wtYzzBycxe/3BOu978H/rWJGaw/s3jrQjsKLCKKtwEBwoNZrEHA5zzLPPqxZM6pMYSaXDwax1B1m5J5e1aXl0jQsnLDiA0/rE88qCHZw7KIneCZFHdX1jDLPXH6RjdNhxLbN6vBZuzSC7sIyJQzs3yUx9aWkTbFJSUszy5cuPfKJSrdy+3GKCAqQ66+re7CKS27ejwmF4YuZGrhvVnb4do1iXlkevhAgiQoNYv8/+YB5L5/b+3GIqHYafdmTywCfr+L9LT+TcQUkIcNIT39Y5/5Secazak0PXuHAmDe3CrswClu3OITY8mD9dMID2ESH0TYysTmTojWveWMKujEIW3j+eZbtzuOr1JfRJjKS80lGdO+kfVwzl9x+tIbl9O3584Eyvr22M4YmZm5i+aBftggNZ+qcJRIf5fhBAbR8t38sfPl4LwBOXDG60BI4issIYk+LxmAYCpdTRyC0q4+V527n7rH5EhNpGhRWpOSzZmcWMn/eQllPM0OSY6qGtDeka144HzxtAx+hQotsFV2ev9WTTgcOc/8IP/OHc/tw2vg8VlQ5e/G4b14zqToAID3yytno51SpL/ziB7zenExggXDE8ucHO+he/28Y/v91KSvf2LE/N4Xen9+Kh8wc0WP7Z6w6QX1LBkK4xnJAUfcS/90jyissZ/+x8esVHkF9SQWlFJfPuO6NRhi5rIFBKNYmC0go2HTjMSV1j+Xl3Nkt2ZnPPWX1ZsjObCoeDsX0TmLc5HcTWMJ6fu40Mt1QXPeMj6JMYiQDxUaEkRoXSITKUdWm5zFp3kMAA4fvfn15vJtwb31nOtxsP0TM+gl2ZhSRFh3HQOYP6zxcOoGN0GP2ToggODCBQhE6xYQQFCC/P286z32zlspOTeebyIdz30Rq+WneAZX8+i5zCMqbO20FQoPCHc/sTGx5CeaWDBz5Zy/9W2jyaIUEBzLzjtOpAVukwfLIijTVpuXSICOGioZ3rBLnMglL25xbTPymqupP9iZkbmb5oF1/efhqbDhzmDx+v5dNbT+WkbsffTKWBQCnVLJVVONiw385T2Hoon5WpuWzPKCBAILOgrHr0VWRoEOcM6sjt4/vQq4F2/+W7s7n81cV8dPNoPlu1j40HDnPOwCTeW5pKWk5xnfM7xdgRW2v25jJpWGf+eeUwAgOElXtyuHTqT9xyRm8+X7WPrMIySiscpHRvz7RfpvD4lxv4bPV+fjeuF8O7t+e+j9bQObYdn902hvJKB/d9tIY5Gw4REhRAeaUDY6B/xyhG9oojLiKEdWl5/Lg9k9IKBxEhgUy9djgJkaFMfOlHLh+ezFOXDeFwSTkpT87l6lO68djEQTz37VbOHtiRwV2Obd6EBgKlVItUVuEgq7CU9uEhhAV7NzS1vNJRZ+TSnqwi5m46RN+OkWQXluEwhtJyB1+s2f//7d17jBVnGcfx7w8otFxSWtg2pCBQLq1oEJUgFBqBXsTGqFGM9maDNCSGGpqgtkRbY/1L/wA1qZVGSVuL0lSLIq1pKRSSagW2LeVOu9RthQDL/SpQ6OMf8+56WJbbsrPHPfP7JCc7887L5H0Oc/bZeefMM2zd9x/uHdOfu0b2bZiCiQi+8tg/ePP9fXTt1IF5U0by/p4jTP39G0SABNNvGcx947Oq+Us27uBbT1Tz2cFV7DhwlJq6Qzww4XruvbE/Ow8d429rtvP86m1s2H6Ag0dP8JErOzP2uir69+zCU6+9x792HaZ9O1HVtRN//c4YqrplZzzffvp1VtbuYdrNg3noz2uZOm4A3/vc9c16L50IzMwu0J7Dx1mwaiujBvTkuvQI1tc272bR+h3cPOQqbhjQ85T+v1paw8yX3uaKLh352cShjDtD7adjJ07SsX27hqRz8OgHzHm1lr1HjjNpdD/69vjf41j/XrOLO3+zHIDRA3vw5KQRF3RxvZQTgZlZKzh24iSXtGvXol/5/N1rtdTuPsJ94wae9Wu/53K2ROD7CMzMWkged1bfPapfi++zsXI/s9jMzMrMicDMrOByTQSSJkjaJKlG0oNn6fdVSSGpyfkrMzPLT26JQFJ74FHg88AQ4HZJQ5ro1w2YBizPayxmZnZmeZ4RjABqIuLdiDgOzAO+1ES/nwA/BY42sc3MzHKWZyK4Bvh3yfqW1NZA0qeAPhHx/Nl2JGmKpGpJ1Tt37mz5kZqZFVjZLhZLagfMBKafq29EPB4RwyNieFVVVf6DMzMrkDwTwVagT8l679RWrxvwcWCppFpgJLDAF4zNzFpXbncWS+oAvA3cRJYAVgJ3RMS6M/RfCnw3Is5627CkncB7zRxWT2DXOXtVFsdcDI65GC4m5r4R0eSUSm53FkfECUn3AS8C7YE5EbFO0iNAdUQsaOZ+mz03JKn6TLdYVyrHXAyOuRjyijnXEhMR8QLwQqO2h8/Qd2yeYzEzs6b5zmIzs4IrWiJ4vNwDKAPHXAyOuRhyibnNlaE2M7OWVbQzAjMza8SJwMys4AqTCM63EmpbI2mOpDpJa0varpS0SNI76ecVqV2Sfpneg9WpxEebI6mPpFckrZe0TtK01F6xcUu6VNIKSW+lmH+c2vtLWp5ie0ZSx9TeKa3XpO39yjn+5pLUXtKbkham9YqOF0BSraQ1klZJqk5tuR7bhUgE51sJtY16ApjQqO1BYHFEDAIWp3XI4h+UXlOAx1ppjC3tBDA9IoaQ3ZE+Nf1/VnLcx4DxEfEJYBgwQdJIsoKNsyJiILAXmJz6Twb2pvZZqV9bNA3YULJe6fHWGxcRw0ruGcj32I6Iin8Bo4AXS9ZnADPKPa4WjK8fsLZkfRPQKy33Ajal5dnA7U31a8sv4C/ALUWJG+gMvAF8huwu0w6pveE4J7uRc1Ra7pD6qdxjv8A4e6dfeuOBhYAqOd6SuGuBno3acj22C3FGwHlUQq0wV0fEtrS8Hbg6LVfc+5CmAD5J9jyLio47TZOsAuqARcBmYF9EnEhdSuNqiDlt3w/0aN0RX7SfA98HPkzrPajseOsF8JKk1yVNSW25Htt+eH2Fi4iQVJHfEZbUFfgTcH9EHJDUsK0S446Ik8AwSd2B+cD1ZR5SbiR9AaiLiNcljS33eFrZmIjYKukqYJGkjaUb8zi2i3JGcK5KqJVmh6ReAOlnXWqvmPdB0iVkSWBuRDyXmis+boCI2Ae8QjY10j0VeIRT42qIOW2/HNjdykO9GKOBL6bKxPPIpod+QeXG2yAitqafdWQJfwQ5H9tFSQQrgUHpGwcdgW8AzSp610YsAO5Jy/eQzaHXt38zfdNgJLC/5HSzzVD2p/9vgQ0RMbNkU8XGLakqnQkg6TKyayIbyBLCxNStccz178VEYEmkSeS2ICJmRETviOhH9nldEhF3UqHx1pPURdnje5HUBbgVWEvex3a5L4y04gWY28jKYm8GflDu8bRgXH8AtgEfkM0PTiabG10MvAO8DFyZ+ors21ObgTXA8HKPv5kxjyGbR10NrEqv2yo5bmAo8GaKeS3wcGq/FlgB1ADPAp1S+6VpvSZtv7bcMVxE7GOBhUWIN8X3Vnqtq/9dlfex7RITZmYFV5SpITMzOwMnAjOzgnMiMDMrOCcCM7OCcyIwMys4JwKzViRpbH0lTbP/F04EZmYF50Rg1gRJd6X6/6skzU4F3w5JmpWeB7BYUlXqO0zSP1M9+PklteIHSno5PUPgDUkD0u67SvqjpI2S5qq0SJJZGTgRmDUi6aPA14HRETEMOAncCXQBqiPiY8Ay4EfpnzwFPBARQ8nu7qxvnws8GtkzBG4guwMcsmqp95M9G+Nasro6ZmXj6qNmp7sJ+DSwMv2xfhlZka8PgWdSn6eB5yRdDnSPiGWp/Ung2VQv5pqImA8QEUcB0v5WRMSWtL6K7HkSr+YfllnTnAjMTifgyYiYcUqj9FCjfs2tz3KsZPkk/hxamXlqyOx0i4GJqR58/fNi+5J9XuorX94BvBoR+4G9km5M7XcDyyLiILBF0pfTPjpJ6tyqUZidJ/8lYtZIRKyX9EOyp0S1I6vsOhU4DIxI2+rIriNAVhb41+kX/bvApNR+NzBb0iNpH19rxTDMzpurj5qdJ0mHIqJrucdh1tI8NWRmVnA+IzAzKzifEZiZFZwTgZlZwTkRmJkVnBOBmVnBORGYmRXcfwFuJxQkRe6uuQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "apW1sQ_2iMef",
        "colab_type": "code",
        "outputId": "c8ed50f7-8a13-48a8-ed51-2303c7fcfc8f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "net.plot_acc()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y9cpvOhiPbwl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_root = 'drive/My Drive/dl_noise_classification/data/'\n",
        "train_dir = 'train'\n",
        "val_dir = 'val'\n",
        "test_dir = 'test'\n",
        "class_names = ['awgn', 'bayer']\n",
        "\n",
        "train_dir = os.path.join(data_root, train_dir)\n",
        "val_dir = os.path.join(data_root, val_dir)\n",
        "test_dir = os.path.join(data_root, test_dir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5RdNqCUxPKUG",
        "colab_type": "code",
        "outputId": "411d2130-dead-4c28-d8fb-1666f9659555",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# МНОГО ПРОЦЕССОВ ЖРУТ ПАМЯТЬ ОЧЕНЬ МНОГО, при этом сильно не ускоряют\n",
        "train_transforms = transforms.Compose([\n",
        "    #transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
        "    transforms.Grayscale(num_output_channels=1),\n",
        "    #transforms.Resize((64, 64)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "val_transforms = transforms.Compose([\n",
        "    #transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
        "    transforms.Grayscale(num_output_channels=1),\n",
        "    #transforms.Resize((64, 64)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "\n",
        "train_dataset = datasets.ImageFolder(train_dir, train_transforms)\n",
        "val_dataset = datasets.ImageFolder(val_dir, val_transforms)\n",
        "#test_dataset = datasets.ImageFolder(test_dir, train_transforms)\n",
        "\n",
        "train_size = len(train_dataset)\n",
        "val_size = len(val_dataset)\n",
        "#test_size = len(test_dataset)\n",
        "\n",
        "all_train = torch.utils.data.DataLoader(\n",
        "    train_dataset, batch_size=train_size, shuffle=False, num_workers=batch_size)\n",
        "\n",
        "#train_dataloader = torch.utils.data.DataLoader(\n",
        "#    train_dataset, batch_size=batch_size, shuffle=True, num_workers=batch_size)\n",
        "\n",
        "#val_dataloader = torch.utils.data.DataLoader(\n",
        "#    val_dataset, batch_size=batch_size, shuffle=False, num_workers=batch_size)\n",
        "\n",
        "all_val = torch.utils.data.DataLoader(\n",
        "    val_dataset, batch_size=train_size, shuffle=False, num_workers=val_size)\n",
        "\n",
        "#all_test = torch.utils.data.DataLoader(\n",
        "#    test_dataset, batch_size=train_size, shuffle=False, num_workers=test_size)\n",
        "print(\"TRAIN_SIZE: {}\\n VAL_SIZE: {}\\n\".format(train_size, val_size))#, #test_size))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TRAIN_SIZE: 1200\n",
            " VAL_SIZE: 400\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hJj_d24c-VB7",
        "colab_type": "code",
        "outputId": "5b462e32-fe9e-47c4-a791-e92f57fa00ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "%%time\n",
        "#print('all val data loading ...')\n",
        "#val_data = next(iter(all_val))\n",
        "print('all train data loading ...')\n",
        "train_data = next(iter(all_train))\n",
        "#print('test data loading')\n",
        "#test_data = next(iter(all_test))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "all train data loading ...\n",
            "CPU times: user 521 ms, sys: 3.27 s, total: 3.79 s\n",
            "Wall time: 15min 18s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "08l_-OfjMz2W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "55bc39fa-ee71-4981-b8ad-d0401798f08b"
      },
      "source": [
        "%%time\n",
        "\n",
        "print(train_data[0].shape, train_data[1].shape)\n",
        "torch.save(train_data, 'drive/My Drive/dl_noise_classification/data/tensor_images64x64.pth')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1200, 1, 64, 64]) torch.Size([1200])\n",
            "CPU times: user 5.4 ms, sys: 9.04 ms, total: 14.4 ms\n",
            "Wall time: 45.9 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R4wLvSSouccT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5ZrPROoc_H3",
        "colab_type": "code",
        "outputId": "ebaa8807-4550-4269-9612-8e0e490f18cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "%%time\n",
        "\n",
        "print('all val data loading ...')\n",
        "val_data = next(iter(all_val))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "all val data loading ...\n",
            "CPU times: user 916 ms, sys: 10.5 s, total: 11.4 s\n",
            "Wall time: 5min 23s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7BBYEVfaQ_y4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(val_data, 'drive/My Drive/dl_noise_classification/data/tensor_images64x64_val.pth')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pWvqnsI-uzL9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "cc7e1e47-125a-4721-831c-d8e55ba418a4"
      },
      "source": [
        "%%time\n",
        "train_data = torch.load('drive/My Drive/dl_noise_classification/data/tensor_images64x64.pth')\n",
        "val_data = torch.load('drive/My Drive/dl_noise_classification/data/tensor_images64x64_val.pth')"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 6.69 ms, sys: 23.4 ms, total: 30.1 ms\n",
            "Wall time: 2 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_kCTpvvQ1mx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, y_train = train_data\n",
        "X_test, y_test = val_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LBQUcRo3Rfe2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        },
        "outputId": "80a3633e-8fce-466a-a863-0760c1d16c41"
      },
      "source": [
        "net.train_with_hist(train_data=(X_train, y_train),\n",
        "                    val_data=(X_test, y_test))"
      ],
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PCANet first stage...\n",
            "images shape torch.Size([1200, 1, 64, 64])\n",
            "patches_shape,  torch.Size([1200, 4096, 49])\n",
            "should be patches shape,  (1200, 4096, 49)\n",
            "filter_size 7\n",
            "pca fitting ...\n",
            "eigenvectors shape: (8, 49)\n",
            "I  torch.Size([1200, 8, 60, 60])\n",
            "PCANet second stage...\n",
            "images shape torch.Size([9600, 1, 60, 60])\n",
            "patches_shape,  torch.Size([9600, 3600, 49])\n",
            "should be patches shape,  (9600, 3600, 49)\n",
            "filter_size 7\n",
            "X_SHAPE  torch.Size([49, 34560000])\n",
            "56 56\n",
            "pca fitting ...\n",
            "eigenvectors shape: (8, 49)\n",
            "bin_II shape: torch.Size([1200, 8, 56, 56])\n",
            "dec_II shape: torch.Size([1200, 1, 56, 56])\n",
            "blocks_shape: torch.Size([1200, 1, 2, 2, 28, 28])\n",
            "final_features: torch.Size([1200, 512])\n",
            "Training classifier\n",
            "------------========== TRAIN =========--------------\n",
            "Accuracy: 1.0\n",
            "ROC-AUC: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "------------=======================--------------\n",
            "PCANet first stage...\n",
            "I  torch.Size([400, 8, 60, 60])\n",
            "PCANet second stage...\n",
            "bin_II shape: torch.Size([400, 8, 56, 56])\n",
            "dec_II shape: torch.Size([400, 1, 56, 56])\n",
            "blocks_shape: torch.Size([400, 1, 2, 2, 28, 28])\n",
            "final_features: torch.Size([400, 512])\n",
            "------------========== TEST =========--------------\n",
            "Accuracy: 0.51\n",
            "ROC-AUC: 0.51\n",
            "Precision: 0.5108695652173914\n",
            "Recall: 0.47\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uEqB1t96GI-O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8a24ab42-05af-4d0e-c556-016c66988bd8"
      },
      "source": [
        "net.fit(loss,\n",
        "        optimizer,\n",
        "        device,\n",
        "        train_data=(X_train, y_train),\n",
        "        test_data=(X_test, y_test),\n",
        "        num_epochs=500)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PCANet first stage...\n",
            "images shape torch.Size([1200, 1, 64, 64])\n",
            "patches_shape,  torch.Size([1200, 4096, 49])\n",
            "should be patches shape,  (1200, 4096, 49)\n",
            "filter_size 7\n",
            "pca fitting ...\n",
            "eigenvectors shape: (8, 49)\n",
            "I  torch.Size([1200, 8, 60, 60])\n",
            "PCANet second stage...\n",
            "images shape torch.Size([9600, 1, 60, 60])\n",
            "patches_shape,  torch.Size([9600, 3600, 49])\n",
            "should be patches shape,  (9600, 3600, 49)\n",
            "filter_size 7\n",
            "X_SHAPE  torch.Size([49, 34560000])\n",
            "56 56\n",
            "pca fitting ...\n",
            "eigenvectors shape: (8, 49)\n",
            "Epoch 0/499:\n",
            "train Loss: 0.8702 Acc: 0.5008\n",
            "\n",
            "val Loss: 1.0778 Acc: 0.5000\n",
            "\n",
            "Epoch 1/499:\n",
            "train Loss: 0.9170 Acc: 0.4942\n",
            "\n",
            "val Loss: 0.9752 Acc: 0.4950\n",
            "\n",
            "Epoch 2/499:\n",
            "train Loss: 0.8360 Acc: 0.4875\n",
            "\n",
            "val Loss: 0.8599 Acc: 0.5125\n",
            "\n",
            "Epoch 3/499:\n",
            "train Loss: 0.7769 Acc: 0.5058\n",
            "\n",
            "val Loss: 0.8325 Acc: 0.4950\n",
            "\n",
            "Epoch 4/499:\n",
            "train Loss: 0.7940 Acc: 0.4900\n",
            "\n",
            "val Loss: 0.8234 Acc: 0.4975\n",
            "\n",
            "Epoch 5/499:\n",
            "train Loss: 0.7793 Acc: 0.5150\n",
            "\n",
            "val Loss: 0.8144 Acc: 0.4800\n",
            "\n",
            "Epoch 6/499:\n",
            "train Loss: 0.7361 Acc: 0.4925\n",
            "\n",
            "val Loss: 0.8306 Acc: 0.5000\n",
            "\n",
            "Epoch 7/499:\n",
            "train Loss: 0.7245 Acc: 0.4975\n",
            "\n",
            "val Loss: 0.8516 Acc: 0.5100\n",
            "\n",
            "Epoch 8/499:\n",
            "train Loss: 0.7411 Acc: 0.4817\n",
            "\n",
            "val Loss: 0.8396 Acc: 0.5025\n",
            "\n",
            "Epoch 9/499:\n",
            "train Loss: 0.7375 Acc: 0.5017\n",
            "\n",
            "val Loss: 0.8053 Acc: 0.5000\n",
            "\n",
            "Epoch 10/499:\n",
            "train Loss: 0.7168 Acc: 0.4742\n",
            "\n",
            "val Loss: 0.7820 Acc: 0.4975\n",
            "\n",
            "Epoch 11/499:\n",
            "train Loss: 0.7109 Acc: 0.5000\n",
            "\n",
            "val Loss: 0.7780 Acc: 0.4950\n",
            "\n",
            "Epoch 12/499:\n",
            "train Loss: 0.7211 Acc: 0.5183\n",
            "\n",
            "val Loss: 0.7751 Acc: 0.4950\n",
            "\n",
            "Epoch 13/499:\n",
            "train Loss: 0.7220 Acc: 0.5133\n",
            "\n",
            "val Loss: 0.7672 Acc: 0.4825\n",
            "\n",
            "Epoch 14/499:\n",
            "train Loss: 0.7091 Acc: 0.4975\n",
            "\n",
            "val Loss: 0.7653 Acc: 0.4975\n",
            "\n",
            "Epoch 15/499:\n",
            "train Loss: 0.7006 Acc: 0.5258\n",
            "\n",
            "val Loss: 0.7725 Acc: 0.5125\n",
            "\n",
            "Epoch 16/499:\n",
            "train Loss: 0.7046 Acc: 0.5108\n",
            "\n",
            "val Loss: 0.7758 Acc: 0.5225\n",
            "\n",
            "Epoch 17/499:\n",
            "train Loss: 0.7078 Acc: 0.5183\n",
            "\n",
            "val Loss: 0.7674 Acc: 0.5250\n",
            "\n",
            "Epoch 18/499:\n",
            "train Loss: 0.7013 Acc: 0.5067\n",
            "\n",
            "val Loss: 0.7560 Acc: 0.5025\n",
            "\n",
            "Epoch 19/499:\n",
            "train Loss: 0.6942 Acc: 0.5283\n",
            "\n",
            "val Loss: 0.7512 Acc: 0.4900\n",
            "\n",
            "Epoch 20/499:\n",
            "train Loss: 0.6954 Acc: 0.5192\n",
            "\n",
            "val Loss: 0.7511 Acc: 0.5000\n",
            "\n",
            "Epoch 21/499:\n",
            "train Loss: 0.6989 Acc: 0.5075\n",
            "\n",
            "val Loss: 0.7501 Acc: 0.4950\n",
            "\n",
            "Epoch 22/499:\n",
            "train Loss: 0.6959 Acc: 0.5075\n",
            "\n",
            "val Loss: 0.7504 Acc: 0.4925\n",
            "\n",
            "Epoch 23/499:\n",
            "train Loss: 0.6901 Acc: 0.5267\n",
            "\n",
            "val Loss: 0.7557 Acc: 0.5225\n",
            "\n",
            "Epoch 24/499:\n",
            "train Loss: 0.6889 Acc: 0.5608\n",
            "\n",
            "val Loss: 0.7618 Acc: 0.5000\n",
            "\n",
            "Epoch 25/499:\n",
            "train Loss: 0.6906 Acc: 0.5375\n",
            "\n",
            "val Loss: 0.7617 Acc: 0.5075\n",
            "\n",
            "Epoch 26/499:\n",
            "train Loss: 0.6887 Acc: 0.5350\n",
            "\n",
            "val Loss: 0.7565 Acc: 0.5200\n",
            "\n",
            "Epoch 27/499:\n",
            "train Loss: 0.6840 Acc: 0.5500\n",
            "\n",
            "val Loss: 0.7524 Acc: 0.4975\n",
            "\n",
            "Epoch 28/499:\n",
            "train Loss: 0.6822 Acc: 0.5392\n",
            "\n",
            "val Loss: 0.7519 Acc: 0.4925\n",
            "\n",
            "Epoch 29/499:\n",
            "train Loss: 0.6832 Acc: 0.5475\n",
            "\n",
            "val Loss: 0.7526 Acc: 0.4925\n",
            "\n",
            "Epoch 30/499:\n",
            "train Loss: 0.6822 Acc: 0.5508\n",
            "\n",
            "val Loss: 0.7541 Acc: 0.4975\n",
            "\n",
            "Epoch 31/499:\n",
            "train Loss: 0.6790 Acc: 0.5492\n",
            "\n",
            "val Loss: 0.7579 Acc: 0.5075\n",
            "\n",
            "Epoch 32/499:\n",
            "train Loss: 0.6776 Acc: 0.5517\n",
            "\n",
            "val Loss: 0.7624 Acc: 0.5125\n",
            "\n",
            "Epoch 33/499:\n",
            "train Loss: 0.6780 Acc: 0.5383\n",
            "\n",
            "val Loss: 0.7634 Acc: 0.5050\n",
            "\n",
            "Epoch 34/499:\n",
            "train Loss: 0.6771 Acc: 0.5483\n",
            "\n",
            "val Loss: 0.7609 Acc: 0.5000\n",
            "\n",
            "Epoch 35/499:\n",
            "train Loss: 0.6744 Acc: 0.5475\n",
            "\n",
            "val Loss: 0.7583 Acc: 0.4950\n",
            "\n",
            "Epoch 36/499:\n",
            "train Loss: 0.6729 Acc: 0.5892\n",
            "\n",
            "val Loss: 0.7577 Acc: 0.4950\n",
            "\n",
            "Epoch 37/499:\n",
            "train Loss: 0.6726 Acc: 0.6083\n",
            "\n",
            "val Loss: 0.7583 Acc: 0.4925\n",
            "\n",
            "Epoch 38/499:\n",
            "train Loss: 0.6713 Acc: 0.6108\n",
            "\n",
            "val Loss: 0.7602 Acc: 0.4975\n",
            "\n",
            "Epoch 39/499:\n",
            "train Loss: 0.6691 Acc: 0.6108\n",
            "\n",
            "val Loss: 0.7634 Acc: 0.4825\n",
            "\n",
            "Epoch 40/499:\n",
            "train Loss: 0.6679 Acc: 0.6525\n",
            "\n",
            "val Loss: 0.7663 Acc: 0.4825\n",
            "\n",
            "Epoch 41/499:\n",
            "train Loss: 0.6675 Acc: 0.6392\n",
            "\n",
            "val Loss: 0.7665 Acc: 0.4775\n",
            "\n",
            "Epoch 42/499:\n",
            "train Loss: 0.6663 Acc: 0.6600\n",
            "\n",
            "val Loss: 0.7648 Acc: 0.4950\n",
            "\n",
            "Epoch 43/499:\n",
            "train Loss: 0.6646 Acc: 0.6675\n",
            "\n",
            "val Loss: 0.7637 Acc: 0.5000\n",
            "\n",
            "Epoch 44/499:\n",
            "train Loss: 0.6637 Acc: 0.6542\n",
            "\n",
            "val Loss: 0.7639 Acc: 0.5000\n",
            "\n",
            "Epoch 45/499:\n",
            "train Loss: 0.6631 Acc: 0.6533\n",
            "\n",
            "val Loss: 0.7652 Acc: 0.5000\n",
            "\n",
            "Epoch 46/499:\n",
            "train Loss: 0.6616 Acc: 0.6692\n",
            "\n",
            "val Loss: 0.7673 Acc: 0.5025\n",
            "\n",
            "Epoch 47/499:\n",
            "train Loss: 0.6601 Acc: 0.7092\n",
            "\n",
            "val Loss: 0.7697 Acc: 0.4900\n",
            "\n",
            "Epoch 48/499:\n",
            "train Loss: 0.6592 Acc: 0.6908\n",
            "\n",
            "val Loss: 0.7710 Acc: 0.4900\n",
            "\n",
            "Epoch 49/499:\n",
            "train Loss: 0.6582 Acc: 0.6908\n",
            "\n",
            "val Loss: 0.7710 Acc: 0.4875\n",
            "\n",
            "Epoch 50/499:\n",
            "train Loss: 0.6567 Acc: 0.7292\n",
            "\n",
            "val Loss: 0.7709 Acc: 0.5025\n",
            "\n",
            "Epoch 51/499:\n",
            "train Loss: 0.6554 Acc: 0.7358\n",
            "\n",
            "val Loss: 0.7717 Acc: 0.5075\n",
            "\n",
            "Epoch 52/499:\n",
            "train Loss: 0.6545 Acc: 0.7125\n",
            "\n",
            "val Loss: 0.7731 Acc: 0.5050\n",
            "\n",
            "Epoch 53/499:\n",
            "train Loss: 0.6534 Acc: 0.7267\n",
            "\n",
            "val Loss: 0.7752 Acc: 0.5000\n",
            "\n",
            "Epoch 54/499:\n",
            "train Loss: 0.6520 Acc: 0.7392\n",
            "\n",
            "val Loss: 0.7776 Acc: 0.4975\n",
            "\n",
            "Epoch 55/499:\n",
            "train Loss: 0.6510 Acc: 0.7433\n",
            "\n",
            "val Loss: 0.7797 Acc: 0.4975\n",
            "\n",
            "Epoch 56/499:\n",
            "train Loss: 0.6499 Acc: 0.7425\n",
            "\n",
            "val Loss: 0.7812 Acc: 0.4950\n",
            "\n",
            "Epoch 57/499:\n",
            "train Loss: 0.6486 Acc: 0.7508\n",
            "\n",
            "val Loss: 0.7826 Acc: 0.4925\n",
            "\n",
            "Epoch 58/499:\n",
            "train Loss: 0.6474 Acc: 0.7550\n",
            "\n",
            "val Loss: 0.7845 Acc: 0.5025\n",
            "\n",
            "Epoch 59/499:\n",
            "train Loss: 0.6463 Acc: 0.7450\n",
            "\n",
            "val Loss: 0.7869 Acc: 0.4925\n",
            "\n",
            "Epoch 60/499:\n",
            "train Loss: 0.6451 Acc: 0.7500\n",
            "\n",
            "val Loss: 0.7897 Acc: 0.4950\n",
            "\n",
            "Epoch 61/499:\n",
            "train Loss: 0.6438 Acc: 0.7658\n",
            "\n",
            "val Loss: 0.7928 Acc: 0.5000\n",
            "\n",
            "Epoch 62/499:\n",
            "train Loss: 0.6427 Acc: 0.7850\n",
            "\n",
            "val Loss: 0.7957 Acc: 0.4975\n",
            "\n",
            "Epoch 63/499:\n",
            "train Loss: 0.6416 Acc: 0.7883\n",
            "\n",
            "val Loss: 0.7982 Acc: 0.5025\n",
            "\n",
            "Epoch 64/499:\n",
            "train Loss: 0.6403 Acc: 0.7900\n",
            "\n",
            "val Loss: 0.8007 Acc: 0.4975\n",
            "\n",
            "Epoch 65/499:\n",
            "train Loss: 0.6391 Acc: 0.7933\n",
            "\n",
            "val Loss: 0.8034 Acc: 0.5000\n",
            "\n",
            "Epoch 66/499:\n",
            "train Loss: 0.6380 Acc: 0.7833\n",
            "\n",
            "val Loss: 0.8066 Acc: 0.4975\n",
            "\n",
            "Epoch 67/499:\n",
            "train Loss: 0.6368 Acc: 0.7900\n",
            "\n",
            "val Loss: 0.8100 Acc: 0.4950\n",
            "\n",
            "Epoch 68/499:\n",
            "train Loss: 0.6356 Acc: 0.8067\n",
            "\n",
            "val Loss: 0.8136 Acc: 0.4975\n",
            "\n",
            "Epoch 69/499:\n",
            "train Loss: 0.6344 Acc: 0.8100\n",
            "\n",
            "val Loss: 0.8170 Acc: 0.4975\n",
            "\n",
            "Epoch 70/499:\n",
            "train Loss: 0.6333 Acc: 0.8150\n",
            "\n",
            "val Loss: 0.8202 Acc: 0.4950\n",
            "\n",
            "Epoch 71/499:\n",
            "train Loss: 0.6320 Acc: 0.8150\n",
            "\n",
            "val Loss: 0.8235 Acc: 0.4950\n",
            "\n",
            "Epoch 72/499:\n",
            "train Loss: 0.6308 Acc: 0.8117\n",
            "\n",
            "val Loss: 0.8271 Acc: 0.4950\n",
            "\n",
            "Epoch 73/499:\n",
            "train Loss: 0.6297 Acc: 0.8117\n",
            "\n",
            "val Loss: 0.8310 Acc: 0.4975\n",
            "\n",
            "Epoch 74/499:\n",
            "train Loss: 0.6284 Acc: 0.8208\n",
            "\n",
            "val Loss: 0.8351 Acc: 0.5000\n",
            "\n",
            "Epoch 75/499:\n",
            "train Loss: 0.6272 Acc: 0.8267\n",
            "\n",
            "val Loss: 0.8392 Acc: 0.5000\n",
            "\n",
            "Epoch 76/499:\n",
            "train Loss: 0.6261 Acc: 0.8375\n",
            "\n",
            "val Loss: 0.8432 Acc: 0.5000\n",
            "\n",
            "Epoch 77/499:\n",
            "train Loss: 0.6248 Acc: 0.8383\n",
            "\n",
            "val Loss: 0.8472 Acc: 0.5025\n",
            "\n",
            "Epoch 78/499:\n",
            "train Loss: 0.6236 Acc: 0.8367\n",
            "\n",
            "val Loss: 0.8513 Acc: 0.5025\n",
            "\n",
            "Epoch 79/499:\n",
            "train Loss: 0.6224 Acc: 0.8317\n",
            "\n",
            "val Loss: 0.8556 Acc: 0.5000\n",
            "\n",
            "Epoch 80/499:\n",
            "train Loss: 0.6212 Acc: 0.8358\n",
            "\n",
            "val Loss: 0.8600 Acc: 0.4975\n",
            "\n",
            "Epoch 81/499:\n",
            "train Loss: 0.6200 Acc: 0.8400\n",
            "\n",
            "val Loss: 0.8645 Acc: 0.4900\n",
            "\n",
            "Epoch 82/499:\n",
            "train Loss: 0.6188 Acc: 0.8450\n",
            "\n",
            "val Loss: 0.8689 Acc: 0.4900\n",
            "\n",
            "Epoch 83/499:\n",
            "train Loss: 0.6176 Acc: 0.8458\n",
            "\n",
            "val Loss: 0.8732 Acc: 0.4875\n",
            "\n",
            "Epoch 84/499:\n",
            "train Loss: 0.6164 Acc: 0.8450\n",
            "\n",
            "val Loss: 0.8776 Acc: 0.4950\n",
            "\n",
            "Epoch 85/499:\n",
            "train Loss: 0.6152 Acc: 0.8450\n",
            "\n",
            "val Loss: 0.8820 Acc: 0.4950\n",
            "\n",
            "Epoch 86/499:\n",
            "train Loss: 0.6140 Acc: 0.8500\n",
            "\n",
            "val Loss: 0.8867 Acc: 0.5000\n",
            "\n",
            "Epoch 87/499:\n",
            "train Loss: 0.6128 Acc: 0.8525\n",
            "\n",
            "val Loss: 0.8914 Acc: 0.4950\n",
            "\n",
            "Epoch 88/499:\n",
            "train Loss: 0.6116 Acc: 0.8558\n",
            "\n",
            "val Loss: 0.8962 Acc: 0.4950\n",
            "\n",
            "Epoch 89/499:\n",
            "train Loss: 0.6104 Acc: 0.8583\n",
            "\n",
            "val Loss: 0.9009 Acc: 0.4925\n",
            "\n",
            "Epoch 90/499:\n",
            "train Loss: 0.6092 Acc: 0.8633\n",
            "\n",
            "val Loss: 0.9056 Acc: 0.4950\n",
            "\n",
            "Epoch 91/499:\n",
            "train Loss: 0.6080 Acc: 0.8600\n",
            "\n",
            "val Loss: 0.9105 Acc: 0.4950\n",
            "\n",
            "Epoch 92/499:\n",
            "train Loss: 0.6068 Acc: 0.8575\n",
            "\n",
            "val Loss: 0.9156 Acc: 0.4950\n",
            "\n",
            "Epoch 93/499:\n",
            "train Loss: 0.6055 Acc: 0.8617\n",
            "\n",
            "val Loss: 0.9209 Acc: 0.4925\n",
            "\n",
            "Epoch 94/499:\n",
            "train Loss: 0.6043 Acc: 0.8658\n",
            "\n",
            "val Loss: 0.9262 Acc: 0.4950\n",
            "\n",
            "Epoch 95/499:\n",
            "train Loss: 0.6031 Acc: 0.8692\n",
            "\n",
            "val Loss: 0.9315 Acc: 0.4950\n",
            "\n",
            "Epoch 96/499:\n",
            "train Loss: 0.6019 Acc: 0.8683\n",
            "\n",
            "val Loss: 0.9369 Acc: 0.4950\n",
            "\n",
            "Epoch 97/499:\n",
            "train Loss: 0.6007 Acc: 0.8650\n",
            "\n",
            "val Loss: 0.9423 Acc: 0.4950\n",
            "\n",
            "Epoch 98/499:\n",
            "train Loss: 0.5995 Acc: 0.8617\n",
            "\n",
            "val Loss: 0.9479 Acc: 0.4950\n",
            "\n",
            "Epoch 99/499:\n",
            "train Loss: 0.5983 Acc: 0.8633\n",
            "\n",
            "val Loss: 0.9537 Acc: 0.4950\n",
            "\n",
            "Epoch 100/499:\n",
            "train Loss: 0.5971 Acc: 0.8675\n",
            "\n",
            "val Loss: 0.9595 Acc: 0.4950\n",
            "\n",
            "Epoch 101/499:\n",
            "train Loss: 0.5959 Acc: 0.8742\n",
            "\n",
            "val Loss: 0.9653 Acc: 0.4950\n",
            "\n",
            "Epoch 102/499:\n",
            "train Loss: 0.5947 Acc: 0.8725\n",
            "\n",
            "val Loss: 0.9710 Acc: 0.4950\n",
            "\n",
            "Epoch 103/499:\n",
            "train Loss: 0.5935 Acc: 0.8700\n",
            "\n",
            "val Loss: 0.9769 Acc: 0.4950\n",
            "\n",
            "Epoch 104/499:\n",
            "train Loss: 0.5923 Acc: 0.8692\n",
            "\n",
            "val Loss: 0.9828 Acc: 0.4950\n",
            "\n",
            "Epoch 105/499:\n",
            "train Loss: 0.5911 Acc: 0.8708\n",
            "\n",
            "val Loss: 0.9889 Acc: 0.4950\n",
            "\n",
            "Epoch 106/499:\n",
            "train Loss: 0.5899 Acc: 0.8733\n",
            "\n",
            "val Loss: 0.9951 Acc: 0.4950\n",
            "\n",
            "Epoch 107/499:\n",
            "train Loss: 0.5887 Acc: 0.8767\n",
            "\n",
            "val Loss: 1.0012 Acc: 0.4950\n",
            "\n",
            "Epoch 108/499:\n",
            "train Loss: 0.5876 Acc: 0.8767\n",
            "\n",
            "val Loss: 1.0073 Acc: 0.4950\n",
            "\n",
            "Epoch 109/499:\n",
            "train Loss: 0.5864 Acc: 0.8758\n",
            "\n",
            "val Loss: 1.0135 Acc: 0.4950\n",
            "\n",
            "Epoch 110/499:\n",
            "train Loss: 0.5852 Acc: 0.8783\n",
            "\n",
            "val Loss: 1.0198 Acc: 0.4950\n",
            "\n",
            "Epoch 111/499:\n",
            "train Loss: 0.5840 Acc: 0.8783\n",
            "\n",
            "val Loss: 1.0262 Acc: 0.4950\n",
            "\n",
            "Epoch 112/499:\n",
            "train Loss: 0.5828 Acc: 0.8783\n",
            "\n",
            "val Loss: 1.0327 Acc: 0.4950\n",
            "\n",
            "Epoch 113/499:\n",
            "train Loss: 0.5816 Acc: 0.8783\n",
            "\n",
            "val Loss: 1.0391 Acc: 0.4950\n",
            "\n",
            "Epoch 114/499:\n",
            "train Loss: 0.5804 Acc: 0.8792\n",
            "\n",
            "val Loss: 1.0455 Acc: 0.4950\n",
            "\n",
            "Epoch 115/499:\n",
            "train Loss: 0.5793 Acc: 0.8800\n",
            "\n",
            "val Loss: 1.0520 Acc: 0.4950\n",
            "\n",
            "Epoch 116/499:\n",
            "train Loss: 0.5781 Acc: 0.8817\n",
            "\n",
            "val Loss: 1.0585 Acc: 0.4950\n",
            "\n",
            "Epoch 117/499:\n",
            "train Loss: 0.5769 Acc: 0.8825\n",
            "\n",
            "val Loss: 1.0652 Acc: 0.4950\n",
            "\n",
            "Epoch 118/499:\n",
            "train Loss: 0.5757 Acc: 0.8825\n",
            "\n",
            "val Loss: 1.0718 Acc: 0.4950\n",
            "\n",
            "Epoch 119/499:\n",
            "train Loss: 0.5746 Acc: 0.8842\n",
            "\n",
            "val Loss: 1.0785 Acc: 0.4950\n",
            "\n",
            "Epoch 120/499:\n",
            "train Loss: 0.5734 Acc: 0.8867\n",
            "\n",
            "val Loss: 1.0851 Acc: 0.4950\n",
            "\n",
            "Epoch 121/499:\n",
            "train Loss: 0.5722 Acc: 0.8850\n",
            "\n",
            "val Loss: 1.0918 Acc: 0.4950\n",
            "\n",
            "Epoch 122/499:\n",
            "train Loss: 0.5711 Acc: 0.8867\n",
            "\n",
            "val Loss: 1.0986 Acc: 0.4950\n",
            "\n",
            "Epoch 123/499:\n",
            "train Loss: 0.5699 Acc: 0.8883\n",
            "\n",
            "val Loss: 1.1055 Acc: 0.4950\n",
            "\n",
            "Epoch 124/499:\n",
            "train Loss: 0.5687 Acc: 0.8883\n",
            "\n",
            "val Loss: 1.1124 Acc: 0.4950\n",
            "\n",
            "Epoch 125/499:\n",
            "train Loss: 0.5676 Acc: 0.8883\n",
            "\n",
            "val Loss: 1.1193 Acc: 0.4950\n",
            "\n",
            "Epoch 126/499:\n",
            "train Loss: 0.5664 Acc: 0.8875\n",
            "\n",
            "val Loss: 1.1262 Acc: 0.4950\n",
            "\n",
            "Epoch 127/499:\n",
            "train Loss: 0.5653 Acc: 0.8875\n",
            "\n",
            "val Loss: 1.1332 Acc: 0.4925\n",
            "\n",
            "Epoch 128/499:\n",
            "train Loss: 0.5641 Acc: 0.8883\n",
            "\n",
            "val Loss: 1.1403 Acc: 0.4925\n",
            "\n",
            "Epoch 129/499:\n",
            "train Loss: 0.5630 Acc: 0.8883\n",
            "\n",
            "val Loss: 1.1474 Acc: 0.4900\n",
            "\n",
            "Epoch 130/499:\n",
            "train Loss: 0.5618 Acc: 0.8883\n",
            "\n",
            "val Loss: 1.1546 Acc: 0.4900\n",
            "\n",
            "Epoch 131/499:\n",
            "train Loss: 0.5607 Acc: 0.8900\n",
            "\n",
            "val Loss: 1.1617 Acc: 0.4900\n",
            "\n",
            "Epoch 132/499:\n",
            "train Loss: 0.5595 Acc: 0.8908\n",
            "\n",
            "val Loss: 1.1689 Acc: 0.4900\n",
            "\n",
            "Epoch 133/499:\n",
            "train Loss: 0.5584 Acc: 0.8908\n",
            "\n",
            "val Loss: 1.1762 Acc: 0.4900\n",
            "\n",
            "Epoch 134/499:\n",
            "train Loss: 0.5572 Acc: 0.8908\n",
            "\n",
            "val Loss: 1.1835 Acc: 0.4900\n",
            "\n",
            "Epoch 135/499:\n",
            "train Loss: 0.5561 Acc: 0.8908\n",
            "\n",
            "val Loss: 1.1908 Acc: 0.4900\n",
            "\n",
            "Epoch 136/499:\n",
            "train Loss: 0.5550 Acc: 0.8908\n",
            "\n",
            "val Loss: 1.1981 Acc: 0.4900\n",
            "\n",
            "Epoch 137/499:\n",
            "train Loss: 0.5538 Acc: 0.8908\n",
            "\n",
            "val Loss: 1.2054 Acc: 0.4900\n",
            "\n",
            "Epoch 138/499:\n",
            "train Loss: 0.5527 Acc: 0.8917\n",
            "\n",
            "val Loss: 1.2128 Acc: 0.4900\n",
            "\n",
            "Epoch 139/499:\n",
            "train Loss: 0.5516 Acc: 0.8917\n",
            "\n",
            "val Loss: 1.2202 Acc: 0.4900\n",
            "\n",
            "Epoch 140/499:\n",
            "train Loss: 0.5505 Acc: 0.8925\n",
            "\n",
            "val Loss: 1.2277 Acc: 0.4900\n",
            "\n",
            "Epoch 141/499:\n",
            "train Loss: 0.5494 Acc: 0.8942\n",
            "\n",
            "val Loss: 1.2351 Acc: 0.4900\n",
            "\n",
            "Epoch 142/499:\n",
            "train Loss: 0.5482 Acc: 0.8942\n",
            "\n",
            "val Loss: 1.2426 Acc: 0.4900\n",
            "\n",
            "Epoch 143/499:\n",
            "train Loss: 0.5471 Acc: 0.8942\n",
            "\n",
            "val Loss: 1.2501 Acc: 0.4900\n",
            "\n",
            "Epoch 144/499:\n",
            "train Loss: 0.5460 Acc: 0.8942\n",
            "\n",
            "val Loss: 1.2576 Acc: 0.4900\n",
            "\n",
            "Epoch 145/499:\n",
            "train Loss: 0.5449 Acc: 0.8942\n",
            "\n",
            "val Loss: 1.2652 Acc: 0.4900\n",
            "\n",
            "Epoch 146/499:\n",
            "train Loss: 0.5438 Acc: 0.8950\n",
            "\n",
            "val Loss: 1.2728 Acc: 0.4900\n",
            "\n",
            "Epoch 147/499:\n",
            "train Loss: 0.5427 Acc: 0.8967\n",
            "\n",
            "val Loss: 1.2804 Acc: 0.4900\n",
            "\n",
            "Epoch 148/499:\n",
            "train Loss: 0.5416 Acc: 0.8975\n",
            "\n",
            "val Loss: 1.2880 Acc: 0.4900\n",
            "\n",
            "Epoch 149/499:\n",
            "train Loss: 0.5405 Acc: 0.8975\n",
            "\n",
            "val Loss: 1.2957 Acc: 0.4900\n",
            "\n",
            "Epoch 150/499:\n",
            "train Loss: 0.5394 Acc: 0.8975\n",
            "\n",
            "val Loss: 1.3033 Acc: 0.4925\n",
            "\n",
            "Epoch 151/499:\n",
            "train Loss: 0.5383 Acc: 0.8983\n",
            "\n",
            "val Loss: 1.3110 Acc: 0.4900\n",
            "\n",
            "Epoch 152/499:\n",
            "train Loss: 0.5372 Acc: 0.8983\n",
            "\n",
            "val Loss: 1.3188 Acc: 0.4900\n",
            "\n",
            "Epoch 153/499:\n",
            "train Loss: 0.5361 Acc: 0.8992\n",
            "\n",
            "val Loss: 1.3265 Acc: 0.4900\n",
            "\n",
            "Epoch 154/499:\n",
            "train Loss: 0.5351 Acc: 0.9000\n",
            "\n",
            "val Loss: 1.3342 Acc: 0.4900\n",
            "\n",
            "Epoch 155/499:\n",
            "train Loss: 0.5340 Acc: 0.9000\n",
            "\n",
            "val Loss: 1.3420 Acc: 0.4900\n",
            "\n",
            "Epoch 156/499:\n",
            "train Loss: 0.5329 Acc: 0.9008\n",
            "\n",
            "val Loss: 1.3498 Acc: 0.4875\n",
            "\n",
            "Epoch 157/499:\n",
            "train Loss: 0.5318 Acc: 0.9000\n",
            "\n",
            "val Loss: 1.3576 Acc: 0.4875\n",
            "\n",
            "Epoch 158/499:\n",
            "train Loss: 0.5308 Acc: 0.9000\n",
            "\n",
            "val Loss: 1.3654 Acc: 0.4875\n",
            "\n",
            "Epoch 159/499:\n",
            "train Loss: 0.5297 Acc: 0.9008\n",
            "\n",
            "val Loss: 1.3733 Acc: 0.4875\n",
            "\n",
            "Epoch 160/499:\n",
            "train Loss: 0.5286 Acc: 0.9008\n",
            "\n",
            "val Loss: 1.3811 Acc: 0.4875\n",
            "\n",
            "Epoch 161/499:\n",
            "train Loss: 0.5276 Acc: 0.9008\n",
            "\n",
            "val Loss: 1.3890 Acc: 0.4875\n",
            "\n",
            "Epoch 162/499:\n",
            "train Loss: 0.5265 Acc: 0.9000\n",
            "\n",
            "val Loss: 1.3969 Acc: 0.4875\n",
            "\n",
            "Epoch 163/499:\n",
            "train Loss: 0.5254 Acc: 0.9000\n",
            "\n",
            "val Loss: 1.4048 Acc: 0.4875\n",
            "\n",
            "Epoch 164/499:\n",
            "train Loss: 0.5244 Acc: 0.9000\n",
            "\n",
            "val Loss: 1.4127 Acc: 0.4875\n",
            "\n",
            "Epoch 165/499:\n",
            "train Loss: 0.5233 Acc: 0.9000\n",
            "\n",
            "val Loss: 1.4206 Acc: 0.4875\n",
            "\n",
            "Epoch 166/499:\n",
            "train Loss: 0.5223 Acc: 0.8992\n",
            "\n",
            "val Loss: 1.4286 Acc: 0.4875\n",
            "\n",
            "Epoch 167/499:\n",
            "train Loss: 0.5212 Acc: 0.8983\n",
            "\n",
            "val Loss: 1.4365 Acc: 0.4875\n",
            "\n",
            "Epoch 168/499:\n",
            "train Loss: 0.5202 Acc: 0.8983\n",
            "\n",
            "val Loss: 1.4445 Acc: 0.4875\n",
            "\n",
            "Epoch 169/499:\n",
            "train Loss: 0.5192 Acc: 0.8983\n",
            "\n",
            "val Loss: 1.4524 Acc: 0.4875\n",
            "\n",
            "Epoch 170/499:\n",
            "train Loss: 0.5181 Acc: 0.8983\n",
            "\n",
            "val Loss: 1.4604 Acc: 0.4875\n",
            "\n",
            "Epoch 171/499:\n",
            "train Loss: 0.5171 Acc: 0.8983\n",
            "\n",
            "val Loss: 1.4684 Acc: 0.4875\n",
            "\n",
            "Epoch 172/499:\n",
            "train Loss: 0.5161 Acc: 0.8992\n",
            "\n",
            "val Loss: 1.4764 Acc: 0.4875\n",
            "\n",
            "Epoch 173/499:\n",
            "train Loss: 0.5151 Acc: 0.9000\n",
            "\n",
            "val Loss: 1.4844 Acc: 0.4875\n",
            "\n",
            "Epoch 174/499:\n",
            "train Loss: 0.5140 Acc: 0.8992\n",
            "\n",
            "val Loss: 1.4924 Acc: 0.4875\n",
            "\n",
            "Epoch 175/499:\n",
            "train Loss: 0.5130 Acc: 0.8992\n",
            "\n",
            "val Loss: 1.5004 Acc: 0.4875\n",
            "\n",
            "Epoch 176/499:\n",
            "train Loss: 0.5120 Acc: 0.9000\n",
            "\n",
            "val Loss: 1.5085 Acc: 0.4850\n",
            "\n",
            "Epoch 177/499:\n",
            "train Loss: 0.5110 Acc: 0.9000\n",
            "\n",
            "val Loss: 1.5165 Acc: 0.4850\n",
            "\n",
            "Epoch 178/499:\n",
            "train Loss: 0.5100 Acc: 0.9000\n",
            "\n",
            "val Loss: 1.5246 Acc: 0.4850\n",
            "\n",
            "Epoch 179/499:\n",
            "train Loss: 0.5090 Acc: 0.9000\n",
            "\n",
            "val Loss: 1.5326 Acc: 0.4850\n",
            "\n",
            "Epoch 180/499:\n",
            "train Loss: 0.5080 Acc: 0.9000\n",
            "\n",
            "val Loss: 1.5407 Acc: 0.4850\n",
            "\n",
            "Epoch 181/499:\n",
            "train Loss: 0.5070 Acc: 0.9000\n",
            "\n",
            "val Loss: 1.5487 Acc: 0.4850\n",
            "\n",
            "Epoch 182/499:\n",
            "train Loss: 0.5060 Acc: 0.9000\n",
            "\n",
            "val Loss: 1.5568 Acc: 0.4850\n",
            "\n",
            "Epoch 183/499:\n",
            "train Loss: 0.5050 Acc: 0.9000\n",
            "\n",
            "val Loss: 1.5649 Acc: 0.4850\n",
            "\n",
            "Epoch 184/499:\n",
            "train Loss: 0.5040 Acc: 0.9000\n",
            "\n",
            "val Loss: 1.5730 Acc: 0.4850\n",
            "\n",
            "Epoch 185/499:\n",
            "train Loss: 0.5030 Acc: 0.9008\n",
            "\n",
            "val Loss: 1.5810 Acc: 0.4850\n",
            "\n",
            "Epoch 186/499:\n",
            "train Loss: 0.5020 Acc: 0.9008\n",
            "\n",
            "val Loss: 1.5891 Acc: 0.4850\n",
            "\n",
            "Epoch 187/499:\n",
            "train Loss: 0.5010 Acc: 0.9008\n",
            "\n",
            "val Loss: 1.5972 Acc: 0.4850\n",
            "\n",
            "Epoch 188/499:\n",
            "train Loss: 0.5000 Acc: 0.9008\n",
            "\n",
            "val Loss: 1.6053 Acc: 0.4850\n",
            "\n",
            "Epoch 189/499:\n",
            "train Loss: 0.4991 Acc: 0.9008\n",
            "\n",
            "val Loss: 1.6134 Acc: 0.4850\n",
            "\n",
            "Epoch 190/499:\n",
            "train Loss: 0.4981 Acc: 0.9008\n",
            "\n",
            "val Loss: 1.6215 Acc: 0.4825\n",
            "\n",
            "Epoch 191/499:\n",
            "train Loss: 0.4971 Acc: 0.9017\n",
            "\n",
            "val Loss: 1.6296 Acc: 0.4825\n",
            "\n",
            "Epoch 192/499:\n",
            "train Loss: 0.4962 Acc: 0.9017\n",
            "\n",
            "val Loss: 1.6377 Acc: 0.4825\n",
            "\n",
            "Epoch 193/499:\n",
            "train Loss: 0.4952 Acc: 0.9017\n",
            "\n",
            "val Loss: 1.6458 Acc: 0.4825\n",
            "\n",
            "Epoch 194/499:\n",
            "train Loss: 0.4942 Acc: 0.9017\n",
            "\n",
            "val Loss: 1.6539 Acc: 0.4825\n",
            "\n",
            "Epoch 195/499:\n",
            "train Loss: 0.4933 Acc: 0.9033\n",
            "\n",
            "val Loss: 1.6620 Acc: 0.4825\n",
            "\n",
            "Epoch 196/499:\n",
            "train Loss: 0.4923 Acc: 0.9033\n",
            "\n",
            "val Loss: 1.6701 Acc: 0.4825\n",
            "\n",
            "Epoch 197/499:\n",
            "train Loss: 0.4914 Acc: 0.9033\n",
            "\n",
            "val Loss: 1.6782 Acc: 0.4825\n",
            "\n",
            "Epoch 198/499:\n",
            "train Loss: 0.4904 Acc: 0.9033\n",
            "\n",
            "val Loss: 1.6863 Acc: 0.4825\n",
            "\n",
            "Epoch 199/499:\n",
            "train Loss: 0.4895 Acc: 0.9033\n",
            "\n",
            "val Loss: 1.6944 Acc: 0.4825\n",
            "\n",
            "Epoch 200/499:\n",
            "train Loss: 0.4885 Acc: 0.9033\n",
            "\n",
            "val Loss: 1.7025 Acc: 0.4825\n",
            "\n",
            "Epoch 201/499:\n",
            "train Loss: 0.4876 Acc: 0.9033\n",
            "\n",
            "val Loss: 1.7106 Acc: 0.4825\n",
            "\n",
            "Epoch 202/499:\n",
            "train Loss: 0.4867 Acc: 0.9033\n",
            "\n",
            "val Loss: 1.7187 Acc: 0.4825\n",
            "\n",
            "Epoch 203/499:\n",
            "train Loss: 0.4857 Acc: 0.9033\n",
            "\n",
            "val Loss: 1.7268 Acc: 0.4825\n",
            "\n",
            "Epoch 204/499:\n",
            "train Loss: 0.4848 Acc: 0.9042\n",
            "\n",
            "val Loss: 1.7349 Acc: 0.4825\n",
            "\n",
            "Epoch 205/499:\n",
            "train Loss: 0.4839 Acc: 0.9058\n",
            "\n",
            "val Loss: 1.7430 Acc: 0.4825\n",
            "\n",
            "Epoch 206/499:\n",
            "train Loss: 0.4829 Acc: 0.9058\n",
            "\n",
            "val Loss: 1.7511 Acc: 0.4825\n",
            "\n",
            "Epoch 207/499:\n",
            "train Loss: 0.4820 Acc: 0.9058\n",
            "\n",
            "val Loss: 1.7592 Acc: 0.4825\n",
            "\n",
            "Epoch 208/499:\n",
            "train Loss: 0.4811 Acc: 0.9058\n",
            "\n",
            "val Loss: 1.7673 Acc: 0.4825\n",
            "\n",
            "Epoch 209/499:\n",
            "train Loss: 0.4802 Acc: 0.9058\n",
            "\n",
            "val Loss: 1.7754 Acc: 0.4825\n",
            "\n",
            "Epoch 210/499:\n",
            "train Loss: 0.4793 Acc: 0.9058\n",
            "\n",
            "val Loss: 1.7835 Acc: 0.4825\n",
            "\n",
            "Epoch 211/499:\n",
            "train Loss: 0.4784 Acc: 0.9058\n",
            "\n",
            "val Loss: 1.7915 Acc: 0.4850\n",
            "\n",
            "Epoch 212/499:\n",
            "train Loss: 0.4775 Acc: 0.9067\n",
            "\n",
            "val Loss: 1.7996 Acc: 0.4850\n",
            "\n",
            "Epoch 213/499:\n",
            "train Loss: 0.4766 Acc: 0.9075\n",
            "\n",
            "val Loss: 1.8077 Acc: 0.4850\n",
            "\n",
            "Epoch 214/499:\n",
            "train Loss: 0.4757 Acc: 0.9083\n",
            "\n",
            "val Loss: 1.8158 Acc: 0.4850\n",
            "\n",
            "Epoch 215/499:\n",
            "train Loss: 0.4748 Acc: 0.9092\n",
            "\n",
            "val Loss: 1.8238 Acc: 0.4850\n",
            "\n",
            "Epoch 216/499:\n",
            "train Loss: 0.4739 Acc: 0.9092\n",
            "\n",
            "val Loss: 1.8319 Acc: 0.4850\n",
            "\n",
            "Epoch 217/499:\n",
            "train Loss: 0.4730 Acc: 0.9092\n",
            "\n",
            "val Loss: 1.8399 Acc: 0.4850\n",
            "\n",
            "Epoch 218/499:\n",
            "train Loss: 0.4721 Acc: 0.9092\n",
            "\n",
            "val Loss: 1.8480 Acc: 0.4850\n",
            "\n",
            "Epoch 219/499:\n",
            "train Loss: 0.4712 Acc: 0.9100\n",
            "\n",
            "val Loss: 1.8560 Acc: 0.4850\n",
            "\n",
            "Epoch 220/499:\n",
            "train Loss: 0.4703 Acc: 0.9100\n",
            "\n",
            "val Loss: 1.8641 Acc: 0.4850\n",
            "\n",
            "Epoch 221/499:\n",
            "train Loss: 0.4694 Acc: 0.9100\n",
            "\n",
            "val Loss: 1.8721 Acc: 0.4850\n",
            "\n",
            "Epoch 222/499:\n",
            "train Loss: 0.4686 Acc: 0.9100\n",
            "\n",
            "val Loss: 1.8802 Acc: 0.4850\n",
            "\n",
            "Epoch 223/499:\n",
            "train Loss: 0.4677 Acc: 0.9117\n",
            "\n",
            "val Loss: 1.8882 Acc: 0.4850\n",
            "\n",
            "Epoch 224/499:\n",
            "train Loss: 0.4668 Acc: 0.9125\n",
            "\n",
            "val Loss: 1.8962 Acc: 0.4850\n",
            "\n",
            "Epoch 225/499:\n",
            "train Loss: 0.4660 Acc: 0.9125\n",
            "\n",
            "val Loss: 1.9042 Acc: 0.4850\n",
            "\n",
            "Epoch 226/499:\n",
            "train Loss: 0.4651 Acc: 0.9142\n",
            "\n",
            "val Loss: 1.9122 Acc: 0.4850\n",
            "\n",
            "Epoch 227/499:\n",
            "train Loss: 0.4642 Acc: 0.9142\n",
            "\n",
            "val Loss: 1.9202 Acc: 0.4850\n",
            "\n",
            "Epoch 228/499:\n",
            "train Loss: 0.4634 Acc: 0.9150\n",
            "\n",
            "val Loss: 1.9282 Acc: 0.4850\n",
            "\n",
            "Epoch 229/499:\n",
            "train Loss: 0.4625 Acc: 0.9158\n",
            "\n",
            "val Loss: 1.9362 Acc: 0.4850\n",
            "\n",
            "Epoch 230/499:\n",
            "train Loss: 0.4617 Acc: 0.9158\n",
            "\n",
            "val Loss: 1.9442 Acc: 0.4850\n",
            "\n",
            "Epoch 231/499:\n",
            "train Loss: 0.4608 Acc: 0.9167\n",
            "\n",
            "val Loss: 1.9522 Acc: 0.4850\n",
            "\n",
            "Epoch 232/499:\n",
            "train Loss: 0.4600 Acc: 0.9158\n",
            "\n",
            "val Loss: 1.9601 Acc: 0.4850\n",
            "\n",
            "Epoch 233/499:\n",
            "train Loss: 0.4591 Acc: 0.9167\n",
            "\n",
            "val Loss: 1.9681 Acc: 0.4850\n",
            "\n",
            "Epoch 234/499:\n",
            "train Loss: 0.4583 Acc: 0.9167\n",
            "\n",
            "val Loss: 1.9760 Acc: 0.4850\n",
            "\n",
            "Epoch 235/499:\n",
            "train Loss: 0.4574 Acc: 0.9167\n",
            "\n",
            "val Loss: 1.9840 Acc: 0.4850\n",
            "\n",
            "Epoch 236/499:\n",
            "train Loss: 0.4566 Acc: 0.9167\n",
            "\n",
            "val Loss: 1.9919 Acc: 0.4850\n",
            "\n",
            "Epoch 237/499:\n",
            "train Loss: 0.4558 Acc: 0.9167\n",
            "\n",
            "val Loss: 1.9999 Acc: 0.4850\n",
            "\n",
            "Epoch 238/499:\n",
            "train Loss: 0.4549 Acc: 0.9175\n",
            "\n",
            "val Loss: 2.0078 Acc: 0.4850\n",
            "\n",
            "Epoch 239/499:\n",
            "train Loss: 0.4541 Acc: 0.9175\n",
            "\n",
            "val Loss: 2.0157 Acc: 0.4850\n",
            "\n",
            "Epoch 240/499:\n",
            "train Loss: 0.4533 Acc: 0.9183\n",
            "\n",
            "val Loss: 2.0236 Acc: 0.4875\n",
            "\n",
            "Epoch 241/499:\n",
            "train Loss: 0.4525 Acc: 0.9183\n",
            "\n",
            "val Loss: 2.0315 Acc: 0.4850\n",
            "\n",
            "Epoch 242/499:\n",
            "train Loss: 0.4516 Acc: 0.9183\n",
            "\n",
            "val Loss: 2.0394 Acc: 0.4850\n",
            "\n",
            "Epoch 243/499:\n",
            "train Loss: 0.4508 Acc: 0.9183\n",
            "\n",
            "val Loss: 2.0473 Acc: 0.4825\n",
            "\n",
            "Epoch 244/499:\n",
            "train Loss: 0.4500 Acc: 0.9183\n",
            "\n",
            "val Loss: 2.0552 Acc: 0.4825\n",
            "\n",
            "Epoch 245/499:\n",
            "train Loss: 0.4492 Acc: 0.9192\n",
            "\n",
            "val Loss: 2.0630 Acc: 0.4825\n",
            "\n",
            "Epoch 246/499:\n",
            "train Loss: 0.4484 Acc: 0.9192\n",
            "\n",
            "val Loss: 2.0709 Acc: 0.4825\n",
            "\n",
            "Epoch 247/499:\n",
            "train Loss: 0.4476 Acc: 0.9192\n",
            "\n",
            "val Loss: 2.0787 Acc: 0.4825\n",
            "\n",
            "Epoch 248/499:\n",
            "train Loss: 0.4468 Acc: 0.9192\n",
            "\n",
            "val Loss: 2.0866 Acc: 0.4825\n",
            "\n",
            "Epoch 249/499:\n",
            "train Loss: 0.4460 Acc: 0.9192\n",
            "\n",
            "val Loss: 2.0944 Acc: 0.4825\n",
            "\n",
            "Epoch 250/499:\n",
            "train Loss: 0.4452 Acc: 0.9192\n",
            "\n",
            "val Loss: 2.1022 Acc: 0.4825\n",
            "\n",
            "Epoch 251/499:\n",
            "train Loss: 0.4444 Acc: 0.9192\n",
            "\n",
            "val Loss: 2.1100 Acc: 0.4825\n",
            "\n",
            "Epoch 252/499:\n",
            "train Loss: 0.4436 Acc: 0.9192\n",
            "\n",
            "val Loss: 2.1178 Acc: 0.4825\n",
            "\n",
            "Epoch 253/499:\n",
            "train Loss: 0.4428 Acc: 0.9192\n",
            "\n",
            "val Loss: 2.1256 Acc: 0.4825\n",
            "\n",
            "Epoch 254/499:\n",
            "train Loss: 0.4420 Acc: 0.9192\n",
            "\n",
            "val Loss: 2.1334 Acc: 0.4825\n",
            "\n",
            "Epoch 255/499:\n",
            "train Loss: 0.4412 Acc: 0.9192\n",
            "\n",
            "val Loss: 2.1412 Acc: 0.4825\n",
            "\n",
            "Epoch 256/499:\n",
            "train Loss: 0.4404 Acc: 0.9192\n",
            "\n",
            "val Loss: 2.1490 Acc: 0.4825\n",
            "\n",
            "Epoch 257/499:\n",
            "train Loss: 0.4397 Acc: 0.9192\n",
            "\n",
            "val Loss: 2.1567 Acc: 0.4825\n",
            "\n",
            "Epoch 258/499:\n",
            "train Loss: 0.4389 Acc: 0.9183\n",
            "\n",
            "val Loss: 2.1645 Acc: 0.4825\n",
            "\n",
            "Epoch 259/499:\n",
            "train Loss: 0.4381 Acc: 0.9183\n",
            "\n",
            "val Loss: 2.1722 Acc: 0.4800\n",
            "\n",
            "Epoch 260/499:\n",
            "train Loss: 0.4373 Acc: 0.9183\n",
            "\n",
            "val Loss: 2.1799 Acc: 0.4775\n",
            "\n",
            "Epoch 261/499:\n",
            "train Loss: 0.4366 Acc: 0.9183\n",
            "\n",
            "val Loss: 2.1877 Acc: 0.4775\n",
            "\n",
            "Epoch 262/499:\n",
            "train Loss: 0.4358 Acc: 0.9183\n",
            "\n",
            "val Loss: 2.1954 Acc: 0.4775\n",
            "\n",
            "Epoch 263/499:\n",
            "train Loss: 0.4350 Acc: 0.9183\n",
            "\n",
            "val Loss: 2.2031 Acc: 0.4800\n",
            "\n",
            "Epoch 264/499:\n",
            "train Loss: 0.4343 Acc: 0.9183\n",
            "\n",
            "val Loss: 2.2108 Acc: 0.4800\n",
            "\n",
            "Epoch 265/499:\n",
            "train Loss: 0.4335 Acc: 0.9183\n",
            "\n",
            "val Loss: 2.2184 Acc: 0.4800\n",
            "\n",
            "Epoch 266/499:\n",
            "train Loss: 0.4327 Acc: 0.9183\n",
            "\n",
            "val Loss: 2.2261 Acc: 0.4800\n",
            "\n",
            "Epoch 267/499:\n",
            "train Loss: 0.4320 Acc: 0.9183\n",
            "\n",
            "val Loss: 2.2338 Acc: 0.4800\n",
            "\n",
            "Epoch 268/499:\n",
            "train Loss: 0.4312 Acc: 0.9183\n",
            "\n",
            "val Loss: 2.2414 Acc: 0.4800\n",
            "\n",
            "Epoch 269/499:\n",
            "train Loss: 0.4305 Acc: 0.9183\n",
            "\n",
            "val Loss: 2.2490 Acc: 0.4800\n",
            "\n",
            "Epoch 270/499:\n",
            "train Loss: 0.4297 Acc: 0.9183\n",
            "\n",
            "val Loss: 2.2567 Acc: 0.4800\n",
            "\n",
            "Epoch 271/499:\n",
            "train Loss: 0.4290 Acc: 0.9183\n",
            "\n",
            "val Loss: 2.2643 Acc: 0.4800\n",
            "\n",
            "Epoch 272/499:\n",
            "train Loss: 0.4283 Acc: 0.9183\n",
            "\n",
            "val Loss: 2.2719 Acc: 0.4800\n",
            "\n",
            "Epoch 273/499:\n",
            "train Loss: 0.4275 Acc: 0.9183\n",
            "\n",
            "val Loss: 2.2795 Acc: 0.4800\n",
            "\n",
            "Epoch 274/499:\n",
            "train Loss: 0.4268 Acc: 0.9183\n",
            "\n",
            "val Loss: 2.2871 Acc: 0.4800\n",
            "\n",
            "Epoch 275/499:\n",
            "train Loss: 0.4260 Acc: 0.9183\n",
            "\n",
            "val Loss: 2.2947 Acc: 0.4800\n",
            "\n",
            "Epoch 276/499:\n",
            "train Loss: 0.4253 Acc: 0.9192\n",
            "\n",
            "val Loss: 2.3022 Acc: 0.4800\n",
            "\n",
            "Epoch 277/499:\n",
            "train Loss: 0.4246 Acc: 0.9200\n",
            "\n",
            "val Loss: 2.3098 Acc: 0.4825\n",
            "\n",
            "Epoch 278/499:\n",
            "train Loss: 0.4239 Acc: 0.9208\n",
            "\n",
            "val Loss: 2.3173 Acc: 0.4850\n",
            "\n",
            "Epoch 279/499:\n",
            "train Loss: 0.4231 Acc: 0.9208\n",
            "\n",
            "val Loss: 2.3249 Acc: 0.4850\n",
            "\n",
            "Epoch 280/499:\n",
            "train Loss: 0.4224 Acc: 0.9208\n",
            "\n",
            "val Loss: 2.3324 Acc: 0.4850\n",
            "\n",
            "Epoch 281/499:\n",
            "train Loss: 0.4217 Acc: 0.9208\n",
            "\n",
            "val Loss: 2.3399 Acc: 0.4850\n",
            "\n",
            "Epoch 282/499:\n",
            "train Loss: 0.4210 Acc: 0.9208\n",
            "\n",
            "val Loss: 2.3474 Acc: 0.4850\n",
            "\n",
            "Epoch 283/499:\n",
            "train Loss: 0.4203 Acc: 0.9217\n",
            "\n",
            "val Loss: 2.3549 Acc: 0.4875\n",
            "\n",
            "Epoch 284/499:\n",
            "train Loss: 0.4195 Acc: 0.9217\n",
            "\n",
            "val Loss: 2.3624 Acc: 0.4875\n",
            "\n",
            "Epoch 285/499:\n",
            "train Loss: 0.4188 Acc: 0.9217\n",
            "\n",
            "val Loss: 2.3698 Acc: 0.4875\n",
            "\n",
            "Epoch 286/499:\n",
            "train Loss: 0.4181 Acc: 0.9217\n",
            "\n",
            "val Loss: 2.3773 Acc: 0.4875\n",
            "\n",
            "Epoch 287/499:\n",
            "train Loss: 0.4174 Acc: 0.9217\n",
            "\n",
            "val Loss: 2.3847 Acc: 0.4875\n",
            "\n",
            "Epoch 288/499:\n",
            "train Loss: 0.4167 Acc: 0.9217\n",
            "\n",
            "val Loss: 2.3922 Acc: 0.4875\n",
            "\n",
            "Epoch 289/499:\n",
            "train Loss: 0.4160 Acc: 0.9217\n",
            "\n",
            "val Loss: 2.3996 Acc: 0.4875\n",
            "\n",
            "Epoch 290/499:\n",
            "train Loss: 0.4153 Acc: 0.9225\n",
            "\n",
            "val Loss: 2.4070 Acc: 0.4875\n",
            "\n",
            "Epoch 291/499:\n",
            "train Loss: 0.4146 Acc: 0.9225\n",
            "\n",
            "val Loss: 2.4144 Acc: 0.4875\n",
            "\n",
            "Epoch 292/499:\n",
            "train Loss: 0.4139 Acc: 0.9233\n",
            "\n",
            "val Loss: 2.4218 Acc: 0.4875\n",
            "\n",
            "Epoch 293/499:\n",
            "train Loss: 0.4132 Acc: 0.9233\n",
            "\n",
            "val Loss: 2.4292 Acc: 0.4875\n",
            "\n",
            "Epoch 294/499:\n",
            "train Loss: 0.4125 Acc: 0.9242\n",
            "\n",
            "val Loss: 2.4365 Acc: 0.4875\n",
            "\n",
            "Epoch 295/499:\n",
            "train Loss: 0.4118 Acc: 0.9242\n",
            "\n",
            "val Loss: 2.4439 Acc: 0.4875\n",
            "\n",
            "Epoch 296/499:\n",
            "train Loss: 0.4112 Acc: 0.9242\n",
            "\n",
            "val Loss: 2.4512 Acc: 0.4875\n",
            "\n",
            "Epoch 297/499:\n",
            "train Loss: 0.4105 Acc: 0.9242\n",
            "\n",
            "val Loss: 2.4586 Acc: 0.4875\n",
            "\n",
            "Epoch 298/499:\n",
            "train Loss: 0.4098 Acc: 0.9242\n",
            "\n",
            "val Loss: 2.4659 Acc: 0.4875\n",
            "\n",
            "Epoch 299/499:\n",
            "train Loss: 0.4091 Acc: 0.9242\n",
            "\n",
            "val Loss: 2.4732 Acc: 0.4875\n",
            "\n",
            "Epoch 300/499:\n",
            "train Loss: 0.4084 Acc: 0.9242\n",
            "\n",
            "val Loss: 2.4805 Acc: 0.4900\n",
            "\n",
            "Epoch 301/499:\n",
            "train Loss: 0.4078 Acc: 0.9242\n",
            "\n",
            "val Loss: 2.4878 Acc: 0.4900\n",
            "\n",
            "Epoch 302/499:\n",
            "train Loss: 0.4071 Acc: 0.9242\n",
            "\n",
            "val Loss: 2.4951 Acc: 0.4900\n",
            "\n",
            "Epoch 303/499:\n",
            "train Loss: 0.4064 Acc: 0.9242\n",
            "\n",
            "val Loss: 2.5023 Acc: 0.4900\n",
            "\n",
            "Epoch 304/499:\n",
            "train Loss: 0.4057 Acc: 0.9242\n",
            "\n",
            "val Loss: 2.5096 Acc: 0.4900\n",
            "\n",
            "Epoch 305/499:\n",
            "train Loss: 0.4051 Acc: 0.9242\n",
            "\n",
            "val Loss: 2.5168 Acc: 0.4900\n",
            "\n",
            "Epoch 306/499:\n",
            "train Loss: 0.4044 Acc: 0.9242\n",
            "\n",
            "val Loss: 2.5240 Acc: 0.4900\n",
            "\n",
            "Epoch 307/499:\n",
            "train Loss: 0.4038 Acc: 0.9242\n",
            "\n",
            "val Loss: 2.5313 Acc: 0.4900\n",
            "\n",
            "Epoch 308/499:\n",
            "train Loss: 0.4031 Acc: 0.9242\n",
            "\n",
            "val Loss: 2.5385 Acc: 0.4900\n",
            "\n",
            "Epoch 309/499:\n",
            "train Loss: 0.4024 Acc: 0.9242\n",
            "\n",
            "val Loss: 2.5457 Acc: 0.4900\n",
            "\n",
            "Epoch 310/499:\n",
            "train Loss: 0.4018 Acc: 0.9242\n",
            "\n",
            "val Loss: 2.5529 Acc: 0.4900\n",
            "\n",
            "Epoch 311/499:\n",
            "train Loss: 0.4011 Acc: 0.9242\n",
            "\n",
            "val Loss: 2.5600 Acc: 0.4925\n",
            "\n",
            "Epoch 312/499:\n",
            "train Loss: 0.4005 Acc: 0.9242\n",
            "\n",
            "val Loss: 2.5672 Acc: 0.4925\n",
            "\n",
            "Epoch 313/499:\n",
            "train Loss: 0.3998 Acc: 0.9242\n",
            "\n",
            "val Loss: 2.5743 Acc: 0.4925\n",
            "\n",
            "Epoch 314/499:\n",
            "train Loss: 0.3992 Acc: 0.9242\n",
            "\n",
            "val Loss: 2.5815 Acc: 0.4925\n",
            "\n",
            "Epoch 315/499:\n",
            "train Loss: 0.3985 Acc: 0.9242\n",
            "\n",
            "val Loss: 2.5886 Acc: 0.4950\n",
            "\n",
            "Epoch 316/499:\n",
            "train Loss: 0.3979 Acc: 0.9233\n",
            "\n",
            "val Loss: 2.5957 Acc: 0.4950\n",
            "\n",
            "Epoch 317/499:\n",
            "train Loss: 0.3972 Acc: 0.9233\n",
            "\n",
            "val Loss: 2.6028 Acc: 0.4950\n",
            "\n",
            "Epoch 318/499:\n",
            "train Loss: 0.3966 Acc: 0.9233\n",
            "\n",
            "val Loss: 2.6099 Acc: 0.4950\n",
            "\n",
            "Epoch 319/499:\n",
            "train Loss: 0.3960 Acc: 0.9233\n",
            "\n",
            "val Loss: 2.6170 Acc: 0.4950\n",
            "\n",
            "Epoch 320/499:\n",
            "train Loss: 0.3953 Acc: 0.9233\n",
            "\n",
            "val Loss: 2.6241 Acc: 0.4950\n",
            "\n",
            "Epoch 321/499:\n",
            "train Loss: 0.3947 Acc: 0.9233\n",
            "\n",
            "val Loss: 2.6311 Acc: 0.4950\n",
            "\n",
            "Epoch 322/499:\n",
            "train Loss: 0.3941 Acc: 0.9233\n",
            "\n",
            "val Loss: 2.6382 Acc: 0.4950\n",
            "\n",
            "Epoch 323/499:\n",
            "train Loss: 0.3934 Acc: 0.9233\n",
            "\n",
            "val Loss: 2.6452 Acc: 0.4975\n",
            "\n",
            "Epoch 324/499:\n",
            "train Loss: 0.3928 Acc: 0.9233\n",
            "\n",
            "val Loss: 2.6522 Acc: 0.4975\n",
            "\n",
            "Epoch 325/499:\n",
            "train Loss: 0.3922 Acc: 0.9233\n",
            "\n",
            "val Loss: 2.6592 Acc: 0.4975\n",
            "\n",
            "Epoch 326/499:\n",
            "train Loss: 0.3916 Acc: 0.9233\n",
            "\n",
            "val Loss: 2.6663 Acc: 0.4975\n",
            "\n",
            "Epoch 327/499:\n",
            "train Loss: 0.3909 Acc: 0.9233\n",
            "\n",
            "val Loss: 2.6732 Acc: 0.4975\n",
            "\n",
            "Epoch 328/499:\n",
            "train Loss: 0.3903 Acc: 0.9233\n",
            "\n",
            "val Loss: 2.6802 Acc: 0.4975\n",
            "\n",
            "Epoch 329/499:\n",
            "train Loss: 0.3897 Acc: 0.9233\n",
            "\n",
            "val Loss: 2.6872 Acc: 0.4975\n",
            "\n",
            "Epoch 330/499:\n",
            "train Loss: 0.3891 Acc: 0.9233\n",
            "\n",
            "val Loss: 2.6941 Acc: 0.4975\n",
            "\n",
            "Epoch 331/499:\n",
            "train Loss: 0.3885 Acc: 0.9233\n",
            "\n",
            "val Loss: 2.7011 Acc: 0.4975\n",
            "\n",
            "Epoch 332/499:\n",
            "train Loss: 0.3879 Acc: 0.9233\n",
            "\n",
            "val Loss: 2.7080 Acc: 0.4975\n",
            "\n",
            "Epoch 333/499:\n",
            "train Loss: 0.3873 Acc: 0.9233\n",
            "\n",
            "val Loss: 2.7149 Acc: 0.4975\n",
            "\n",
            "Epoch 334/499:\n",
            "train Loss: 0.3866 Acc: 0.9233\n",
            "\n",
            "val Loss: 2.7218 Acc: 0.4975\n",
            "\n",
            "Epoch 335/499:\n",
            "train Loss: 0.3860 Acc: 0.9233\n",
            "\n",
            "val Loss: 2.7287 Acc: 0.4975\n",
            "\n",
            "Epoch 336/499:\n",
            "train Loss: 0.3854 Acc: 0.9242\n",
            "\n",
            "val Loss: 2.7356 Acc: 0.4975\n",
            "\n",
            "Epoch 337/499:\n",
            "train Loss: 0.3848 Acc: 0.9242\n",
            "\n",
            "val Loss: 2.7425 Acc: 0.4975\n",
            "\n",
            "Epoch 338/499:\n",
            "train Loss: 0.3842 Acc: 0.9242\n",
            "\n",
            "val Loss: 2.7494 Acc: 0.4975\n",
            "\n",
            "Epoch 339/499:\n",
            "train Loss: 0.3836 Acc: 0.9242\n",
            "\n",
            "val Loss: 2.7562 Acc: 0.4975\n",
            "\n",
            "Epoch 340/499:\n",
            "train Loss: 0.3830 Acc: 0.9242\n",
            "\n",
            "val Loss: 2.7631 Acc: 0.4975\n",
            "\n",
            "Epoch 341/499:\n",
            "train Loss: 0.3824 Acc: 0.9242\n",
            "\n",
            "val Loss: 2.7699 Acc: 0.4975\n",
            "\n",
            "Epoch 342/499:\n",
            "train Loss: 0.3818 Acc: 0.9242\n",
            "\n",
            "val Loss: 2.7767 Acc: 0.4975\n",
            "\n",
            "Epoch 343/499:\n",
            "train Loss: 0.3813 Acc: 0.9250\n",
            "\n",
            "val Loss: 2.7835 Acc: 0.4975\n",
            "\n",
            "Epoch 344/499:\n",
            "train Loss: 0.3807 Acc: 0.9250\n",
            "\n",
            "val Loss: 2.7903 Acc: 0.4975\n",
            "\n",
            "Epoch 345/499:\n",
            "train Loss: 0.3801 Acc: 0.9250\n",
            "\n",
            "val Loss: 2.7971 Acc: 0.4975\n",
            "\n",
            "Epoch 346/499:\n",
            "train Loss: 0.3795 Acc: 0.9250\n",
            "\n",
            "val Loss: 2.8038 Acc: 0.4975\n",
            "\n",
            "Epoch 347/499:\n",
            "train Loss: 0.3789 Acc: 0.9250\n",
            "\n",
            "val Loss: 2.8106 Acc: 0.4975\n",
            "\n",
            "Epoch 348/499:\n",
            "train Loss: 0.3783 Acc: 0.9250\n",
            "\n",
            "val Loss: 2.8174 Acc: 0.4975\n",
            "\n",
            "Epoch 349/499:\n",
            "train Loss: 0.3777 Acc: 0.9250\n",
            "\n",
            "val Loss: 2.8241 Acc: 0.5000\n",
            "\n",
            "Epoch 350/499:\n",
            "train Loss: 0.3772 Acc: 0.9250\n",
            "\n",
            "val Loss: 2.8308 Acc: 0.4975\n",
            "\n",
            "Epoch 351/499:\n",
            "train Loss: 0.3766 Acc: 0.9250\n",
            "\n",
            "val Loss: 2.8375 Acc: 0.4975\n",
            "\n",
            "Epoch 352/499:\n",
            "train Loss: 0.3760 Acc: 0.9250\n",
            "\n",
            "val Loss: 2.8442 Acc: 0.4975\n",
            "\n",
            "Epoch 353/499:\n",
            "train Loss: 0.3754 Acc: 0.9250\n",
            "\n",
            "val Loss: 2.8509 Acc: 0.4975\n",
            "\n",
            "Epoch 354/499:\n",
            "train Loss: 0.3749 Acc: 0.9250\n",
            "\n",
            "val Loss: 2.8576 Acc: 0.4975\n",
            "\n",
            "Epoch 355/499:\n",
            "train Loss: 0.3743 Acc: 0.9250\n",
            "\n",
            "val Loss: 2.8643 Acc: 0.4975\n",
            "\n",
            "Epoch 356/499:\n",
            "train Loss: 0.3737 Acc: 0.9250\n",
            "\n",
            "val Loss: 2.8709 Acc: 0.4975\n",
            "\n",
            "Epoch 357/499:\n",
            "train Loss: 0.3732 Acc: 0.9250\n",
            "\n",
            "val Loss: 2.8776 Acc: 0.4975\n",
            "\n",
            "Epoch 358/499:\n",
            "train Loss: 0.3726 Acc: 0.9250\n",
            "\n",
            "val Loss: 2.8842 Acc: 0.4975\n",
            "\n",
            "Epoch 359/499:\n",
            "train Loss: 0.3720 Acc: 0.9250\n",
            "\n",
            "val Loss: 2.8908 Acc: 0.4975\n",
            "\n",
            "Epoch 360/499:\n",
            "train Loss: 0.3715 Acc: 0.9250\n",
            "\n",
            "val Loss: 2.8974 Acc: 0.4975\n",
            "\n",
            "Epoch 361/499:\n",
            "train Loss: 0.3709 Acc: 0.9258\n",
            "\n",
            "val Loss: 2.9040 Acc: 0.4975\n",
            "\n",
            "Epoch 362/499:\n",
            "train Loss: 0.3704 Acc: 0.9258\n",
            "\n",
            "val Loss: 2.9106 Acc: 0.4975\n",
            "\n",
            "Epoch 363/499:\n",
            "train Loss: 0.3698 Acc: 0.9258\n",
            "\n",
            "val Loss: 2.9172 Acc: 0.4975\n",
            "\n",
            "Epoch 364/499:\n",
            "train Loss: 0.3692 Acc: 0.9258\n",
            "\n",
            "val Loss: 2.9238 Acc: 0.4975\n",
            "\n",
            "Epoch 365/499:\n",
            "train Loss: 0.3687 Acc: 0.9258\n",
            "\n",
            "val Loss: 2.9303 Acc: 0.4975\n",
            "\n",
            "Epoch 366/499:\n",
            "train Loss: 0.3681 Acc: 0.9258\n",
            "\n",
            "val Loss: 2.9369 Acc: 0.4975\n",
            "\n",
            "Epoch 367/499:\n",
            "train Loss: 0.3676 Acc: 0.9258\n",
            "\n",
            "val Loss: 2.9434 Acc: 0.4975\n",
            "\n",
            "Epoch 368/499:\n",
            "train Loss: 0.3670 Acc: 0.9258\n",
            "\n",
            "val Loss: 2.9499 Acc: 0.4975\n",
            "\n",
            "Epoch 369/499:\n",
            "train Loss: 0.3665 Acc: 0.9258\n",
            "\n",
            "val Loss: 2.9564 Acc: 0.5000\n",
            "\n",
            "Epoch 370/499:\n",
            "train Loss: 0.3659 Acc: 0.9258\n",
            "\n",
            "val Loss: 2.9629 Acc: 0.5000\n",
            "\n",
            "Epoch 371/499:\n",
            "train Loss: 0.3654 Acc: 0.9258\n",
            "\n",
            "val Loss: 2.9694 Acc: 0.5000\n",
            "\n",
            "Epoch 372/499:\n",
            "train Loss: 0.3649 Acc: 0.9267\n",
            "\n",
            "val Loss: 2.9759 Acc: 0.5000\n",
            "\n",
            "Epoch 373/499:\n",
            "train Loss: 0.3643 Acc: 0.9267\n",
            "\n",
            "val Loss: 2.9824 Acc: 0.5000\n",
            "\n",
            "Epoch 374/499:\n",
            "train Loss: 0.3638 Acc: 0.9267\n",
            "\n",
            "val Loss: 2.9888 Acc: 0.5000\n",
            "\n",
            "Epoch 375/499:\n",
            "train Loss: 0.3632 Acc: 0.9267\n",
            "\n",
            "val Loss: 2.9953 Acc: 0.5000\n",
            "\n",
            "Epoch 376/499:\n",
            "train Loss: 0.3627 Acc: 0.9275\n",
            "\n",
            "val Loss: 3.0017 Acc: 0.5000\n",
            "\n",
            "Epoch 377/499:\n",
            "train Loss: 0.3622 Acc: 0.9275\n",
            "\n",
            "val Loss: 3.0081 Acc: 0.5000\n",
            "\n",
            "Epoch 378/499:\n",
            "train Loss: 0.3616 Acc: 0.9275\n",
            "\n",
            "val Loss: 3.0145 Acc: 0.5000\n",
            "\n",
            "Epoch 379/499:\n",
            "train Loss: 0.3611 Acc: 0.9275\n",
            "\n",
            "val Loss: 3.0209 Acc: 0.5000\n",
            "\n",
            "Epoch 380/499:\n",
            "train Loss: 0.3606 Acc: 0.9275\n",
            "\n",
            "val Loss: 3.0273 Acc: 0.5000\n",
            "\n",
            "Epoch 381/499:\n",
            "train Loss: 0.3600 Acc: 0.9275\n",
            "\n",
            "val Loss: 3.0337 Acc: 0.5000\n",
            "\n",
            "Epoch 382/499:\n",
            "train Loss: 0.3595 Acc: 0.9275\n",
            "\n",
            "val Loss: 3.0401 Acc: 0.5000\n",
            "\n",
            "Epoch 383/499:\n",
            "train Loss: 0.3590 Acc: 0.9275\n",
            "\n",
            "val Loss: 3.0464 Acc: 0.5000\n",
            "\n",
            "Epoch 384/499:\n",
            "train Loss: 0.3585 Acc: 0.9275\n",
            "\n",
            "val Loss: 3.0528 Acc: 0.5000\n",
            "\n",
            "Epoch 385/499:\n",
            "train Loss: 0.3579 Acc: 0.9275\n",
            "\n",
            "val Loss: 3.0591 Acc: 0.5000\n",
            "\n",
            "Epoch 386/499:\n",
            "train Loss: 0.3574 Acc: 0.9275\n",
            "\n",
            "val Loss: 3.0654 Acc: 0.5000\n",
            "\n",
            "Epoch 387/499:\n",
            "train Loss: 0.3569 Acc: 0.9275\n",
            "\n",
            "val Loss: 3.0717 Acc: 0.5000\n",
            "\n",
            "Epoch 388/499:\n",
            "train Loss: 0.3564 Acc: 0.9275\n",
            "\n",
            "val Loss: 3.0780 Acc: 0.5000\n",
            "\n",
            "Epoch 389/499:\n",
            "train Loss: 0.3559 Acc: 0.9275\n",
            "\n",
            "val Loss: 3.0843 Acc: 0.5000\n",
            "\n",
            "Epoch 390/499:\n",
            "train Loss: 0.3554 Acc: 0.9275\n",
            "\n",
            "val Loss: 3.0906 Acc: 0.5000\n",
            "\n",
            "Epoch 391/499:\n",
            "train Loss: 0.3548 Acc: 0.9275\n",
            "\n",
            "val Loss: 3.0969 Acc: 0.5000\n",
            "\n",
            "Epoch 392/499:\n",
            "train Loss: 0.3543 Acc: 0.9275\n",
            "\n",
            "val Loss: 3.1031 Acc: 0.5000\n",
            "\n",
            "Epoch 393/499:\n",
            "train Loss: 0.3538 Acc: 0.9275\n",
            "\n",
            "val Loss: 3.1094 Acc: 0.5000\n",
            "\n",
            "Epoch 394/499:\n",
            "train Loss: 0.3533 Acc: 0.9275\n",
            "\n",
            "val Loss: 3.1156 Acc: 0.5000\n",
            "\n",
            "Epoch 395/499:\n",
            "train Loss: 0.3528 Acc: 0.9275\n",
            "\n",
            "val Loss: 3.1218 Acc: 0.5000\n",
            "\n",
            "Epoch 396/499:\n",
            "train Loss: 0.3523 Acc: 0.9275\n",
            "\n",
            "val Loss: 3.1281 Acc: 0.5000\n",
            "\n",
            "Epoch 397/499:\n",
            "train Loss: 0.3518 Acc: 0.9283\n",
            "\n",
            "val Loss: 3.1343 Acc: 0.5000\n",
            "\n",
            "Epoch 398/499:\n",
            "train Loss: 0.3513 Acc: 0.9283\n",
            "\n",
            "val Loss: 3.1405 Acc: 0.5000\n",
            "\n",
            "Epoch 399/499:\n",
            "train Loss: 0.3508 Acc: 0.9283\n",
            "\n",
            "val Loss: 3.1466 Acc: 0.5000\n",
            "\n",
            "Epoch 400/499:\n",
            "train Loss: 0.3503 Acc: 0.9283\n",
            "\n",
            "val Loss: 3.1528 Acc: 0.5000\n",
            "\n",
            "Epoch 401/499:\n",
            "train Loss: 0.3498 Acc: 0.9283\n",
            "\n",
            "val Loss: 3.1590 Acc: 0.5000\n",
            "\n",
            "Epoch 402/499:\n",
            "train Loss: 0.3493 Acc: 0.9283\n",
            "\n",
            "val Loss: 3.1651 Acc: 0.5000\n",
            "\n",
            "Epoch 403/499:\n",
            "train Loss: 0.3488 Acc: 0.9292\n",
            "\n",
            "val Loss: 3.1713 Acc: 0.5000\n",
            "\n",
            "Epoch 404/499:\n",
            "train Loss: 0.3483 Acc: 0.9300\n",
            "\n",
            "val Loss: 3.1774 Acc: 0.5000\n",
            "\n",
            "Epoch 405/499:\n",
            "train Loss: 0.3478 Acc: 0.9300\n",
            "\n",
            "val Loss: 3.1835 Acc: 0.5000\n",
            "\n",
            "Epoch 406/499:\n",
            "train Loss: 0.3473 Acc: 0.9300\n",
            "\n",
            "val Loss: 3.1896 Acc: 0.5000\n",
            "\n",
            "Epoch 407/499:\n",
            "train Loss: 0.3468 Acc: 0.9300\n",
            "\n",
            "val Loss: 3.1957 Acc: 0.5000\n",
            "\n",
            "Epoch 408/499:\n",
            "train Loss: 0.3463 Acc: 0.9300\n",
            "\n",
            "val Loss: 3.2018 Acc: 0.5000\n",
            "\n",
            "Epoch 409/499:\n",
            "train Loss: 0.3459 Acc: 0.9300\n",
            "\n",
            "val Loss: 3.2079 Acc: 0.5000\n",
            "\n",
            "Epoch 410/499:\n",
            "train Loss: 0.3454 Acc: 0.9300\n",
            "\n",
            "val Loss: 3.2139 Acc: 0.5000\n",
            "\n",
            "Epoch 411/499:\n",
            "train Loss: 0.3449 Acc: 0.9300\n",
            "\n",
            "val Loss: 3.2200 Acc: 0.5000\n",
            "\n",
            "Epoch 412/499:\n",
            "train Loss: 0.3444 Acc: 0.9300\n",
            "\n",
            "val Loss: 3.2261 Acc: 0.5000\n",
            "\n",
            "Epoch 413/499:\n",
            "train Loss: 0.3439 Acc: 0.9300\n",
            "\n",
            "val Loss: 3.2321 Acc: 0.5000\n",
            "\n",
            "Epoch 414/499:\n",
            "train Loss: 0.3434 Acc: 0.9300\n",
            "\n",
            "val Loss: 3.2381 Acc: 0.5000\n",
            "\n",
            "Epoch 415/499:\n",
            "train Loss: 0.3430 Acc: 0.9300\n",
            "\n",
            "val Loss: 3.2441 Acc: 0.5000\n",
            "\n",
            "Epoch 416/499:\n",
            "train Loss: 0.3425 Acc: 0.9300\n",
            "\n",
            "val Loss: 3.2501 Acc: 0.5000\n",
            "\n",
            "Epoch 417/499:\n",
            "train Loss: 0.3420 Acc: 0.9300\n",
            "\n",
            "val Loss: 3.2561 Acc: 0.5000\n",
            "\n",
            "Epoch 418/499:\n",
            "train Loss: 0.3415 Acc: 0.9308\n",
            "\n",
            "val Loss: 3.2621 Acc: 0.5000\n",
            "\n",
            "Epoch 419/499:\n",
            "train Loss: 0.3410 Acc: 0.9308\n",
            "\n",
            "val Loss: 3.2681 Acc: 0.5000\n",
            "\n",
            "Epoch 420/499:\n",
            "train Loss: 0.3406 Acc: 0.9308\n",
            "\n",
            "val Loss: 3.2740 Acc: 0.5000\n",
            "\n",
            "Epoch 421/499:\n",
            "train Loss: 0.3401 Acc: 0.9308\n",
            "\n",
            "val Loss: 3.2800 Acc: 0.5000\n",
            "\n",
            "Epoch 422/499:\n",
            "train Loss: 0.3396 Acc: 0.9308\n",
            "\n",
            "val Loss: 3.2859 Acc: 0.5000\n",
            "\n",
            "Epoch 423/499:\n",
            "train Loss: 0.3392 Acc: 0.9308\n",
            "\n",
            "val Loss: 3.2919 Acc: 0.5000\n",
            "\n",
            "Epoch 424/499:\n",
            "train Loss: 0.3387 Acc: 0.9325\n",
            "\n",
            "val Loss: 3.2978 Acc: 0.5000\n",
            "\n",
            "Epoch 425/499:\n",
            "train Loss: 0.3382 Acc: 0.9325\n",
            "\n",
            "val Loss: 3.3037 Acc: 0.5000\n",
            "\n",
            "Epoch 426/499:\n",
            "train Loss: 0.3378 Acc: 0.9333\n",
            "\n",
            "val Loss: 3.3096 Acc: 0.5000\n",
            "\n",
            "Epoch 427/499:\n",
            "train Loss: 0.3373 Acc: 0.9333\n",
            "\n",
            "val Loss: 3.3155 Acc: 0.5000\n",
            "\n",
            "Epoch 428/499:\n",
            "train Loss: 0.3368 Acc: 0.9333\n",
            "\n",
            "val Loss: 3.3214 Acc: 0.5000\n",
            "\n",
            "Epoch 429/499:\n",
            "train Loss: 0.3364 Acc: 0.9333\n",
            "\n",
            "val Loss: 3.3273 Acc: 0.5000\n",
            "\n",
            "Epoch 430/499:\n",
            "train Loss: 0.3359 Acc: 0.9333\n",
            "\n",
            "val Loss: 3.3331 Acc: 0.5000\n",
            "\n",
            "Epoch 431/499:\n",
            "train Loss: 0.3355 Acc: 0.9333\n",
            "\n",
            "val Loss: 3.3390 Acc: 0.5000\n",
            "\n",
            "Epoch 432/499:\n",
            "train Loss: 0.3350 Acc: 0.9333\n",
            "\n",
            "val Loss: 3.3448 Acc: 0.5000\n",
            "\n",
            "Epoch 433/499:\n",
            "train Loss: 0.3345 Acc: 0.9333\n",
            "\n",
            "val Loss: 3.3506 Acc: 0.5000\n",
            "\n",
            "Epoch 434/499:\n",
            "train Loss: 0.3341 Acc: 0.9333\n",
            "\n",
            "val Loss: 3.3565 Acc: 0.5000\n",
            "\n",
            "Epoch 435/499:\n",
            "train Loss: 0.3336 Acc: 0.9333\n",
            "\n",
            "val Loss: 3.3623 Acc: 0.5000\n",
            "\n",
            "Epoch 436/499:\n",
            "train Loss: 0.3332 Acc: 0.9333\n",
            "\n",
            "val Loss: 3.3681 Acc: 0.5000\n",
            "\n",
            "Epoch 437/499:\n",
            "train Loss: 0.3327 Acc: 0.9333\n",
            "\n",
            "val Loss: 3.3739 Acc: 0.5000\n",
            "\n",
            "Epoch 438/499:\n",
            "train Loss: 0.3323 Acc: 0.9333\n",
            "\n",
            "val Loss: 3.3797 Acc: 0.5000\n",
            "\n",
            "Epoch 439/499:\n",
            "train Loss: 0.3318 Acc: 0.9342\n",
            "\n",
            "val Loss: 3.3854 Acc: 0.5000\n",
            "\n",
            "Epoch 440/499:\n",
            "train Loss: 0.3314 Acc: 0.9342\n",
            "\n",
            "val Loss: 3.3912 Acc: 0.5000\n",
            "\n",
            "Epoch 441/499:\n",
            "train Loss: 0.3309 Acc: 0.9342\n",
            "\n",
            "val Loss: 3.3969 Acc: 0.5000\n",
            "\n",
            "Epoch 442/499:\n",
            "train Loss: 0.3305 Acc: 0.9342\n",
            "\n",
            "val Loss: 3.4027 Acc: 0.5000\n",
            "\n",
            "Epoch 443/499:\n",
            "train Loss: 0.3300 Acc: 0.9342\n",
            "\n",
            "val Loss: 3.4084 Acc: 0.5000\n",
            "\n",
            "Epoch 444/499:\n",
            "train Loss: 0.3296 Acc: 0.9342\n",
            "\n",
            "val Loss: 3.4141 Acc: 0.5000\n",
            "\n",
            "Epoch 445/499:\n",
            "train Loss: 0.3291 Acc: 0.9342\n",
            "\n",
            "val Loss: 3.4199 Acc: 0.5000\n",
            "\n",
            "Epoch 446/499:\n",
            "train Loss: 0.3287 Acc: 0.9342\n",
            "\n",
            "val Loss: 3.4256 Acc: 0.5000\n",
            "\n",
            "Epoch 447/499:\n",
            "train Loss: 0.3283 Acc: 0.9342\n",
            "\n",
            "val Loss: 3.4313 Acc: 0.5000\n",
            "\n",
            "Epoch 448/499:\n",
            "train Loss: 0.3278 Acc: 0.9342\n",
            "\n",
            "val Loss: 3.4369 Acc: 0.5000\n",
            "\n",
            "Epoch 449/499:\n",
            "train Loss: 0.3274 Acc: 0.9342\n",
            "\n",
            "val Loss: 3.4426 Acc: 0.5000\n",
            "\n",
            "Epoch 450/499:\n",
            "train Loss: 0.3269 Acc: 0.9342\n",
            "\n",
            "val Loss: 3.4483 Acc: 0.5000\n",
            "\n",
            "Epoch 451/499:\n",
            "train Loss: 0.3265 Acc: 0.9342\n",
            "\n",
            "val Loss: 3.4539 Acc: 0.5000\n",
            "\n",
            "Epoch 452/499:\n",
            "train Loss: 0.3261 Acc: 0.9342\n",
            "\n",
            "val Loss: 3.4596 Acc: 0.5000\n",
            "\n",
            "Epoch 453/499:\n",
            "train Loss: 0.3256 Acc: 0.9342\n",
            "\n",
            "val Loss: 3.4652 Acc: 0.5000\n",
            "\n",
            "Epoch 454/499:\n",
            "train Loss: 0.3252 Acc: 0.9342\n",
            "\n",
            "val Loss: 3.4708 Acc: 0.5000\n",
            "\n",
            "Epoch 455/499:\n",
            "train Loss: 0.3248 Acc: 0.9342\n",
            "\n",
            "val Loss: 3.4765 Acc: 0.5000\n",
            "\n",
            "Epoch 456/499:\n",
            "train Loss: 0.3243 Acc: 0.9342\n",
            "\n",
            "val Loss: 3.4821 Acc: 0.5000\n",
            "\n",
            "Epoch 457/499:\n",
            "train Loss: 0.3239 Acc: 0.9342\n",
            "\n",
            "val Loss: 3.4877 Acc: 0.5000\n",
            "\n",
            "Epoch 458/499:\n",
            "train Loss: 0.3235 Acc: 0.9342\n",
            "\n",
            "val Loss: 3.4933 Acc: 0.5000\n",
            "\n",
            "Epoch 459/499:\n",
            "train Loss: 0.3231 Acc: 0.9342\n",
            "\n",
            "val Loss: 3.4988 Acc: 0.5000\n",
            "\n",
            "Epoch 460/499:\n",
            "train Loss: 0.3226 Acc: 0.9342\n",
            "\n",
            "val Loss: 3.5044 Acc: 0.5000\n",
            "\n",
            "Epoch 461/499:\n",
            "train Loss: 0.3222 Acc: 0.9342\n",
            "\n",
            "val Loss: 3.5100 Acc: 0.5000\n",
            "\n",
            "Epoch 462/499:\n",
            "train Loss: 0.3218 Acc: 0.9350\n",
            "\n",
            "val Loss: 3.5155 Acc: 0.5000\n",
            "\n",
            "Epoch 463/499:\n",
            "train Loss: 0.3214 Acc: 0.9350\n",
            "\n",
            "val Loss: 3.5211 Acc: 0.5000\n",
            "\n",
            "Epoch 464/499:\n",
            "train Loss: 0.3209 Acc: 0.9350\n",
            "\n",
            "val Loss: 3.5266 Acc: 0.5000\n",
            "\n",
            "Epoch 465/499:\n",
            "train Loss: 0.3205 Acc: 0.9350\n",
            "\n",
            "val Loss: 3.5321 Acc: 0.5000\n",
            "\n",
            "Epoch 466/499:\n",
            "train Loss: 0.3201 Acc: 0.9350\n",
            "\n",
            "val Loss: 3.5376 Acc: 0.5000\n",
            "\n",
            "Epoch 467/499:\n",
            "train Loss: 0.3197 Acc: 0.9350\n",
            "\n",
            "val Loss: 3.5431 Acc: 0.5000\n",
            "\n",
            "Epoch 468/499:\n",
            "train Loss: 0.3193 Acc: 0.9350\n",
            "\n",
            "val Loss: 3.5486 Acc: 0.5000\n",
            "\n",
            "Epoch 469/499:\n",
            "train Loss: 0.3189 Acc: 0.9350\n",
            "\n",
            "val Loss: 3.5541 Acc: 0.5000\n",
            "\n",
            "Epoch 470/499:\n",
            "train Loss: 0.3184 Acc: 0.9350\n",
            "\n",
            "val Loss: 3.5596 Acc: 0.5000\n",
            "\n",
            "Epoch 471/499:\n",
            "train Loss: 0.3180 Acc: 0.9350\n",
            "\n",
            "val Loss: 3.5651 Acc: 0.5000\n",
            "\n",
            "Epoch 472/499:\n",
            "train Loss: 0.3176 Acc: 0.9350\n",
            "\n",
            "val Loss: 3.5705 Acc: 0.5000\n",
            "\n",
            "Epoch 473/499:\n",
            "train Loss: 0.3172 Acc: 0.9350\n",
            "\n",
            "val Loss: 3.5760 Acc: 0.5000\n",
            "\n",
            "Epoch 474/499:\n",
            "train Loss: 0.3168 Acc: 0.9358\n",
            "\n",
            "val Loss: 3.5814 Acc: 0.5000\n",
            "\n",
            "Epoch 475/499:\n",
            "train Loss: 0.3164 Acc: 0.9358\n",
            "\n",
            "val Loss: 3.5869 Acc: 0.5000\n",
            "\n",
            "Epoch 476/499:\n",
            "train Loss: 0.3160 Acc: 0.9358\n",
            "\n",
            "val Loss: 3.5923 Acc: 0.5000\n",
            "\n",
            "Epoch 477/499:\n",
            "train Loss: 0.3156 Acc: 0.9358\n",
            "\n",
            "val Loss: 3.5977 Acc: 0.5000\n",
            "\n",
            "Epoch 478/499:\n",
            "train Loss: 0.3152 Acc: 0.9358\n",
            "\n",
            "val Loss: 3.6031 Acc: 0.5000\n",
            "\n",
            "Epoch 479/499:\n",
            "train Loss: 0.3147 Acc: 0.9358\n",
            "\n",
            "val Loss: 3.6085 Acc: 0.5000\n",
            "\n",
            "Epoch 480/499:\n",
            "train Loss: 0.3143 Acc: 0.9367\n",
            "\n",
            "val Loss: 3.6139 Acc: 0.5000\n",
            "\n",
            "Epoch 481/499:\n",
            "train Loss: 0.3139 Acc: 0.9367\n",
            "\n",
            "val Loss: 3.6193 Acc: 0.5000\n",
            "\n",
            "Epoch 482/499:\n",
            "train Loss: 0.3135 Acc: 0.9367\n",
            "\n",
            "val Loss: 3.6246 Acc: 0.5000\n",
            "\n",
            "Epoch 483/499:\n",
            "train Loss: 0.3131 Acc: 0.9367\n",
            "\n",
            "val Loss: 3.6300 Acc: 0.5000\n",
            "\n",
            "Epoch 484/499:\n",
            "train Loss: 0.3127 Acc: 0.9367\n",
            "\n",
            "val Loss: 3.6353 Acc: 0.5000\n",
            "\n",
            "Epoch 485/499:\n",
            "train Loss: 0.3123 Acc: 0.9367\n",
            "\n",
            "val Loss: 3.6407 Acc: 0.5000\n",
            "\n",
            "Epoch 486/499:\n",
            "train Loss: 0.3119 Acc: 0.9367\n",
            "\n",
            "val Loss: 3.6460 Acc: 0.5000\n",
            "\n",
            "Epoch 487/499:\n",
            "train Loss: 0.3115 Acc: 0.9367\n",
            "\n",
            "val Loss: 3.6513 Acc: 0.5000\n",
            "\n",
            "Epoch 488/499:\n",
            "train Loss: 0.3111 Acc: 0.9367\n",
            "\n",
            "val Loss: 3.6567 Acc: 0.5000\n",
            "\n",
            "Epoch 489/499:\n",
            "train Loss: 0.3107 Acc: 0.9375\n",
            "\n",
            "val Loss: 3.6620 Acc: 0.5000\n",
            "\n",
            "Epoch 490/499:\n",
            "train Loss: 0.3103 Acc: 0.9375\n",
            "\n",
            "val Loss: 3.6673 Acc: 0.5000\n",
            "\n",
            "Epoch 491/499:\n",
            "train Loss: 0.3100 Acc: 0.9375\n",
            "\n",
            "val Loss: 3.6726 Acc: 0.5000\n",
            "\n",
            "Epoch 492/499:\n",
            "train Loss: 0.3096 Acc: 0.9375\n",
            "\n",
            "val Loss: 3.6778 Acc: 0.5000\n",
            "\n",
            "Epoch 493/499:\n",
            "train Loss: 0.3092 Acc: 0.9375\n",
            "\n",
            "val Loss: 3.6831 Acc: 0.5000\n",
            "\n",
            "Epoch 494/499:\n",
            "train Loss: 0.3088 Acc: 0.9375\n",
            "\n",
            "val Loss: 3.6884 Acc: 0.5000\n",
            "\n",
            "Epoch 495/499:\n",
            "train Loss: 0.3084 Acc: 0.9375\n",
            "\n",
            "val Loss: 3.6936 Acc: 0.5000\n",
            "\n",
            "Epoch 496/499:\n",
            "train Loss: 0.3080 Acc: 0.9375\n",
            "\n",
            "val Loss: 3.6989 Acc: 0.5000\n",
            "\n",
            "Epoch 497/499:\n",
            "train Loss: 0.3076 Acc: 0.9375\n",
            "\n",
            "val Loss: 3.7041 Acc: 0.5000\n",
            "\n",
            "Epoch 498/499:\n",
            "train Loss: 0.3072 Acc: 0.9375\n",
            "\n",
            "val Loss: 3.7093 Acc: 0.5000\n",
            "\n",
            "Epoch 499/499:\n",
            "train Loss: 0.3068 Acc: 0.9375\n",
            "\n",
            "val Loss: 3.7146 Acc: 0.5000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f47q_lMXGJEv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "a975b6ac-7fc5-4149-f96f-9a77bab7b6e1"
      },
      "source": [
        "net.plot_loss()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CapH4bK_ScK1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "9a97d3d2-6882-4af2-cd2f-e4307a08c304"
      },
      "source": [
        "net.plot_acc()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_OS5K01ZSer0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}