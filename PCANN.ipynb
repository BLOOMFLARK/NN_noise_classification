{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "PCANN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8az9TUBPNn3",
        "colab_type": "code",
        "outputId": "3e7e7883-5cd3-479d-e01c-989cebae9bc7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZOKuZLzPKT1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn.functional as F\n",
        "from sklearn.decomposition import PCA, IncrementalPCA\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "from torchvision import transforms, models, datasets\n",
        "\n",
        "import random\n",
        "\n",
        "\n",
        "class PCANet(torch.nn.Module):\n",
        "    def __init__(self, num_filters: list, filters_sizes: list, batch_size=256):\n",
        "        super(PCANet, self).__init__()\n",
        "        self.params = {\n",
        "            'num_filters': num_filters,\n",
        "            'filters_sizes': filters_sizes,\n",
        "        }\n",
        "        self.W_1 = None\n",
        "        self.W_2 = None\n",
        "        self.fc = torch.nn.Linear(30250, 2, bias=True)\n",
        "        # self.act1 = torch.nn.ReLU()\n",
        "        # self.fc2 = torch.nn.Linear(100, 2, bias=True)\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.conv2d(x, self.W_1)\n",
        "        N1, C1, H1, W1 = x.shape\n",
        "\n",
        "        x = F.conv2d(x, self.W_2)\n",
        "        N, C, H, W = x.shape\n",
        "\n",
        "        x_flat = x.view(N, C * H * W)\n",
        "\n",
        "        x_flat = self.fc(x_flat)\n",
        "        # x_flat = self.act1(x_flat)\n",
        "        # x_flat = self.fc2(x_flat)\n",
        "        return x_flat\n",
        "            \n",
        "    @staticmethod        \n",
        "    def _extract_image_patches(imgs: torch.Tensor, filter_size, stride=1, remove_mean=True):\n",
        "        # imgs.shape = (N, C, H, W) -> (N, 1, H, W) \n",
        "        # так должно быть, но сюда могут прийти не grayscale изображения первого шага, а со второго\n",
        "        # на котором применено L1 фильтров -> L1 каналов\n",
        "        N, n_channels, H, W = imgs.shape\n",
        "        \n",
        "        if n_channels > 1:\n",
        "            # изображение вида (N, C, H, W) - N C-канальных изображений\n",
        "            # приводим к виду (N*C, 1, H, W) - N*C одно-канальных изображений\n",
        "            imgs = imgs.view(-1, 1, H, W)\n",
        "        print('images shape', imgs.shape)\n",
        "            \n",
        "        k = filter_size\n",
        "        patches = torch.nn.functional.unfold(imgs, k, padding=k//2) # (N, k^2, H*W)\n",
        "        print('patches_shape, ', patches.shape)\n",
        "        print('should be patches shape, ', (imgs.shape[0], k**2, H*W))\n",
        "        \n",
        "        if remove_mean:\n",
        "            patches -= patches.mean(dim=1, keepdim=True) # последнее измерение - количество патчей\n",
        "        \n",
        "        print('filter_size', k)\n",
        "        X = patches.view(k**2, -1) # (k^2, N*H*W)\n",
        "\n",
        "        return X\n",
        "    \n",
        "    def _convolve(self, imgs: torch.Tensor, filter_bank: torch.Tensor) -> torch.Tensor:\n",
        "        weight = filter_bank\n",
        "        output = F.conv2d(imgs, weight) #, padding=padding)\n",
        "        return output\n",
        "    \n",
        "    def _first_stage(self, imgs: torch.Tensor, train: bool) -> torch.Tensor:\n",
        "        # (N, C, H, W) image\n",
        "        # (train_size, 1, H, W) - grayscale\n",
        "        assert imgs.dim() == 4 and imgs.nelement() > 0\n",
        "\n",
        "        print('PCANet first stage...')\n",
        "\n",
        "        if train:\n",
        "            # достаем все патчи из всех N изображений\n",
        "            filter_size1 = self.params['filters_sizes'][0]\n",
        "            X = self._extract_image_patches(\n",
        "                imgs, filter_size1)\n",
        "            \n",
        "            n_filters = self.params['num_filters'][0]\n",
        "            \n",
        "            eigenvectors = self.get_pca_eigenvectors(X, n_components=n_filters, batch_size=self.batch_size)\n",
        "            self.W_1 = torch.FloatTensor(eigenvectors).view(n_filters, 1, filter_size1, filter_size1)\n",
        "         \n",
        "        I = self._convolve(imgs, self.W_1)  # (N, 1, H, W) * (L1, k1, k1) -> (N, L1, H', W')\n",
        "        return I\n",
        "    \n",
        "    @staticmethod\n",
        "    def conv_output_size(w, filter_size, padding=0, stride=1):\n",
        "        return int((w - filter_size + 2 * padding) / stride + 1)\n",
        "    \n",
        "    @staticmethod\n",
        "    def get_pca_eigenvectors(X, n_components, batch_size=100):\n",
        "        ipca = IncrementalPCA(n_components=n_components, batch_size=batch_size)\n",
        "        print('pca fitting ...')\n",
        "        ipca.fit(X @ X.t())\n",
        "        eigenvectors = ipca.components_\n",
        "        print('eigenvectors shape:', eigenvectors.shape)\n",
        "        return eigenvectors\n",
        "        \n",
        "    def _second_stage(self, I: torch.Tensor, train):\n",
        "        print('PCANet second stage...')\n",
        "        # I: (N, L1, H, W)\n",
        "        if train:\n",
        "            N, L1, H, W = I.shape\n",
        "            filter_size2 = self.params['filters_sizes'][1]\n",
        "            n_filters2 = self.params['num_filters'][1]\n",
        "            n_filters1 = self.params['num_filters'][0]\n",
        "            \n",
        "            H_new = self.conv_output_size(I.shape[2], filter_size2)\n",
        "            W_new = self.conv_output_size(I.shape[3], filter_size2)\n",
        "            \n",
        "            X = self._extract_image_patches(I, filter_size2)\n",
        "            print('X_SHAPE ', X.shape)\n",
        "            eigenvectors = self.get_pca_eigenvectors(X, n_components=n_filters2, batch_size=self.batch_size)\n",
        "            W_2 = torch.FloatTensor(eigenvectors).view(n_filters2, 1, filter_size2, filter_size2) # (L2, 1, k2, k2)\n",
        "            self.W_2 = W_2.repeat(1, n_filters1, 1, 1) # (L2, L1, k2, k2) - повторяет L1 раз для конкретного l из L2\n",
        "        return self._convolve(I, self.W_2)\n",
        "    \n",
        "    def run(self, images):\n",
        "        # Создаем фильтры\n",
        "        # images: (N, 1, H, W)\n",
        "        I = self._first_stage(images, train=True)\n",
        "        print(\"I \", I.shape)\n",
        "        II = self._second_stage(I, train=True)\n",
        "        N, C, H, W = II.shape\n",
        "        # self.fc = torch.nn.Linear(H * W, 2, bias=True)\n",
        "        \n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y9cpvOhiPbwl",
        "colab_type": "code",
        "outputId": "5e88b808-8112-44c3-ceff-6e30c68cf0f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "data_root = 'drive/My Drive/dl_noise_classification/data/'\n",
        "train_dir = 'train'\n",
        "val_dir = 'val'\n",
        "class_names = ['awgn', 'bayer']\n",
        "\n",
        "train_dir = os.path.join(data_root, train_dir)\n",
        "val_dir = os.path.join(data_root, val_dir)\n",
        "\n",
        "train_dir"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'drive/My Drive/dl_noise_classification/data/train'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ag7yTvPNPKT7",
        "colab_type": "code",
        "outputId": "84c5ee65-5e98-49bb-bf81-b0e1fb4cf7c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "net = PCANet([5, 10], [3, 8])\n",
        "net.params\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "net = net.to(device)"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x5GHuftbPKUC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "SEED = 1235\n",
        "\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "num_epochs = 5000\n",
        "batch_size = 150\n",
        "lr = 1e-6\n",
        "\n",
        "loss = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
        "#optimizer = torch.optim.SGD(net.parameters(), lr=lr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5RdNqCUxPKUG",
        "colab_type": "code",
        "outputId": "158cd08e-1e4e-4894-d07d-322f4847cbc2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "train_transforms = transforms.Compose([\n",
        "    #transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
        "    transforms.Grayscale(num_output_channels=1),\n",
        "    transforms.Resize((64, 64)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "val_transforms = transforms.Compose([\n",
        "    #transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
        "    transforms.Grayscale(num_output_channels=1),\n",
        "    transforms.Resize((64, 64)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "\n",
        "train_dataset = datasets.ImageFolder(train_dir, train_transforms)\n",
        "val_dataset = datasets.ImageFolder(val_dir, val_transforms)\n",
        "\n",
        "train_size = len(train_dataset)\n",
        "val_size = len(val_dataset)\n",
        "\n",
        "all_train = torch.utils.data.DataLoader(\n",
        "    train_dataset, batch_size=train_size, shuffle=False, num_workers=batch_size)\n",
        "\n",
        "train_dataloader = torch.utils.data.DataLoader(\n",
        "    train_dataset, batch_size=batch_size, shuffle=True, num_workers=batch_size)\n",
        "\n",
        "val_dataloader = torch.utils.data.DataLoader(\n",
        "    val_dataset, batch_size=batch_size, shuffle=False, num_workers=batch_size)\n",
        "\n",
        "all_val = torch.utils.data.DataLoader(\n",
        "    val_dataset, batch_size=train_size, shuffle=False, num_workers=batch_size)\n",
        "\n",
        "print(\"TRAIN_SIZE: {}\\n VAL_SIZE: {}\".format(train_size, val_size))"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TRAIN_SIZE: 750\n",
            " VAL_SIZE: 150\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hJj_d24c-VB7",
        "colab_type": "code",
        "outputId": "03f9fad0-b722-4fd5-e7b3-9fae8636c016",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print('all val data loading ...')\n",
        "val_data = next(iter(all_val))\n",
        "print('all train data loading ...')\n",
        "train_data = next(iter(all_train))"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "all val data loading ...\n",
            "all train data loading ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oHhiI3-0U3PQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from time import time\n",
        "\n",
        "val_loss = np.zeros(num_epochs)\n",
        "train_loss = np.zeros(num_epochs)\n",
        "\n",
        "val_acc = np.zeros(num_epochs)\n",
        "train_acc = np.zeros(num_epochs)\n",
        "\n",
        "\n",
        "def train_model(model, loss, optimizer, scheduler, num_epochs):\n",
        "    print('Making filters....')\n",
        "    t_start = time()\n",
        "    model.run(train_data[0])\n",
        "    print('TIME: ', time() - t_start)\n",
        "\n",
        "\n",
        "    model.W_1 = model.W_1.to(device)\n",
        "    model.W_2 = model.W_2.to(device)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "\n",
        "        print('Epoch {}/{}:'.format(epoch, num_epochs - 1), flush=True)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train']:\n",
        "            if phase == 'train':\n",
        "                data = val_data\n",
        "                model.train()  # training mode\n",
        "                history_acc = train_acc\n",
        "                history_loss = train_loss\n",
        "            else:\n",
        "                data = val_data\n",
        "                model.eval()   # evaluate mode (dropout + bn)\n",
        "                history_acc = val_acc\n",
        "                history_loss = val_loss\n",
        "\n",
        "            running_loss = 0.\n",
        "            running_acc = 0.\n",
        "\n",
        "            # Iterate over data.\n",
        "            inputs, labels = data\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # forward and backward\n",
        "            with torch.set_grad_enabled(phase=='train'):\n",
        "                preds = model(inputs)\n",
        "                loss_value = loss(preds, labels)\n",
        "                preds_class = preds.argmax(dim=1)\n",
        "\n",
        "                # backward + optimize only if in training phase\n",
        "                if phase == 'train':\n",
        "                    loss_value.backward()\n",
        "                    optimizer.step()\n",
        "\n",
        "            # statistics\n",
        "            running_loss += loss_value.cpu().item()\n",
        "            running_acc += (preds_class.cpu() == labels.cpu().data).float().mean()\n",
        "            \n",
        "            epoch_loss = running_loss\n",
        "            epoch_acc = running_acc\n",
        "            history_acc[epoch] = epoch_acc\n",
        "            history_loss[epoch] = epoch_loss\n",
        "\n",
        "            # запоминаем модель по лоссу\n",
        "\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}\\n'.format(phase, epoch_loss, epoch_acc), flush=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iYahGgdxPKUM",
        "colab_type": "code",
        "outputId": "089faeb0-d46c-4fb3-c6bc-ae4cab110544",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "train_model(net, loss, optimizer, None, num_epochs=num_epochs)"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "\n",
            "Epoch 3334/4999:\n",
            "train Loss: 0.4553 Acc: 0.8667\n",
            "\n",
            "Epoch 3335/4999:\n",
            "train Loss: 0.4553 Acc: 0.8667\n",
            "\n",
            "Epoch 3336/4999:\n",
            "train Loss: 0.4553 Acc: 0.8667\n",
            "\n",
            "Epoch 3337/4999:\n",
            "train Loss: 0.4552 Acc: 0.8667\n",
            "\n",
            "Epoch 3338/4999:\n",
            "train Loss: 0.4552 Acc: 0.8667\n",
            "\n",
            "Epoch 3339/4999:\n",
            "train Loss: 0.4552 Acc: 0.8667\n",
            "\n",
            "Epoch 3340/4999:\n",
            "train Loss: 0.4551 Acc: 0.8667\n",
            "\n",
            "Epoch 3341/4999:\n",
            "train Loss: 0.4551 Acc: 0.8667\n",
            "\n",
            "Epoch 3342/4999:\n",
            "train Loss: 0.4551 Acc: 0.8667\n",
            "\n",
            "Epoch 3343/4999:\n",
            "train Loss: 0.4551 Acc: 0.8667\n",
            "\n",
            "Epoch 3344/4999:\n",
            "train Loss: 0.4550 Acc: 0.8667\n",
            "\n",
            "Epoch 3345/4999:\n",
            "train Loss: 0.4550 Acc: 0.8667\n",
            "\n",
            "Epoch 3346/4999:\n",
            "train Loss: 0.4550 Acc: 0.8667\n",
            "\n",
            "Epoch 3347/4999:\n",
            "train Loss: 0.4549 Acc: 0.8667\n",
            "\n",
            "Epoch 3348/4999:\n",
            "train Loss: 0.4549 Acc: 0.8667\n",
            "\n",
            "Epoch 3349/4999:\n",
            "train Loss: 0.4549 Acc: 0.8667\n",
            "\n",
            "Epoch 3350/4999:\n",
            "train Loss: 0.4548 Acc: 0.8667\n",
            "\n",
            "Epoch 3351/4999:\n",
            "train Loss: 0.4548 Acc: 0.8667\n",
            "\n",
            "Epoch 3352/4999:\n",
            "train Loss: 0.4548 Acc: 0.8667\n",
            "\n",
            "Epoch 3353/4999:\n",
            "train Loss: 0.4547 Acc: 0.8667\n",
            "\n",
            "Epoch 3354/4999:\n",
            "train Loss: 0.4547 Acc: 0.8667\n",
            "\n",
            "Epoch 3355/4999:\n",
            "train Loss: 0.4547 Acc: 0.8667\n",
            "\n",
            "Epoch 3356/4999:\n",
            "train Loss: 0.4547 Acc: 0.8667\n",
            "\n",
            "Epoch 3357/4999:\n",
            "train Loss: 0.4546 Acc: 0.8667\n",
            "\n",
            "Epoch 3358/4999:\n",
            "train Loss: 0.4546 Acc: 0.8667\n",
            "\n",
            "Epoch 3359/4999:\n",
            "train Loss: 0.4546 Acc: 0.8667\n",
            "\n",
            "Epoch 3360/4999:\n",
            "train Loss: 0.4545 Acc: 0.8667\n",
            "\n",
            "Epoch 3361/4999:\n",
            "train Loss: 0.4545 Acc: 0.8667\n",
            "\n",
            "Epoch 3362/4999:\n",
            "train Loss: 0.4545 Acc: 0.8667\n",
            "\n",
            "Epoch 3363/4999:\n",
            "train Loss: 0.4544 Acc: 0.8667\n",
            "\n",
            "Epoch 3364/4999:\n",
            "train Loss: 0.4544 Acc: 0.8667\n",
            "\n",
            "Epoch 3365/4999:\n",
            "train Loss: 0.4544 Acc: 0.8667\n",
            "\n",
            "Epoch 3366/4999:\n",
            "train Loss: 0.4544 Acc: 0.8667\n",
            "\n",
            "Epoch 3367/4999:\n",
            "train Loss: 0.4543 Acc: 0.8667\n",
            "\n",
            "Epoch 3368/4999:\n",
            "train Loss: 0.4543 Acc: 0.8667\n",
            "\n",
            "Epoch 3369/4999:\n",
            "train Loss: 0.4543 Acc: 0.8667\n",
            "\n",
            "Epoch 3370/4999:\n",
            "train Loss: 0.4542 Acc: 0.8667\n",
            "\n",
            "Epoch 3371/4999:\n",
            "train Loss: 0.4542 Acc: 0.8667\n",
            "\n",
            "Epoch 3372/4999:\n",
            "train Loss: 0.4542 Acc: 0.8667\n",
            "\n",
            "Epoch 3373/4999:\n",
            "train Loss: 0.4541 Acc: 0.8667\n",
            "\n",
            "Epoch 3374/4999:\n",
            "train Loss: 0.4541 Acc: 0.8667\n",
            "\n",
            "Epoch 3375/4999:\n",
            "train Loss: 0.4541 Acc: 0.8667\n",
            "\n",
            "Epoch 3376/4999:\n",
            "train Loss: 0.4541 Acc: 0.8667\n",
            "\n",
            "Epoch 3377/4999:\n",
            "train Loss: 0.4540 Acc: 0.8667\n",
            "\n",
            "Epoch 3378/4999:\n",
            "train Loss: 0.4540 Acc: 0.8667\n",
            "\n",
            "Epoch 3379/4999:\n",
            "train Loss: 0.4540 Acc: 0.8667\n",
            "\n",
            "Epoch 3380/4999:\n",
            "train Loss: 0.4539 Acc: 0.8667\n",
            "\n",
            "Epoch 3381/4999:\n",
            "train Loss: 0.4539 Acc: 0.8667\n",
            "\n",
            "Epoch 3382/4999:\n",
            "train Loss: 0.4539 Acc: 0.8667\n",
            "\n",
            "Epoch 3383/4999:\n",
            "train Loss: 0.4538 Acc: 0.8667\n",
            "\n",
            "Epoch 3384/4999:\n",
            "train Loss: 0.4538 Acc: 0.8667\n",
            "\n",
            "Epoch 3385/4999:\n",
            "train Loss: 0.4538 Acc: 0.8667\n",
            "\n",
            "Epoch 3386/4999:\n",
            "train Loss: 0.4538 Acc: 0.8667\n",
            "\n",
            "Epoch 3387/4999:\n",
            "train Loss: 0.4537 Acc: 0.8667\n",
            "\n",
            "Epoch 3388/4999:\n",
            "train Loss: 0.4537 Acc: 0.8667\n",
            "\n",
            "Epoch 3389/4999:\n",
            "train Loss: 0.4537 Acc: 0.8667\n",
            "\n",
            "Epoch 3390/4999:\n",
            "train Loss: 0.4536 Acc: 0.8667\n",
            "\n",
            "Epoch 3391/4999:\n",
            "train Loss: 0.4536 Acc: 0.8667\n",
            "\n",
            "Epoch 3392/4999:\n",
            "train Loss: 0.4536 Acc: 0.8667\n",
            "\n",
            "Epoch 3393/4999:\n",
            "train Loss: 0.4535 Acc: 0.8667\n",
            "\n",
            "Epoch 3394/4999:\n",
            "train Loss: 0.4535 Acc: 0.8667\n",
            "\n",
            "Epoch 3395/4999:\n",
            "train Loss: 0.4535 Acc: 0.8667\n",
            "\n",
            "Epoch 3396/4999:\n",
            "train Loss: 0.4535 Acc: 0.8667\n",
            "\n",
            "Epoch 3397/4999:\n",
            "train Loss: 0.4534 Acc: 0.8667\n",
            "\n",
            "Epoch 3398/4999:\n",
            "train Loss: 0.4534 Acc: 0.8667\n",
            "\n",
            "Epoch 3399/4999:\n",
            "train Loss: 0.4534 Acc: 0.8667\n",
            "\n",
            "Epoch 3400/4999:\n",
            "train Loss: 0.4533 Acc: 0.8667\n",
            "\n",
            "Epoch 3401/4999:\n",
            "train Loss: 0.4533 Acc: 0.8667\n",
            "\n",
            "Epoch 3402/4999:\n",
            "train Loss: 0.4533 Acc: 0.8667\n",
            "\n",
            "Epoch 3403/4999:\n",
            "train Loss: 0.4532 Acc: 0.8667\n",
            "\n",
            "Epoch 3404/4999:\n",
            "train Loss: 0.4532 Acc: 0.8667\n",
            "\n",
            "Epoch 3405/4999:\n",
            "train Loss: 0.4532 Acc: 0.8667\n",
            "\n",
            "Epoch 3406/4999:\n",
            "train Loss: 0.4532 Acc: 0.8667\n",
            "\n",
            "Epoch 3407/4999:\n",
            "train Loss: 0.4531 Acc: 0.8667\n",
            "\n",
            "Epoch 3408/4999:\n",
            "train Loss: 0.4531 Acc: 0.8667\n",
            "\n",
            "Epoch 3409/4999:\n",
            "train Loss: 0.4531 Acc: 0.8667\n",
            "\n",
            "Epoch 3410/4999:\n",
            "train Loss: 0.4530 Acc: 0.8667\n",
            "\n",
            "Epoch 3411/4999:\n",
            "train Loss: 0.4530 Acc: 0.8667\n",
            "\n",
            "Epoch 3412/4999:\n",
            "train Loss: 0.4530 Acc: 0.8667\n",
            "\n",
            "Epoch 3413/4999:\n",
            "train Loss: 0.4529 Acc: 0.8667\n",
            "\n",
            "Epoch 3414/4999:\n",
            "train Loss: 0.4529 Acc: 0.8667\n",
            "\n",
            "Epoch 3415/4999:\n",
            "train Loss: 0.4529 Acc: 0.8667\n",
            "\n",
            "Epoch 3416/4999:\n",
            "train Loss: 0.4529 Acc: 0.8667\n",
            "\n",
            "Epoch 3417/4999:\n",
            "train Loss: 0.4528 Acc: 0.8667\n",
            "\n",
            "Epoch 3418/4999:\n",
            "train Loss: 0.4528 Acc: 0.8667\n",
            "\n",
            "Epoch 3419/4999:\n",
            "train Loss: 0.4528 Acc: 0.8667\n",
            "\n",
            "Epoch 3420/4999:\n",
            "train Loss: 0.4527 Acc: 0.8667\n",
            "\n",
            "Epoch 3421/4999:\n",
            "train Loss: 0.4527 Acc: 0.8667\n",
            "\n",
            "Epoch 3422/4999:\n",
            "train Loss: 0.4527 Acc: 0.8667\n",
            "\n",
            "Epoch 3423/4999:\n",
            "train Loss: 0.4526 Acc: 0.8667\n",
            "\n",
            "Epoch 3424/4999:\n",
            "train Loss: 0.4526 Acc: 0.8667\n",
            "\n",
            "Epoch 3425/4999:\n",
            "train Loss: 0.4526 Acc: 0.8667\n",
            "\n",
            "Epoch 3426/4999:\n",
            "train Loss: 0.4526 Acc: 0.8667\n",
            "\n",
            "Epoch 3427/4999:\n",
            "train Loss: 0.4525 Acc: 0.8667\n",
            "\n",
            "Epoch 3428/4999:\n",
            "train Loss: 0.4525 Acc: 0.8667\n",
            "\n",
            "Epoch 3429/4999:\n",
            "train Loss: 0.4525 Acc: 0.8667\n",
            "\n",
            "Epoch 3430/4999:\n",
            "train Loss: 0.4524 Acc: 0.8667\n",
            "\n",
            "Epoch 3431/4999:\n",
            "train Loss: 0.4524 Acc: 0.8667\n",
            "\n",
            "Epoch 3432/4999:\n",
            "train Loss: 0.4524 Acc: 0.8667\n",
            "\n",
            "Epoch 3433/4999:\n",
            "train Loss: 0.4523 Acc: 0.8667\n",
            "\n",
            "Epoch 3434/4999:\n",
            "train Loss: 0.4523 Acc: 0.8667\n",
            "\n",
            "Epoch 3435/4999:\n",
            "train Loss: 0.4523 Acc: 0.8667\n",
            "\n",
            "Epoch 3436/4999:\n",
            "train Loss: 0.4523 Acc: 0.8667\n",
            "\n",
            "Epoch 3437/4999:\n",
            "train Loss: 0.4522 Acc: 0.8667\n",
            "\n",
            "Epoch 3438/4999:\n",
            "train Loss: 0.4522 Acc: 0.8667\n",
            "\n",
            "Epoch 3439/4999:\n",
            "train Loss: 0.4522 Acc: 0.8667\n",
            "\n",
            "Epoch 3440/4999:\n",
            "train Loss: 0.4521 Acc: 0.8667\n",
            "\n",
            "Epoch 3441/4999:\n",
            "train Loss: 0.4521 Acc: 0.8667\n",
            "\n",
            "Epoch 3442/4999:\n",
            "train Loss: 0.4521 Acc: 0.8667\n",
            "\n",
            "Epoch 3443/4999:\n",
            "train Loss: 0.4520 Acc: 0.8667\n",
            "\n",
            "Epoch 3444/4999:\n",
            "train Loss: 0.4520 Acc: 0.8667\n",
            "\n",
            "Epoch 3445/4999:\n",
            "train Loss: 0.4520 Acc: 0.8667\n",
            "\n",
            "Epoch 3446/4999:\n",
            "train Loss: 0.4520 Acc: 0.8667\n",
            "\n",
            "Epoch 3447/4999:\n",
            "train Loss: 0.4519 Acc: 0.8667\n",
            "\n",
            "Epoch 3448/4999:\n",
            "train Loss: 0.4519 Acc: 0.8667\n",
            "\n",
            "Epoch 3449/4999:\n",
            "train Loss: 0.4519 Acc: 0.8667\n",
            "\n",
            "Epoch 3450/4999:\n",
            "train Loss: 0.4518 Acc: 0.8667\n",
            "\n",
            "Epoch 3451/4999:\n",
            "train Loss: 0.4518 Acc: 0.8667\n",
            "\n",
            "Epoch 3452/4999:\n",
            "train Loss: 0.4518 Acc: 0.8667\n",
            "\n",
            "Epoch 3453/4999:\n",
            "train Loss: 0.4517 Acc: 0.8667\n",
            "\n",
            "Epoch 3454/4999:\n",
            "train Loss: 0.4517 Acc: 0.8667\n",
            "\n",
            "Epoch 3455/4999:\n",
            "train Loss: 0.4517 Acc: 0.8667\n",
            "\n",
            "Epoch 3456/4999:\n",
            "train Loss: 0.4517 Acc: 0.8667\n",
            "\n",
            "Epoch 3457/4999:\n",
            "train Loss: 0.4516 Acc: 0.8667\n",
            "\n",
            "Epoch 3458/4999:\n",
            "train Loss: 0.4516 Acc: 0.8667\n",
            "\n",
            "Epoch 3459/4999:\n",
            "train Loss: 0.4516 Acc: 0.8667\n",
            "\n",
            "Epoch 3460/4999:\n",
            "train Loss: 0.4515 Acc: 0.8667\n",
            "\n",
            "Epoch 3461/4999:\n",
            "train Loss: 0.4515 Acc: 0.8667\n",
            "\n",
            "Epoch 3462/4999:\n",
            "train Loss: 0.4515 Acc: 0.8667\n",
            "\n",
            "Epoch 3463/4999:\n",
            "train Loss: 0.4514 Acc: 0.8667\n",
            "\n",
            "Epoch 3464/4999:\n",
            "train Loss: 0.4514 Acc: 0.8667\n",
            "\n",
            "Epoch 3465/4999:\n",
            "train Loss: 0.4514 Acc: 0.8667\n",
            "\n",
            "Epoch 3466/4999:\n",
            "train Loss: 0.4514 Acc: 0.8667\n",
            "\n",
            "Epoch 3467/4999:\n",
            "train Loss: 0.4513 Acc: 0.8667\n",
            "\n",
            "Epoch 3468/4999:\n",
            "train Loss: 0.4513 Acc: 0.8667\n",
            "\n",
            "Epoch 3469/4999:\n",
            "train Loss: 0.4513 Acc: 0.8667\n",
            "\n",
            "Epoch 3470/4999:\n",
            "train Loss: 0.4512 Acc: 0.8667\n",
            "\n",
            "Epoch 3471/4999:\n",
            "train Loss: 0.4512 Acc: 0.8667\n",
            "\n",
            "Epoch 3472/4999:\n",
            "train Loss: 0.4512 Acc: 0.8667\n",
            "\n",
            "Epoch 3473/4999:\n",
            "train Loss: 0.4511 Acc: 0.8667\n",
            "\n",
            "Epoch 3474/4999:\n",
            "train Loss: 0.4511 Acc: 0.8667\n",
            "\n",
            "Epoch 3475/4999:\n",
            "train Loss: 0.4511 Acc: 0.8667\n",
            "\n",
            "Epoch 3476/4999:\n",
            "train Loss: 0.4511 Acc: 0.8667\n",
            "\n",
            "Epoch 3477/4999:\n",
            "train Loss: 0.4510 Acc: 0.8667\n",
            "\n",
            "Epoch 3478/4999:\n",
            "train Loss: 0.4510 Acc: 0.8667\n",
            "\n",
            "Epoch 3479/4999:\n",
            "train Loss: 0.4510 Acc: 0.8667\n",
            "\n",
            "Epoch 3480/4999:\n",
            "train Loss: 0.4509 Acc: 0.8667\n",
            "\n",
            "Epoch 3481/4999:\n",
            "train Loss: 0.4509 Acc: 0.8667\n",
            "\n",
            "Epoch 3482/4999:\n",
            "train Loss: 0.4509 Acc: 0.8667\n",
            "\n",
            "Epoch 3483/4999:\n",
            "train Loss: 0.4508 Acc: 0.8667\n",
            "\n",
            "Epoch 3484/4999:\n",
            "train Loss: 0.4508 Acc: 0.8667\n",
            "\n",
            "Epoch 3485/4999:\n",
            "train Loss: 0.4508 Acc: 0.8667\n",
            "\n",
            "Epoch 3486/4999:\n",
            "train Loss: 0.4508 Acc: 0.8667\n",
            "\n",
            "Epoch 3487/4999:\n",
            "train Loss: 0.4507 Acc: 0.8667\n",
            "\n",
            "Epoch 3488/4999:\n",
            "train Loss: 0.4507 Acc: 0.8667\n",
            "\n",
            "Epoch 3489/4999:\n",
            "train Loss: 0.4507 Acc: 0.8667\n",
            "\n",
            "Epoch 3490/4999:\n",
            "train Loss: 0.4506 Acc: 0.8667\n",
            "\n",
            "Epoch 3491/4999:\n",
            "train Loss: 0.4506 Acc: 0.8667\n",
            "\n",
            "Epoch 3492/4999:\n",
            "train Loss: 0.4506 Acc: 0.8667\n",
            "\n",
            "Epoch 3493/4999:\n",
            "train Loss: 0.4506 Acc: 0.8667\n",
            "\n",
            "Epoch 3494/4999:\n",
            "train Loss: 0.4505 Acc: 0.8667\n",
            "\n",
            "Epoch 3495/4999:\n",
            "train Loss: 0.4505 Acc: 0.8667\n",
            "\n",
            "Epoch 3496/4999:\n",
            "train Loss: 0.4505 Acc: 0.8667\n",
            "\n",
            "Epoch 3497/4999:\n",
            "train Loss: 0.4504 Acc: 0.8667\n",
            "\n",
            "Epoch 3498/4999:\n",
            "train Loss: 0.4504 Acc: 0.8667\n",
            "\n",
            "Epoch 3499/4999:\n",
            "train Loss: 0.4504 Acc: 0.8667\n",
            "\n",
            "Epoch 3500/4999:\n",
            "train Loss: 0.4503 Acc: 0.8667\n",
            "\n",
            "Epoch 3501/4999:\n",
            "train Loss: 0.4503 Acc: 0.8667\n",
            "\n",
            "Epoch 3502/4999:\n",
            "train Loss: 0.4503 Acc: 0.8667\n",
            "\n",
            "Epoch 3503/4999:\n",
            "train Loss: 0.4503 Acc: 0.8667\n",
            "\n",
            "Epoch 3504/4999:\n",
            "train Loss: 0.4502 Acc: 0.8667\n",
            "\n",
            "Epoch 3505/4999:\n",
            "train Loss: 0.4502 Acc: 0.8667\n",
            "\n",
            "Epoch 3506/4999:\n",
            "train Loss: 0.4502 Acc: 0.8667\n",
            "\n",
            "Epoch 3507/4999:\n",
            "train Loss: 0.4501 Acc: 0.8667\n",
            "\n",
            "Epoch 3508/4999:\n",
            "train Loss: 0.4501 Acc: 0.8667\n",
            "\n",
            "Epoch 3509/4999:\n",
            "train Loss: 0.4501 Acc: 0.8667\n",
            "\n",
            "Epoch 3510/4999:\n",
            "train Loss: 0.4500 Acc: 0.8667\n",
            "\n",
            "Epoch 3511/4999:\n",
            "train Loss: 0.4500 Acc: 0.8667\n",
            "\n",
            "Epoch 3512/4999:\n",
            "train Loss: 0.4500 Acc: 0.8667\n",
            "\n",
            "Epoch 3513/4999:\n",
            "train Loss: 0.4500 Acc: 0.8667\n",
            "\n",
            "Epoch 3514/4999:\n",
            "train Loss: 0.4499 Acc: 0.8667\n",
            "\n",
            "Epoch 3515/4999:\n",
            "train Loss: 0.4499 Acc: 0.8667\n",
            "\n",
            "Epoch 3516/4999:\n",
            "train Loss: 0.4499 Acc: 0.8667\n",
            "\n",
            "Epoch 3517/4999:\n",
            "train Loss: 0.4498 Acc: 0.8667\n",
            "\n",
            "Epoch 3518/4999:\n",
            "train Loss: 0.4498 Acc: 0.8667\n",
            "\n",
            "Epoch 3519/4999:\n",
            "train Loss: 0.4498 Acc: 0.8667\n",
            "\n",
            "Epoch 3520/4999:\n",
            "train Loss: 0.4497 Acc: 0.8667\n",
            "\n",
            "Epoch 3521/4999:\n",
            "train Loss: 0.4497 Acc: 0.8667\n",
            "\n",
            "Epoch 3522/4999:\n",
            "train Loss: 0.4497 Acc: 0.8667\n",
            "\n",
            "Epoch 3523/4999:\n",
            "train Loss: 0.4497 Acc: 0.8667\n",
            "\n",
            "Epoch 3524/4999:\n",
            "train Loss: 0.4496 Acc: 0.8667\n",
            "\n",
            "Epoch 3525/4999:\n",
            "train Loss: 0.4496 Acc: 0.8667\n",
            "\n",
            "Epoch 3526/4999:\n",
            "train Loss: 0.4496 Acc: 0.8667\n",
            "\n",
            "Epoch 3527/4999:\n",
            "train Loss: 0.4495 Acc: 0.8667\n",
            "\n",
            "Epoch 3528/4999:\n",
            "train Loss: 0.4495 Acc: 0.8667\n",
            "\n",
            "Epoch 3529/4999:\n",
            "train Loss: 0.4495 Acc: 0.8667\n",
            "\n",
            "Epoch 3530/4999:\n",
            "train Loss: 0.4495 Acc: 0.8667\n",
            "\n",
            "Epoch 3531/4999:\n",
            "train Loss: 0.4494 Acc: 0.8667\n",
            "\n",
            "Epoch 3532/4999:\n",
            "train Loss: 0.4494 Acc: 0.8667\n",
            "\n",
            "Epoch 3533/4999:\n",
            "train Loss: 0.4494 Acc: 0.8667\n",
            "\n",
            "Epoch 3534/4999:\n",
            "train Loss: 0.4493 Acc: 0.8667\n",
            "\n",
            "Epoch 3535/4999:\n",
            "train Loss: 0.4493 Acc: 0.8667\n",
            "\n",
            "Epoch 3536/4999:\n",
            "train Loss: 0.4493 Acc: 0.8667\n",
            "\n",
            "Epoch 3537/4999:\n",
            "train Loss: 0.4492 Acc: 0.8667\n",
            "\n",
            "Epoch 3538/4999:\n",
            "train Loss: 0.4492 Acc: 0.8667\n",
            "\n",
            "Epoch 3539/4999:\n",
            "train Loss: 0.4492 Acc: 0.8667\n",
            "\n",
            "Epoch 3540/4999:\n",
            "train Loss: 0.4492 Acc: 0.8667\n",
            "\n",
            "Epoch 3541/4999:\n",
            "train Loss: 0.4491 Acc: 0.8667\n",
            "\n",
            "Epoch 3542/4999:\n",
            "train Loss: 0.4491 Acc: 0.8667\n",
            "\n",
            "Epoch 3543/4999:\n",
            "train Loss: 0.4491 Acc: 0.8667\n",
            "\n",
            "Epoch 3544/4999:\n",
            "train Loss: 0.4490 Acc: 0.8667\n",
            "\n",
            "Epoch 3545/4999:\n",
            "train Loss: 0.4490 Acc: 0.8667\n",
            "\n",
            "Epoch 3546/4999:\n",
            "train Loss: 0.4490 Acc: 0.8667\n",
            "\n",
            "Epoch 3547/4999:\n",
            "train Loss: 0.4489 Acc: 0.8667\n",
            "\n",
            "Epoch 3548/4999:\n",
            "train Loss: 0.4489 Acc: 0.8667\n",
            "\n",
            "Epoch 3549/4999:\n",
            "train Loss: 0.4489 Acc: 0.8667\n",
            "\n",
            "Epoch 3550/4999:\n",
            "train Loss: 0.4489 Acc: 0.8667\n",
            "\n",
            "Epoch 3551/4999:\n",
            "train Loss: 0.4488 Acc: 0.8667\n",
            "\n",
            "Epoch 3552/4999:\n",
            "train Loss: 0.4488 Acc: 0.8667\n",
            "\n",
            "Epoch 3553/4999:\n",
            "train Loss: 0.4488 Acc: 0.8667\n",
            "\n",
            "Epoch 3554/4999:\n",
            "train Loss: 0.4487 Acc: 0.8667\n",
            "\n",
            "Epoch 3555/4999:\n",
            "train Loss: 0.4487 Acc: 0.8667\n",
            "\n",
            "Epoch 3556/4999:\n",
            "train Loss: 0.4487 Acc: 0.8667\n",
            "\n",
            "Epoch 3557/4999:\n",
            "train Loss: 0.4487 Acc: 0.8667\n",
            "\n",
            "Epoch 3558/4999:\n",
            "train Loss: 0.4486 Acc: 0.8667\n",
            "\n",
            "Epoch 3559/4999:\n",
            "train Loss: 0.4486 Acc: 0.8667\n",
            "\n",
            "Epoch 3560/4999:\n",
            "train Loss: 0.4486 Acc: 0.8667\n",
            "\n",
            "Epoch 3561/4999:\n",
            "train Loss: 0.4485 Acc: 0.8667\n",
            "\n",
            "Epoch 3562/4999:\n",
            "train Loss: 0.4485 Acc: 0.8667\n",
            "\n",
            "Epoch 3563/4999:\n",
            "train Loss: 0.4485 Acc: 0.8667\n",
            "\n",
            "Epoch 3564/4999:\n",
            "train Loss: 0.4484 Acc: 0.8667\n",
            "\n",
            "Epoch 3565/4999:\n",
            "train Loss: 0.4484 Acc: 0.8667\n",
            "\n",
            "Epoch 3566/4999:\n",
            "train Loss: 0.4484 Acc: 0.8667\n",
            "\n",
            "Epoch 3567/4999:\n",
            "train Loss: 0.4484 Acc: 0.8667\n",
            "\n",
            "Epoch 3568/4999:\n",
            "train Loss: 0.4483 Acc: 0.8667\n",
            "\n",
            "Epoch 3569/4999:\n",
            "train Loss: 0.4483 Acc: 0.8667\n",
            "\n",
            "Epoch 3570/4999:\n",
            "train Loss: 0.4483 Acc: 0.8667\n",
            "\n",
            "Epoch 3571/4999:\n",
            "train Loss: 0.4482 Acc: 0.8667\n",
            "\n",
            "Epoch 3572/4999:\n",
            "train Loss: 0.4482 Acc: 0.8667\n",
            "\n",
            "Epoch 3573/4999:\n",
            "train Loss: 0.4482 Acc: 0.8667\n",
            "\n",
            "Epoch 3574/4999:\n",
            "train Loss: 0.4481 Acc: 0.8667\n",
            "\n",
            "Epoch 3575/4999:\n",
            "train Loss: 0.4481 Acc: 0.8667\n",
            "\n",
            "Epoch 3576/4999:\n",
            "train Loss: 0.4481 Acc: 0.8667\n",
            "\n",
            "Epoch 3577/4999:\n",
            "train Loss: 0.4481 Acc: 0.8667\n",
            "\n",
            "Epoch 3578/4999:\n",
            "train Loss: 0.4480 Acc: 0.8667\n",
            "\n",
            "Epoch 3579/4999:\n",
            "train Loss: 0.4480 Acc: 0.8667\n",
            "\n",
            "Epoch 3580/4999:\n",
            "train Loss: 0.4480 Acc: 0.8667\n",
            "\n",
            "Epoch 3581/4999:\n",
            "train Loss: 0.4479 Acc: 0.8667\n",
            "\n",
            "Epoch 3582/4999:\n",
            "train Loss: 0.4479 Acc: 0.8667\n",
            "\n",
            "Epoch 3583/4999:\n",
            "train Loss: 0.4479 Acc: 0.8667\n",
            "\n",
            "Epoch 3584/4999:\n",
            "train Loss: 0.4479 Acc: 0.8667\n",
            "\n",
            "Epoch 3585/4999:\n",
            "train Loss: 0.4478 Acc: 0.8667\n",
            "\n",
            "Epoch 3586/4999:\n",
            "train Loss: 0.4478 Acc: 0.8667\n",
            "\n",
            "Epoch 3587/4999:\n",
            "train Loss: 0.4478 Acc: 0.8667\n",
            "\n",
            "Epoch 3588/4999:\n",
            "train Loss: 0.4477 Acc: 0.8667\n",
            "\n",
            "Epoch 3589/4999:\n",
            "train Loss: 0.4477 Acc: 0.8667\n",
            "\n",
            "Epoch 3590/4999:\n",
            "train Loss: 0.4477 Acc: 0.8667\n",
            "\n",
            "Epoch 3591/4999:\n",
            "train Loss: 0.4476 Acc: 0.8667\n",
            "\n",
            "Epoch 3592/4999:\n",
            "train Loss: 0.4476 Acc: 0.8667\n",
            "\n",
            "Epoch 3593/4999:\n",
            "train Loss: 0.4476 Acc: 0.8667\n",
            "\n",
            "Epoch 3594/4999:\n",
            "train Loss: 0.4476 Acc: 0.8667\n",
            "\n",
            "Epoch 3595/4999:\n",
            "train Loss: 0.4475 Acc: 0.8667\n",
            "\n",
            "Epoch 3596/4999:\n",
            "train Loss: 0.4475 Acc: 0.8667\n",
            "\n",
            "Epoch 3597/4999:\n",
            "train Loss: 0.4475 Acc: 0.8667\n",
            "\n",
            "Epoch 3598/4999:\n",
            "train Loss: 0.4474 Acc: 0.8667\n",
            "\n",
            "Epoch 3599/4999:\n",
            "train Loss: 0.4474 Acc: 0.8667\n",
            "\n",
            "Epoch 3600/4999:\n",
            "train Loss: 0.4474 Acc: 0.8667\n",
            "\n",
            "Epoch 3601/4999:\n",
            "train Loss: 0.4474 Acc: 0.8667\n",
            "\n",
            "Epoch 3602/4999:\n",
            "train Loss: 0.4473 Acc: 0.8667\n",
            "\n",
            "Epoch 3603/4999:\n",
            "train Loss: 0.4473 Acc: 0.8667\n",
            "\n",
            "Epoch 3604/4999:\n",
            "train Loss: 0.4473 Acc: 0.8667\n",
            "\n",
            "Epoch 3605/4999:\n",
            "train Loss: 0.4472 Acc: 0.8667\n",
            "\n",
            "Epoch 3606/4999:\n",
            "train Loss: 0.4472 Acc: 0.8667\n",
            "\n",
            "Epoch 3607/4999:\n",
            "train Loss: 0.4472 Acc: 0.8667\n",
            "\n",
            "Epoch 3608/4999:\n",
            "train Loss: 0.4471 Acc: 0.8667\n",
            "\n",
            "Epoch 3609/4999:\n",
            "train Loss: 0.4471 Acc: 0.8667\n",
            "\n",
            "Epoch 3610/4999:\n",
            "train Loss: 0.4471 Acc: 0.8667\n",
            "\n",
            "Epoch 3611/4999:\n",
            "train Loss: 0.4471 Acc: 0.8667\n",
            "\n",
            "Epoch 3612/4999:\n",
            "train Loss: 0.4470 Acc: 0.8667\n",
            "\n",
            "Epoch 3613/4999:\n",
            "train Loss: 0.4470 Acc: 0.8667\n",
            "\n",
            "Epoch 3614/4999:\n",
            "train Loss: 0.4470 Acc: 0.8667\n",
            "\n",
            "Epoch 3615/4999:\n",
            "train Loss: 0.4469 Acc: 0.8667\n",
            "\n",
            "Epoch 3616/4999:\n",
            "train Loss: 0.4469 Acc: 0.8667\n",
            "\n",
            "Epoch 3617/4999:\n",
            "train Loss: 0.4469 Acc: 0.8667\n",
            "\n",
            "Epoch 3618/4999:\n",
            "train Loss: 0.4469 Acc: 0.8667\n",
            "\n",
            "Epoch 3619/4999:\n",
            "train Loss: 0.4468 Acc: 0.8667\n",
            "\n",
            "Epoch 3620/4999:\n",
            "train Loss: 0.4468 Acc: 0.8667\n",
            "\n",
            "Epoch 3621/4999:\n",
            "train Loss: 0.4468 Acc: 0.8667\n",
            "\n",
            "Epoch 3622/4999:\n",
            "train Loss: 0.4467 Acc: 0.8667\n",
            "\n",
            "Epoch 3623/4999:\n",
            "train Loss: 0.4467 Acc: 0.8667\n",
            "\n",
            "Epoch 3624/4999:\n",
            "train Loss: 0.4467 Acc: 0.8667\n",
            "\n",
            "Epoch 3625/4999:\n",
            "train Loss: 0.4466 Acc: 0.8667\n",
            "\n",
            "Epoch 3626/4999:\n",
            "train Loss: 0.4466 Acc: 0.8667\n",
            "\n",
            "Epoch 3627/4999:\n",
            "train Loss: 0.4466 Acc: 0.8667\n",
            "\n",
            "Epoch 3628/4999:\n",
            "train Loss: 0.4466 Acc: 0.8667\n",
            "\n",
            "Epoch 3629/4999:\n",
            "train Loss: 0.4465 Acc: 0.8667\n",
            "\n",
            "Epoch 3630/4999:\n",
            "train Loss: 0.4465 Acc: 0.8667\n",
            "\n",
            "Epoch 3631/4999:\n",
            "train Loss: 0.4465 Acc: 0.8667\n",
            "\n",
            "Epoch 3632/4999:\n",
            "train Loss: 0.4464 Acc: 0.8667\n",
            "\n",
            "Epoch 3633/4999:\n",
            "train Loss: 0.4464 Acc: 0.8667\n",
            "\n",
            "Epoch 3634/4999:\n",
            "train Loss: 0.4464 Acc: 0.8667\n",
            "\n",
            "Epoch 3635/4999:\n",
            "train Loss: 0.4464 Acc: 0.8667\n",
            "\n",
            "Epoch 3636/4999:\n",
            "train Loss: 0.4463 Acc: 0.8667\n",
            "\n",
            "Epoch 3637/4999:\n",
            "train Loss: 0.4463 Acc: 0.8667\n",
            "\n",
            "Epoch 3638/4999:\n",
            "train Loss: 0.4463 Acc: 0.8667\n",
            "\n",
            "Epoch 3639/4999:\n",
            "train Loss: 0.4462 Acc: 0.8667\n",
            "\n",
            "Epoch 3640/4999:\n",
            "train Loss: 0.4462 Acc: 0.8667\n",
            "\n",
            "Epoch 3641/4999:\n",
            "train Loss: 0.4462 Acc: 0.8667\n",
            "\n",
            "Epoch 3642/4999:\n",
            "train Loss: 0.4461 Acc: 0.8667\n",
            "\n",
            "Epoch 3643/4999:\n",
            "train Loss: 0.4461 Acc: 0.8667\n",
            "\n",
            "Epoch 3644/4999:\n",
            "train Loss: 0.4461 Acc: 0.8667\n",
            "\n",
            "Epoch 3645/4999:\n",
            "train Loss: 0.4461 Acc: 0.8667\n",
            "\n",
            "Epoch 3646/4999:\n",
            "train Loss: 0.4460 Acc: 0.8667\n",
            "\n",
            "Epoch 3647/4999:\n",
            "train Loss: 0.4460 Acc: 0.8667\n",
            "\n",
            "Epoch 3648/4999:\n",
            "train Loss: 0.4460 Acc: 0.8667\n",
            "\n",
            "Epoch 3649/4999:\n",
            "train Loss: 0.4459 Acc: 0.8667\n",
            "\n",
            "Epoch 3650/4999:\n",
            "train Loss: 0.4459 Acc: 0.8667\n",
            "\n",
            "Epoch 3651/4999:\n",
            "train Loss: 0.4459 Acc: 0.8667\n",
            "\n",
            "Epoch 3652/4999:\n",
            "train Loss: 0.4459 Acc: 0.8667\n",
            "\n",
            "Epoch 3653/4999:\n",
            "train Loss: 0.4458 Acc: 0.8667\n",
            "\n",
            "Epoch 3654/4999:\n",
            "train Loss: 0.4458 Acc: 0.8667\n",
            "\n",
            "Epoch 3655/4999:\n",
            "train Loss: 0.4458 Acc: 0.8667\n",
            "\n",
            "Epoch 3656/4999:\n",
            "train Loss: 0.4457 Acc: 0.8667\n",
            "\n",
            "Epoch 3657/4999:\n",
            "train Loss: 0.4457 Acc: 0.8667\n",
            "\n",
            "Epoch 3658/4999:\n",
            "train Loss: 0.4457 Acc: 0.8667\n",
            "\n",
            "Epoch 3659/4999:\n",
            "train Loss: 0.4457 Acc: 0.8667\n",
            "\n",
            "Epoch 3660/4999:\n",
            "train Loss: 0.4456 Acc: 0.8667\n",
            "\n",
            "Epoch 3661/4999:\n",
            "train Loss: 0.4456 Acc: 0.8667\n",
            "\n",
            "Epoch 3662/4999:\n",
            "train Loss: 0.4456 Acc: 0.8667\n",
            "\n",
            "Epoch 3663/4999:\n",
            "train Loss: 0.4455 Acc: 0.8667\n",
            "\n",
            "Epoch 3664/4999:\n",
            "train Loss: 0.4455 Acc: 0.8667\n",
            "\n",
            "Epoch 3665/4999:\n",
            "train Loss: 0.4455 Acc: 0.8667\n",
            "\n",
            "Epoch 3666/4999:\n",
            "train Loss: 0.4454 Acc: 0.8667\n",
            "\n",
            "Epoch 3667/4999:\n",
            "train Loss: 0.4454 Acc: 0.8667\n",
            "\n",
            "Epoch 3668/4999:\n",
            "train Loss: 0.4454 Acc: 0.8667\n",
            "\n",
            "Epoch 3669/4999:\n",
            "train Loss: 0.4454 Acc: 0.8667\n",
            "\n",
            "Epoch 3670/4999:\n",
            "train Loss: 0.4453 Acc: 0.8667\n",
            "\n",
            "Epoch 3671/4999:\n",
            "train Loss: 0.4453 Acc: 0.8667\n",
            "\n",
            "Epoch 3672/4999:\n",
            "train Loss: 0.4453 Acc: 0.8667\n",
            "\n",
            "Epoch 3673/4999:\n",
            "train Loss: 0.4452 Acc: 0.8667\n",
            "\n",
            "Epoch 3674/4999:\n",
            "train Loss: 0.4452 Acc: 0.8667\n",
            "\n",
            "Epoch 3675/4999:\n",
            "train Loss: 0.4452 Acc: 0.8667\n",
            "\n",
            "Epoch 3676/4999:\n",
            "train Loss: 0.4452 Acc: 0.8667\n",
            "\n",
            "Epoch 3677/4999:\n",
            "train Loss: 0.4451 Acc: 0.8667\n",
            "\n",
            "Epoch 3678/4999:\n",
            "train Loss: 0.4451 Acc: 0.8667\n",
            "\n",
            "Epoch 3679/4999:\n",
            "train Loss: 0.4451 Acc: 0.8667\n",
            "\n",
            "Epoch 3680/4999:\n",
            "train Loss: 0.4450 Acc: 0.8667\n",
            "\n",
            "Epoch 3681/4999:\n",
            "train Loss: 0.4450 Acc: 0.8667\n",
            "\n",
            "Epoch 3682/4999:\n",
            "train Loss: 0.4450 Acc: 0.8667\n",
            "\n",
            "Epoch 3683/4999:\n",
            "train Loss: 0.4449 Acc: 0.8667\n",
            "\n",
            "Epoch 3684/4999:\n",
            "train Loss: 0.4449 Acc: 0.8667\n",
            "\n",
            "Epoch 3685/4999:\n",
            "train Loss: 0.4449 Acc: 0.8667\n",
            "\n",
            "Epoch 3686/4999:\n",
            "train Loss: 0.4449 Acc: 0.8667\n",
            "\n",
            "Epoch 3687/4999:\n",
            "train Loss: 0.4448 Acc: 0.8667\n",
            "\n",
            "Epoch 3688/4999:\n",
            "train Loss: 0.4448 Acc: 0.8667\n",
            "\n",
            "Epoch 3689/4999:\n",
            "train Loss: 0.4448 Acc: 0.8667\n",
            "\n",
            "Epoch 3690/4999:\n",
            "train Loss: 0.4447 Acc: 0.8667\n",
            "\n",
            "Epoch 3691/4999:\n",
            "train Loss: 0.4447 Acc: 0.8667\n",
            "\n",
            "Epoch 3692/4999:\n",
            "train Loss: 0.4447 Acc: 0.8667\n",
            "\n",
            "Epoch 3693/4999:\n",
            "train Loss: 0.4447 Acc: 0.8667\n",
            "\n",
            "Epoch 3694/4999:\n",
            "train Loss: 0.4446 Acc: 0.8667\n",
            "\n",
            "Epoch 3695/4999:\n",
            "train Loss: 0.4446 Acc: 0.8667\n",
            "\n",
            "Epoch 3696/4999:\n",
            "train Loss: 0.4446 Acc: 0.8667\n",
            "\n",
            "Epoch 3697/4999:\n",
            "train Loss: 0.4445 Acc: 0.8667\n",
            "\n",
            "Epoch 3698/4999:\n",
            "train Loss: 0.4445 Acc: 0.8667\n",
            "\n",
            "Epoch 3699/4999:\n",
            "train Loss: 0.4445 Acc: 0.8667\n",
            "\n",
            "Epoch 3700/4999:\n",
            "train Loss: 0.4445 Acc: 0.8667\n",
            "\n",
            "Epoch 3701/4999:\n",
            "train Loss: 0.4444 Acc: 0.8667\n",
            "\n",
            "Epoch 3702/4999:\n",
            "train Loss: 0.4444 Acc: 0.8667\n",
            "\n",
            "Epoch 3703/4999:\n",
            "train Loss: 0.4444 Acc: 0.8667\n",
            "\n",
            "Epoch 3704/4999:\n",
            "train Loss: 0.4443 Acc: 0.8667\n",
            "\n",
            "Epoch 3705/4999:\n",
            "train Loss: 0.4443 Acc: 0.8667\n",
            "\n",
            "Epoch 3706/4999:\n",
            "train Loss: 0.4443 Acc: 0.8667\n",
            "\n",
            "Epoch 3707/4999:\n",
            "train Loss: 0.4442 Acc: 0.8667\n",
            "\n",
            "Epoch 3708/4999:\n",
            "train Loss: 0.4442 Acc: 0.8667\n",
            "\n",
            "Epoch 3709/4999:\n",
            "train Loss: 0.4442 Acc: 0.8667\n",
            "\n",
            "Epoch 3710/4999:\n",
            "train Loss: 0.4442 Acc: 0.8667\n",
            "\n",
            "Epoch 3711/4999:\n",
            "train Loss: 0.4441 Acc: 0.8667\n",
            "\n",
            "Epoch 3712/4999:\n",
            "train Loss: 0.4441 Acc: 0.8667\n",
            "\n",
            "Epoch 3713/4999:\n",
            "train Loss: 0.4441 Acc: 0.8667\n",
            "\n",
            "Epoch 3714/4999:\n",
            "train Loss: 0.4440 Acc: 0.8667\n",
            "\n",
            "Epoch 3715/4999:\n",
            "train Loss: 0.4440 Acc: 0.8667\n",
            "\n",
            "Epoch 3716/4999:\n",
            "train Loss: 0.4440 Acc: 0.8667\n",
            "\n",
            "Epoch 3717/4999:\n",
            "train Loss: 0.4440 Acc: 0.8667\n",
            "\n",
            "Epoch 3718/4999:\n",
            "train Loss: 0.4439 Acc: 0.8667\n",
            "\n",
            "Epoch 3719/4999:\n",
            "train Loss: 0.4439 Acc: 0.8667\n",
            "\n",
            "Epoch 3720/4999:\n",
            "train Loss: 0.4439 Acc: 0.8667\n",
            "\n",
            "Epoch 3721/4999:\n",
            "train Loss: 0.4438 Acc: 0.8667\n",
            "\n",
            "Epoch 3722/4999:\n",
            "train Loss: 0.4438 Acc: 0.8667\n",
            "\n",
            "Epoch 3723/4999:\n",
            "train Loss: 0.4438 Acc: 0.8667\n",
            "\n",
            "Epoch 3724/4999:\n",
            "train Loss: 0.4438 Acc: 0.8667\n",
            "\n",
            "Epoch 3725/4999:\n",
            "train Loss: 0.4437 Acc: 0.8667\n",
            "\n",
            "Epoch 3726/4999:\n",
            "train Loss: 0.4437 Acc: 0.8667\n",
            "\n",
            "Epoch 3727/4999:\n",
            "train Loss: 0.4437 Acc: 0.8667\n",
            "\n",
            "Epoch 3728/4999:\n",
            "train Loss: 0.4436 Acc: 0.8667\n",
            "\n",
            "Epoch 3729/4999:\n",
            "train Loss: 0.4436 Acc: 0.8667\n",
            "\n",
            "Epoch 3730/4999:\n",
            "train Loss: 0.4436 Acc: 0.8667\n",
            "\n",
            "Epoch 3731/4999:\n",
            "train Loss: 0.4435 Acc: 0.8667\n",
            "\n",
            "Epoch 3732/4999:\n",
            "train Loss: 0.4435 Acc: 0.8667\n",
            "\n",
            "Epoch 3733/4999:\n",
            "train Loss: 0.4435 Acc: 0.8667\n",
            "\n",
            "Epoch 3734/4999:\n",
            "train Loss: 0.4435 Acc: 0.8667\n",
            "\n",
            "Epoch 3735/4999:\n",
            "train Loss: 0.4434 Acc: 0.8667\n",
            "\n",
            "Epoch 3736/4999:\n",
            "train Loss: 0.4434 Acc: 0.8667\n",
            "\n",
            "Epoch 3737/4999:\n",
            "train Loss: 0.4434 Acc: 0.8667\n",
            "\n",
            "Epoch 3738/4999:\n",
            "train Loss: 0.4433 Acc: 0.8667\n",
            "\n",
            "Epoch 3739/4999:\n",
            "train Loss: 0.4433 Acc: 0.8667\n",
            "\n",
            "Epoch 3740/4999:\n",
            "train Loss: 0.4433 Acc: 0.8667\n",
            "\n",
            "Epoch 3741/4999:\n",
            "train Loss: 0.4433 Acc: 0.8667\n",
            "\n",
            "Epoch 3742/4999:\n",
            "train Loss: 0.4432 Acc: 0.8667\n",
            "\n",
            "Epoch 3743/4999:\n",
            "train Loss: 0.4432 Acc: 0.8667\n",
            "\n",
            "Epoch 3744/4999:\n",
            "train Loss: 0.4432 Acc: 0.8667\n",
            "\n",
            "Epoch 3745/4999:\n",
            "train Loss: 0.4431 Acc: 0.8667\n",
            "\n",
            "Epoch 3746/4999:\n",
            "train Loss: 0.4431 Acc: 0.8667\n",
            "\n",
            "Epoch 3747/4999:\n",
            "train Loss: 0.4431 Acc: 0.8667\n",
            "\n",
            "Epoch 3748/4999:\n",
            "train Loss: 0.4431 Acc: 0.8667\n",
            "\n",
            "Epoch 3749/4999:\n",
            "train Loss: 0.4430 Acc: 0.8667\n",
            "\n",
            "Epoch 3750/4999:\n",
            "train Loss: 0.4430 Acc: 0.8667\n",
            "\n",
            "Epoch 3751/4999:\n",
            "train Loss: 0.4430 Acc: 0.8667\n",
            "\n",
            "Epoch 3752/4999:\n",
            "train Loss: 0.4429 Acc: 0.8667\n",
            "\n",
            "Epoch 3753/4999:\n",
            "train Loss: 0.4429 Acc: 0.8667\n",
            "\n",
            "Epoch 3754/4999:\n",
            "train Loss: 0.4429 Acc: 0.8667\n",
            "\n",
            "Epoch 3755/4999:\n",
            "train Loss: 0.4429 Acc: 0.8667\n",
            "\n",
            "Epoch 3756/4999:\n",
            "train Loss: 0.4428 Acc: 0.8667\n",
            "\n",
            "Epoch 3757/4999:\n",
            "train Loss: 0.4428 Acc: 0.8667\n",
            "\n",
            "Epoch 3758/4999:\n",
            "train Loss: 0.4428 Acc: 0.8667\n",
            "\n",
            "Epoch 3759/4999:\n",
            "train Loss: 0.4427 Acc: 0.8667\n",
            "\n",
            "Epoch 3760/4999:\n",
            "train Loss: 0.4427 Acc: 0.8667\n",
            "\n",
            "Epoch 3761/4999:\n",
            "train Loss: 0.4427 Acc: 0.8667\n",
            "\n",
            "Epoch 3762/4999:\n",
            "train Loss: 0.4426 Acc: 0.8667\n",
            "\n",
            "Epoch 3763/4999:\n",
            "train Loss: 0.4426 Acc: 0.8667\n",
            "\n",
            "Epoch 3764/4999:\n",
            "train Loss: 0.4426 Acc: 0.8667\n",
            "\n",
            "Epoch 3765/4999:\n",
            "train Loss: 0.4426 Acc: 0.8667\n",
            "\n",
            "Epoch 3766/4999:\n",
            "train Loss: 0.4425 Acc: 0.8667\n",
            "\n",
            "Epoch 3767/4999:\n",
            "train Loss: 0.4425 Acc: 0.8667\n",
            "\n",
            "Epoch 3768/4999:\n",
            "train Loss: 0.4425 Acc: 0.8667\n",
            "\n",
            "Epoch 3769/4999:\n",
            "train Loss: 0.4424 Acc: 0.8667\n",
            "\n",
            "Epoch 3770/4999:\n",
            "train Loss: 0.4424 Acc: 0.8667\n",
            "\n",
            "Epoch 3771/4999:\n",
            "train Loss: 0.4424 Acc: 0.8667\n",
            "\n",
            "Epoch 3772/4999:\n",
            "train Loss: 0.4424 Acc: 0.8667\n",
            "\n",
            "Epoch 3773/4999:\n",
            "train Loss: 0.4423 Acc: 0.8667\n",
            "\n",
            "Epoch 3774/4999:\n",
            "train Loss: 0.4423 Acc: 0.8667\n",
            "\n",
            "Epoch 3775/4999:\n",
            "train Loss: 0.4423 Acc: 0.8667\n",
            "\n",
            "Epoch 3776/4999:\n",
            "train Loss: 0.4422 Acc: 0.8667\n",
            "\n",
            "Epoch 3777/4999:\n",
            "train Loss: 0.4422 Acc: 0.8667\n",
            "\n",
            "Epoch 3778/4999:\n",
            "train Loss: 0.4422 Acc: 0.8667\n",
            "\n",
            "Epoch 3779/4999:\n",
            "train Loss: 0.4422 Acc: 0.8667\n",
            "\n",
            "Epoch 3780/4999:\n",
            "train Loss: 0.4421 Acc: 0.8667\n",
            "\n",
            "Epoch 3781/4999:\n",
            "train Loss: 0.4421 Acc: 0.8667\n",
            "\n",
            "Epoch 3782/4999:\n",
            "train Loss: 0.4421 Acc: 0.8667\n",
            "\n",
            "Epoch 3783/4999:\n",
            "train Loss: 0.4420 Acc: 0.8667\n",
            "\n",
            "Epoch 3784/4999:\n",
            "train Loss: 0.4420 Acc: 0.8667\n",
            "\n",
            "Epoch 3785/4999:\n",
            "train Loss: 0.4420 Acc: 0.8667\n",
            "\n",
            "Epoch 3786/4999:\n",
            "train Loss: 0.4420 Acc: 0.8667\n",
            "\n",
            "Epoch 3787/4999:\n",
            "train Loss: 0.4419 Acc: 0.8667\n",
            "\n",
            "Epoch 3788/4999:\n",
            "train Loss: 0.4419 Acc: 0.8667\n",
            "\n",
            "Epoch 3789/4999:\n",
            "train Loss: 0.4419 Acc: 0.8667\n",
            "\n",
            "Epoch 3790/4999:\n",
            "train Loss: 0.4418 Acc: 0.8667\n",
            "\n",
            "Epoch 3791/4999:\n",
            "train Loss: 0.4418 Acc: 0.8667\n",
            "\n",
            "Epoch 3792/4999:\n",
            "train Loss: 0.4418 Acc: 0.8667\n",
            "\n",
            "Epoch 3793/4999:\n",
            "train Loss: 0.4418 Acc: 0.8667\n",
            "\n",
            "Epoch 3794/4999:\n",
            "train Loss: 0.4417 Acc: 0.8667\n",
            "\n",
            "Epoch 3795/4999:\n",
            "train Loss: 0.4417 Acc: 0.8667\n",
            "\n",
            "Epoch 3796/4999:\n",
            "train Loss: 0.4417 Acc: 0.8667\n",
            "\n",
            "Epoch 3797/4999:\n",
            "train Loss: 0.4416 Acc: 0.8733\n",
            "\n",
            "Epoch 3798/4999:\n",
            "train Loss: 0.4416 Acc: 0.8733\n",
            "\n",
            "Epoch 3799/4999:\n",
            "train Loss: 0.4416 Acc: 0.8733\n",
            "\n",
            "Epoch 3800/4999:\n",
            "train Loss: 0.4415 Acc: 0.8733\n",
            "\n",
            "Epoch 3801/4999:\n",
            "train Loss: 0.4415 Acc: 0.8733\n",
            "\n",
            "Epoch 3802/4999:\n",
            "train Loss: 0.4415 Acc: 0.8733\n",
            "\n",
            "Epoch 3803/4999:\n",
            "train Loss: 0.4415 Acc: 0.8733\n",
            "\n",
            "Epoch 3804/4999:\n",
            "train Loss: 0.4414 Acc: 0.8733\n",
            "\n",
            "Epoch 3805/4999:\n",
            "train Loss: 0.4414 Acc: 0.8733\n",
            "\n",
            "Epoch 3806/4999:\n",
            "train Loss: 0.4414 Acc: 0.8733\n",
            "\n",
            "Epoch 3807/4999:\n",
            "train Loss: 0.4413 Acc: 0.8733\n",
            "\n",
            "Epoch 3808/4999:\n",
            "train Loss: 0.4413 Acc: 0.8733\n",
            "\n",
            "Epoch 3809/4999:\n",
            "train Loss: 0.4413 Acc: 0.8733\n",
            "\n",
            "Epoch 3810/4999:\n",
            "train Loss: 0.4413 Acc: 0.8733\n",
            "\n",
            "Epoch 3811/4999:\n",
            "train Loss: 0.4412 Acc: 0.8733\n",
            "\n",
            "Epoch 3812/4999:\n",
            "train Loss: 0.4412 Acc: 0.8733\n",
            "\n",
            "Epoch 3813/4999:\n",
            "train Loss: 0.4412 Acc: 0.8733\n",
            "\n",
            "Epoch 3814/4999:\n",
            "train Loss: 0.4411 Acc: 0.8733\n",
            "\n",
            "Epoch 3815/4999:\n",
            "train Loss: 0.4411 Acc: 0.8733\n",
            "\n",
            "Epoch 3816/4999:\n",
            "train Loss: 0.4411 Acc: 0.8733\n",
            "\n",
            "Epoch 3817/4999:\n",
            "train Loss: 0.4411 Acc: 0.8733\n",
            "\n",
            "Epoch 3818/4999:\n",
            "train Loss: 0.4410 Acc: 0.8733\n",
            "\n",
            "Epoch 3819/4999:\n",
            "train Loss: 0.4410 Acc: 0.8733\n",
            "\n",
            "Epoch 3820/4999:\n",
            "train Loss: 0.4410 Acc: 0.8733\n",
            "\n",
            "Epoch 3821/4999:\n",
            "train Loss: 0.4409 Acc: 0.8733\n",
            "\n",
            "Epoch 3822/4999:\n",
            "train Loss: 0.4409 Acc: 0.8733\n",
            "\n",
            "Epoch 3823/4999:\n",
            "train Loss: 0.4409 Acc: 0.8733\n",
            "\n",
            "Epoch 3824/4999:\n",
            "train Loss: 0.4409 Acc: 0.8733\n",
            "\n",
            "Epoch 3825/4999:\n",
            "train Loss: 0.4408 Acc: 0.8733\n",
            "\n",
            "Epoch 3826/4999:\n",
            "train Loss: 0.4408 Acc: 0.8733\n",
            "\n",
            "Epoch 3827/4999:\n",
            "train Loss: 0.4408 Acc: 0.8733\n",
            "\n",
            "Epoch 3828/4999:\n",
            "train Loss: 0.4407 Acc: 0.8733\n",
            "\n",
            "Epoch 3829/4999:\n",
            "train Loss: 0.4407 Acc: 0.8733\n",
            "\n",
            "Epoch 3830/4999:\n",
            "train Loss: 0.4407 Acc: 0.8733\n",
            "\n",
            "Epoch 3831/4999:\n",
            "train Loss: 0.4407 Acc: 0.8733\n",
            "\n",
            "Epoch 3832/4999:\n",
            "train Loss: 0.4406 Acc: 0.8733\n",
            "\n",
            "Epoch 3833/4999:\n",
            "train Loss: 0.4406 Acc: 0.8733\n",
            "\n",
            "Epoch 3834/4999:\n",
            "train Loss: 0.4406 Acc: 0.8733\n",
            "\n",
            "Epoch 3835/4999:\n",
            "train Loss: 0.4405 Acc: 0.8733\n",
            "\n",
            "Epoch 3836/4999:\n",
            "train Loss: 0.4405 Acc: 0.8733\n",
            "\n",
            "Epoch 3837/4999:\n",
            "train Loss: 0.4405 Acc: 0.8733\n",
            "\n",
            "Epoch 3838/4999:\n",
            "train Loss: 0.4405 Acc: 0.8733\n",
            "\n",
            "Epoch 3839/4999:\n",
            "train Loss: 0.4404 Acc: 0.8733\n",
            "\n",
            "Epoch 3840/4999:\n",
            "train Loss: 0.4404 Acc: 0.8733\n",
            "\n",
            "Epoch 3841/4999:\n",
            "train Loss: 0.4404 Acc: 0.8733\n",
            "\n",
            "Epoch 3842/4999:\n",
            "train Loss: 0.4403 Acc: 0.8733\n",
            "\n",
            "Epoch 3843/4999:\n",
            "train Loss: 0.4403 Acc: 0.8733\n",
            "\n",
            "Epoch 3844/4999:\n",
            "train Loss: 0.4403 Acc: 0.8733\n",
            "\n",
            "Epoch 3845/4999:\n",
            "train Loss: 0.4403 Acc: 0.8733\n",
            "\n",
            "Epoch 3846/4999:\n",
            "train Loss: 0.4402 Acc: 0.8733\n",
            "\n",
            "Epoch 3847/4999:\n",
            "train Loss: 0.4402 Acc: 0.8733\n",
            "\n",
            "Epoch 3848/4999:\n",
            "train Loss: 0.4402 Acc: 0.8733\n",
            "\n",
            "Epoch 3849/4999:\n",
            "train Loss: 0.4401 Acc: 0.8733\n",
            "\n",
            "Epoch 3850/4999:\n",
            "train Loss: 0.4401 Acc: 0.8733\n",
            "\n",
            "Epoch 3851/4999:\n",
            "train Loss: 0.4401 Acc: 0.8733\n",
            "\n",
            "Epoch 3852/4999:\n",
            "train Loss: 0.4401 Acc: 0.8733\n",
            "\n",
            "Epoch 3853/4999:\n",
            "train Loss: 0.4400 Acc: 0.8733\n",
            "\n",
            "Epoch 3854/4999:\n",
            "train Loss: 0.4400 Acc: 0.8733\n",
            "\n",
            "Epoch 3855/4999:\n",
            "train Loss: 0.4400 Acc: 0.8733\n",
            "\n",
            "Epoch 3856/4999:\n",
            "train Loss: 0.4399 Acc: 0.8733\n",
            "\n",
            "Epoch 3857/4999:\n",
            "train Loss: 0.4399 Acc: 0.8733\n",
            "\n",
            "Epoch 3858/4999:\n",
            "train Loss: 0.4399 Acc: 0.8733\n",
            "\n",
            "Epoch 3859/4999:\n",
            "train Loss: 0.4398 Acc: 0.8733\n",
            "\n",
            "Epoch 3860/4999:\n",
            "train Loss: 0.4398 Acc: 0.8733\n",
            "\n",
            "Epoch 3861/4999:\n",
            "train Loss: 0.4398 Acc: 0.8733\n",
            "\n",
            "Epoch 3862/4999:\n",
            "train Loss: 0.4398 Acc: 0.8733\n",
            "\n",
            "Epoch 3863/4999:\n",
            "train Loss: 0.4397 Acc: 0.8733\n",
            "\n",
            "Epoch 3864/4999:\n",
            "train Loss: 0.4397 Acc: 0.8733\n",
            "\n",
            "Epoch 3865/4999:\n",
            "train Loss: 0.4397 Acc: 0.8733\n",
            "\n",
            "Epoch 3866/4999:\n",
            "train Loss: 0.4396 Acc: 0.8733\n",
            "\n",
            "Epoch 3867/4999:\n",
            "train Loss: 0.4396 Acc: 0.8733\n",
            "\n",
            "Epoch 3868/4999:\n",
            "train Loss: 0.4396 Acc: 0.8733\n",
            "\n",
            "Epoch 3869/4999:\n",
            "train Loss: 0.4396 Acc: 0.8733\n",
            "\n",
            "Epoch 3870/4999:\n",
            "train Loss: 0.4395 Acc: 0.8733\n",
            "\n",
            "Epoch 3871/4999:\n",
            "train Loss: 0.4395 Acc: 0.8733\n",
            "\n",
            "Epoch 3872/4999:\n",
            "train Loss: 0.4395 Acc: 0.8733\n",
            "\n",
            "Epoch 3873/4999:\n",
            "train Loss: 0.4394 Acc: 0.8733\n",
            "\n",
            "Epoch 3874/4999:\n",
            "train Loss: 0.4394 Acc: 0.8733\n",
            "\n",
            "Epoch 3875/4999:\n",
            "train Loss: 0.4394 Acc: 0.8733\n",
            "\n",
            "Epoch 3876/4999:\n",
            "train Loss: 0.4394 Acc: 0.8733\n",
            "\n",
            "Epoch 3877/4999:\n",
            "train Loss: 0.4393 Acc: 0.8733\n",
            "\n",
            "Epoch 3878/4999:\n",
            "train Loss: 0.4393 Acc: 0.8733\n",
            "\n",
            "Epoch 3879/4999:\n",
            "train Loss: 0.4393 Acc: 0.8733\n",
            "\n",
            "Epoch 3880/4999:\n",
            "train Loss: 0.4392 Acc: 0.8733\n",
            "\n",
            "Epoch 3881/4999:\n",
            "train Loss: 0.4392 Acc: 0.8733\n",
            "\n",
            "Epoch 3882/4999:\n",
            "train Loss: 0.4392 Acc: 0.8733\n",
            "\n",
            "Epoch 3883/4999:\n",
            "train Loss: 0.4392 Acc: 0.8733\n",
            "\n",
            "Epoch 3884/4999:\n",
            "train Loss: 0.4391 Acc: 0.8733\n",
            "\n",
            "Epoch 3885/4999:\n",
            "train Loss: 0.4391 Acc: 0.8733\n",
            "\n",
            "Epoch 3886/4999:\n",
            "train Loss: 0.4391 Acc: 0.8733\n",
            "\n",
            "Epoch 3887/4999:\n",
            "train Loss: 0.4390 Acc: 0.8733\n",
            "\n",
            "Epoch 3888/4999:\n",
            "train Loss: 0.4390 Acc: 0.8733\n",
            "\n",
            "Epoch 3889/4999:\n",
            "train Loss: 0.4390 Acc: 0.8733\n",
            "\n",
            "Epoch 3890/4999:\n",
            "train Loss: 0.4390 Acc: 0.8733\n",
            "\n",
            "Epoch 3891/4999:\n",
            "train Loss: 0.4389 Acc: 0.8733\n",
            "\n",
            "Epoch 3892/4999:\n",
            "train Loss: 0.4389 Acc: 0.8733\n",
            "\n",
            "Epoch 3893/4999:\n",
            "train Loss: 0.4389 Acc: 0.8733\n",
            "\n",
            "Epoch 3894/4999:\n",
            "train Loss: 0.4388 Acc: 0.8733\n",
            "\n",
            "Epoch 3895/4999:\n",
            "train Loss: 0.4388 Acc: 0.8733\n",
            "\n",
            "Epoch 3896/4999:\n",
            "train Loss: 0.4388 Acc: 0.8733\n",
            "\n",
            "Epoch 3897/4999:\n",
            "train Loss: 0.4388 Acc: 0.8733\n",
            "\n",
            "Epoch 3898/4999:\n",
            "train Loss: 0.4387 Acc: 0.8733\n",
            "\n",
            "Epoch 3899/4999:\n",
            "train Loss: 0.4387 Acc: 0.8733\n",
            "\n",
            "Epoch 3900/4999:\n",
            "train Loss: 0.4387 Acc: 0.8733\n",
            "\n",
            "Epoch 3901/4999:\n",
            "train Loss: 0.4386 Acc: 0.8733\n",
            "\n",
            "Epoch 3902/4999:\n",
            "train Loss: 0.4386 Acc: 0.8733\n",
            "\n",
            "Epoch 3903/4999:\n",
            "train Loss: 0.4386 Acc: 0.8733\n",
            "\n",
            "Epoch 3904/4999:\n",
            "train Loss: 0.4386 Acc: 0.8733\n",
            "\n",
            "Epoch 3905/4999:\n",
            "train Loss: 0.4385 Acc: 0.8733\n",
            "\n",
            "Epoch 3906/4999:\n",
            "train Loss: 0.4385 Acc: 0.8733\n",
            "\n",
            "Epoch 3907/4999:\n",
            "train Loss: 0.4385 Acc: 0.8733\n",
            "\n",
            "Epoch 3908/4999:\n",
            "train Loss: 0.4384 Acc: 0.8733\n",
            "\n",
            "Epoch 3909/4999:\n",
            "train Loss: 0.4384 Acc: 0.8733\n",
            "\n",
            "Epoch 3910/4999:\n",
            "train Loss: 0.4384 Acc: 0.8733\n",
            "\n",
            "Epoch 3911/4999:\n",
            "train Loss: 0.4384 Acc: 0.8733\n",
            "\n",
            "Epoch 3912/4999:\n",
            "train Loss: 0.4383 Acc: 0.8733\n",
            "\n",
            "Epoch 3913/4999:\n",
            "train Loss: 0.4383 Acc: 0.8733\n",
            "\n",
            "Epoch 3914/4999:\n",
            "train Loss: 0.4383 Acc: 0.8733\n",
            "\n",
            "Epoch 3915/4999:\n",
            "train Loss: 0.4382 Acc: 0.8733\n",
            "\n",
            "Epoch 3916/4999:\n",
            "train Loss: 0.4382 Acc: 0.8733\n",
            "\n",
            "Epoch 3917/4999:\n",
            "train Loss: 0.4382 Acc: 0.8733\n",
            "\n",
            "Epoch 3918/4999:\n",
            "train Loss: 0.4382 Acc: 0.8733\n",
            "\n",
            "Epoch 3919/4999:\n",
            "train Loss: 0.4381 Acc: 0.8733\n",
            "\n",
            "Epoch 3920/4999:\n",
            "train Loss: 0.4381 Acc: 0.8733\n",
            "\n",
            "Epoch 3921/4999:\n",
            "train Loss: 0.4381 Acc: 0.8733\n",
            "\n",
            "Epoch 3922/4999:\n",
            "train Loss: 0.4380 Acc: 0.8733\n",
            "\n",
            "Epoch 3923/4999:\n",
            "train Loss: 0.4380 Acc: 0.8733\n",
            "\n",
            "Epoch 3924/4999:\n",
            "train Loss: 0.4380 Acc: 0.8733\n",
            "\n",
            "Epoch 3925/4999:\n",
            "train Loss: 0.4380 Acc: 0.8733\n",
            "\n",
            "Epoch 3926/4999:\n",
            "train Loss: 0.4379 Acc: 0.8733\n",
            "\n",
            "Epoch 3927/4999:\n",
            "train Loss: 0.4379 Acc: 0.8733\n",
            "\n",
            "Epoch 3928/4999:\n",
            "train Loss: 0.4379 Acc: 0.8733\n",
            "\n",
            "Epoch 3929/4999:\n",
            "train Loss: 0.4378 Acc: 0.8733\n",
            "\n",
            "Epoch 3930/4999:\n",
            "train Loss: 0.4378 Acc: 0.8733\n",
            "\n",
            "Epoch 3931/4999:\n",
            "train Loss: 0.4378 Acc: 0.8733\n",
            "\n",
            "Epoch 3932/4999:\n",
            "train Loss: 0.4378 Acc: 0.8733\n",
            "\n",
            "Epoch 3933/4999:\n",
            "train Loss: 0.4377 Acc: 0.8733\n",
            "\n",
            "Epoch 3934/4999:\n",
            "train Loss: 0.4377 Acc: 0.8733\n",
            "\n",
            "Epoch 3935/4999:\n",
            "train Loss: 0.4377 Acc: 0.8733\n",
            "\n",
            "Epoch 3936/4999:\n",
            "train Loss: 0.4376 Acc: 0.8733\n",
            "\n",
            "Epoch 3937/4999:\n",
            "train Loss: 0.4376 Acc: 0.8733\n",
            "\n",
            "Epoch 3938/4999:\n",
            "train Loss: 0.4376 Acc: 0.8733\n",
            "\n",
            "Epoch 3939/4999:\n",
            "train Loss: 0.4376 Acc: 0.8733\n",
            "\n",
            "Epoch 3940/4999:\n",
            "train Loss: 0.4375 Acc: 0.8733\n",
            "\n",
            "Epoch 3941/4999:\n",
            "train Loss: 0.4375 Acc: 0.8733\n",
            "\n",
            "Epoch 3942/4999:\n",
            "train Loss: 0.4375 Acc: 0.8733\n",
            "\n",
            "Epoch 3943/4999:\n",
            "train Loss: 0.4374 Acc: 0.8733\n",
            "\n",
            "Epoch 3944/4999:\n",
            "train Loss: 0.4374 Acc: 0.8733\n",
            "\n",
            "Epoch 3945/4999:\n",
            "train Loss: 0.4374 Acc: 0.8733\n",
            "\n",
            "Epoch 3946/4999:\n",
            "train Loss: 0.4374 Acc: 0.8733\n",
            "\n",
            "Epoch 3947/4999:\n",
            "train Loss: 0.4373 Acc: 0.8733\n",
            "\n",
            "Epoch 3948/4999:\n",
            "train Loss: 0.4373 Acc: 0.8733\n",
            "\n",
            "Epoch 3949/4999:\n",
            "train Loss: 0.4373 Acc: 0.8733\n",
            "\n",
            "Epoch 3950/4999:\n",
            "train Loss: 0.4372 Acc: 0.8733\n",
            "\n",
            "Epoch 3951/4999:\n",
            "train Loss: 0.4372 Acc: 0.8733\n",
            "\n",
            "Epoch 3952/4999:\n",
            "train Loss: 0.4372 Acc: 0.8733\n",
            "\n",
            "Epoch 3953/4999:\n",
            "train Loss: 0.4372 Acc: 0.8733\n",
            "\n",
            "Epoch 3954/4999:\n",
            "train Loss: 0.4371 Acc: 0.8733\n",
            "\n",
            "Epoch 3955/4999:\n",
            "train Loss: 0.4371 Acc: 0.8733\n",
            "\n",
            "Epoch 3956/4999:\n",
            "train Loss: 0.4371 Acc: 0.8733\n",
            "\n",
            "Epoch 3957/4999:\n",
            "train Loss: 0.4370 Acc: 0.8733\n",
            "\n",
            "Epoch 3958/4999:\n",
            "train Loss: 0.4370 Acc: 0.8733\n",
            "\n",
            "Epoch 3959/4999:\n",
            "train Loss: 0.4370 Acc: 0.8733\n",
            "\n",
            "Epoch 3960/4999:\n",
            "train Loss: 0.4370 Acc: 0.8733\n",
            "\n",
            "Epoch 3961/4999:\n",
            "train Loss: 0.4369 Acc: 0.8733\n",
            "\n",
            "Epoch 3962/4999:\n",
            "train Loss: 0.4369 Acc: 0.8733\n",
            "\n",
            "Epoch 3963/4999:\n",
            "train Loss: 0.4369 Acc: 0.8733\n",
            "\n",
            "Epoch 3964/4999:\n",
            "train Loss: 0.4368 Acc: 0.8733\n",
            "\n",
            "Epoch 3965/4999:\n",
            "train Loss: 0.4368 Acc: 0.8733\n",
            "\n",
            "Epoch 3966/4999:\n",
            "train Loss: 0.4368 Acc: 0.8733\n",
            "\n",
            "Epoch 3967/4999:\n",
            "train Loss: 0.4368 Acc: 0.8733\n",
            "\n",
            "Epoch 3968/4999:\n",
            "train Loss: 0.4367 Acc: 0.8733\n",
            "\n",
            "Epoch 3969/4999:\n",
            "train Loss: 0.4367 Acc: 0.8733\n",
            "\n",
            "Epoch 3970/4999:\n",
            "train Loss: 0.4367 Acc: 0.8733\n",
            "\n",
            "Epoch 3971/4999:\n",
            "train Loss: 0.4366 Acc: 0.8733\n",
            "\n",
            "Epoch 3972/4999:\n",
            "train Loss: 0.4366 Acc: 0.8733\n",
            "\n",
            "Epoch 3973/4999:\n",
            "train Loss: 0.4366 Acc: 0.8733\n",
            "\n",
            "Epoch 3974/4999:\n",
            "train Loss: 0.4366 Acc: 0.8733\n",
            "\n",
            "Epoch 3975/4999:\n",
            "train Loss: 0.4365 Acc: 0.8733\n",
            "\n",
            "Epoch 3976/4999:\n",
            "train Loss: 0.4365 Acc: 0.8733\n",
            "\n",
            "Epoch 3977/4999:\n",
            "train Loss: 0.4365 Acc: 0.8733\n",
            "\n",
            "Epoch 3978/4999:\n",
            "train Loss: 0.4364 Acc: 0.8733\n",
            "\n",
            "Epoch 3979/4999:\n",
            "train Loss: 0.4364 Acc: 0.8733\n",
            "\n",
            "Epoch 3980/4999:\n",
            "train Loss: 0.4364 Acc: 0.8733\n",
            "\n",
            "Epoch 3981/4999:\n",
            "train Loss: 0.4364 Acc: 0.8733\n",
            "\n",
            "Epoch 3982/4999:\n",
            "train Loss: 0.4363 Acc: 0.8733\n",
            "\n",
            "Epoch 3983/4999:\n",
            "train Loss: 0.4363 Acc: 0.8733\n",
            "\n",
            "Epoch 3984/4999:\n",
            "train Loss: 0.4363 Acc: 0.8733\n",
            "\n",
            "Epoch 3985/4999:\n",
            "train Loss: 0.4363 Acc: 0.8733\n",
            "\n",
            "Epoch 3986/4999:\n",
            "train Loss: 0.4362 Acc: 0.8733\n",
            "\n",
            "Epoch 3987/4999:\n",
            "train Loss: 0.4362 Acc: 0.8733\n",
            "\n",
            "Epoch 3988/4999:\n",
            "train Loss: 0.4362 Acc: 0.8733\n",
            "\n",
            "Epoch 3989/4999:\n",
            "train Loss: 0.4361 Acc: 0.8733\n",
            "\n",
            "Epoch 3990/4999:\n",
            "train Loss: 0.4361 Acc: 0.8733\n",
            "\n",
            "Epoch 3991/4999:\n",
            "train Loss: 0.4361 Acc: 0.8733\n",
            "\n",
            "Epoch 3992/4999:\n",
            "train Loss: 0.4361 Acc: 0.8733\n",
            "\n",
            "Epoch 3993/4999:\n",
            "train Loss: 0.4360 Acc: 0.8733\n",
            "\n",
            "Epoch 3994/4999:\n",
            "train Loss: 0.4360 Acc: 0.8733\n",
            "\n",
            "Epoch 3995/4999:\n",
            "train Loss: 0.4360 Acc: 0.8733\n",
            "\n",
            "Epoch 3996/4999:\n",
            "train Loss: 0.4359 Acc: 0.8733\n",
            "\n",
            "Epoch 3997/4999:\n",
            "train Loss: 0.4359 Acc: 0.8733\n",
            "\n",
            "Epoch 3998/4999:\n",
            "train Loss: 0.4359 Acc: 0.8733\n",
            "\n",
            "Epoch 3999/4999:\n",
            "train Loss: 0.4359 Acc: 0.8733\n",
            "\n",
            "Epoch 4000/4999:\n",
            "train Loss: 0.4358 Acc: 0.8733\n",
            "\n",
            "Epoch 4001/4999:\n",
            "train Loss: 0.4358 Acc: 0.8733\n",
            "\n",
            "Epoch 4002/4999:\n",
            "train Loss: 0.4358 Acc: 0.8733\n",
            "\n",
            "Epoch 4003/4999:\n",
            "train Loss: 0.4357 Acc: 0.8733\n",
            "\n",
            "Epoch 4004/4999:\n",
            "train Loss: 0.4357 Acc: 0.8733\n",
            "\n",
            "Epoch 4005/4999:\n",
            "train Loss: 0.4357 Acc: 0.8733\n",
            "\n",
            "Epoch 4006/4999:\n",
            "train Loss: 0.4357 Acc: 0.8733\n",
            "\n",
            "Epoch 4007/4999:\n",
            "train Loss: 0.4356 Acc: 0.8733\n",
            "\n",
            "Epoch 4008/4999:\n",
            "train Loss: 0.4356 Acc: 0.8733\n",
            "\n",
            "Epoch 4009/4999:\n",
            "train Loss: 0.4356 Acc: 0.8733\n",
            "\n",
            "Epoch 4010/4999:\n",
            "train Loss: 0.4355 Acc: 0.8733\n",
            "\n",
            "Epoch 4011/4999:\n",
            "train Loss: 0.4355 Acc: 0.8733\n",
            "\n",
            "Epoch 4012/4999:\n",
            "train Loss: 0.4355 Acc: 0.8733\n",
            "\n",
            "Epoch 4013/4999:\n",
            "train Loss: 0.4355 Acc: 0.8733\n",
            "\n",
            "Epoch 4014/4999:\n",
            "train Loss: 0.4354 Acc: 0.8733\n",
            "\n",
            "Epoch 4015/4999:\n",
            "train Loss: 0.4354 Acc: 0.8733\n",
            "\n",
            "Epoch 4016/4999:\n",
            "train Loss: 0.4354 Acc: 0.8733\n",
            "\n",
            "Epoch 4017/4999:\n",
            "train Loss: 0.4353 Acc: 0.8733\n",
            "\n",
            "Epoch 4018/4999:\n",
            "train Loss: 0.4353 Acc: 0.8733\n",
            "\n",
            "Epoch 4019/4999:\n",
            "train Loss: 0.4353 Acc: 0.8733\n",
            "\n",
            "Epoch 4020/4999:\n",
            "train Loss: 0.4353 Acc: 0.8733\n",
            "\n",
            "Epoch 4021/4999:\n",
            "train Loss: 0.4352 Acc: 0.8733\n",
            "\n",
            "Epoch 4022/4999:\n",
            "train Loss: 0.4352 Acc: 0.8733\n",
            "\n",
            "Epoch 4023/4999:\n",
            "train Loss: 0.4352 Acc: 0.8733\n",
            "\n",
            "Epoch 4024/4999:\n",
            "train Loss: 0.4351 Acc: 0.8733\n",
            "\n",
            "Epoch 4025/4999:\n",
            "train Loss: 0.4351 Acc: 0.8733\n",
            "\n",
            "Epoch 4026/4999:\n",
            "train Loss: 0.4351 Acc: 0.8733\n",
            "\n",
            "Epoch 4027/4999:\n",
            "train Loss: 0.4351 Acc: 0.8733\n",
            "\n",
            "Epoch 4028/4999:\n",
            "train Loss: 0.4350 Acc: 0.8733\n",
            "\n",
            "Epoch 4029/4999:\n",
            "train Loss: 0.4350 Acc: 0.8733\n",
            "\n",
            "Epoch 4030/4999:\n",
            "train Loss: 0.4350 Acc: 0.8733\n",
            "\n",
            "Epoch 4031/4999:\n",
            "train Loss: 0.4349 Acc: 0.8733\n",
            "\n",
            "Epoch 4032/4999:\n",
            "train Loss: 0.4349 Acc: 0.8733\n",
            "\n",
            "Epoch 4033/4999:\n",
            "train Loss: 0.4349 Acc: 0.8733\n",
            "\n",
            "Epoch 4034/4999:\n",
            "train Loss: 0.4349 Acc: 0.8733\n",
            "\n",
            "Epoch 4035/4999:\n",
            "train Loss: 0.4348 Acc: 0.8733\n",
            "\n",
            "Epoch 4036/4999:\n",
            "train Loss: 0.4348 Acc: 0.8733\n",
            "\n",
            "Epoch 4037/4999:\n",
            "train Loss: 0.4348 Acc: 0.8733\n",
            "\n",
            "Epoch 4038/4999:\n",
            "train Loss: 0.4347 Acc: 0.8733\n",
            "\n",
            "Epoch 4039/4999:\n",
            "train Loss: 0.4347 Acc: 0.8733\n",
            "\n",
            "Epoch 4040/4999:\n",
            "train Loss: 0.4347 Acc: 0.8733\n",
            "\n",
            "Epoch 4041/4999:\n",
            "train Loss: 0.4347 Acc: 0.8733\n",
            "\n",
            "Epoch 4042/4999:\n",
            "train Loss: 0.4346 Acc: 0.8733\n",
            "\n",
            "Epoch 4043/4999:\n",
            "train Loss: 0.4346 Acc: 0.8733\n",
            "\n",
            "Epoch 4044/4999:\n",
            "train Loss: 0.4346 Acc: 0.8733\n",
            "\n",
            "Epoch 4045/4999:\n",
            "train Loss: 0.4346 Acc: 0.8733\n",
            "\n",
            "Epoch 4046/4999:\n",
            "train Loss: 0.4345 Acc: 0.8733\n",
            "\n",
            "Epoch 4047/4999:\n",
            "train Loss: 0.4345 Acc: 0.8733\n",
            "\n",
            "Epoch 4048/4999:\n",
            "train Loss: 0.4345 Acc: 0.8733\n",
            "\n",
            "Epoch 4049/4999:\n",
            "train Loss: 0.4344 Acc: 0.8733\n",
            "\n",
            "Epoch 4050/4999:\n",
            "train Loss: 0.4344 Acc: 0.8733\n",
            "\n",
            "Epoch 4051/4999:\n",
            "train Loss: 0.4344 Acc: 0.8733\n",
            "\n",
            "Epoch 4052/4999:\n",
            "train Loss: 0.4344 Acc: 0.8733\n",
            "\n",
            "Epoch 4053/4999:\n",
            "train Loss: 0.4343 Acc: 0.8733\n",
            "\n",
            "Epoch 4054/4999:\n",
            "train Loss: 0.4343 Acc: 0.8733\n",
            "\n",
            "Epoch 4055/4999:\n",
            "train Loss: 0.4343 Acc: 0.8733\n",
            "\n",
            "Epoch 4056/4999:\n",
            "train Loss: 0.4342 Acc: 0.8733\n",
            "\n",
            "Epoch 4057/4999:\n",
            "train Loss: 0.4342 Acc: 0.8733\n",
            "\n",
            "Epoch 4058/4999:\n",
            "train Loss: 0.4342 Acc: 0.8733\n",
            "\n",
            "Epoch 4059/4999:\n",
            "train Loss: 0.4342 Acc: 0.8733\n",
            "\n",
            "Epoch 4060/4999:\n",
            "train Loss: 0.4341 Acc: 0.8733\n",
            "\n",
            "Epoch 4061/4999:\n",
            "train Loss: 0.4341 Acc: 0.8733\n",
            "\n",
            "Epoch 4062/4999:\n",
            "train Loss: 0.4341 Acc: 0.8733\n",
            "\n",
            "Epoch 4063/4999:\n",
            "train Loss: 0.4340 Acc: 0.8733\n",
            "\n",
            "Epoch 4064/4999:\n",
            "train Loss: 0.4340 Acc: 0.8733\n",
            "\n",
            "Epoch 4065/4999:\n",
            "train Loss: 0.4340 Acc: 0.8733\n",
            "\n",
            "Epoch 4066/4999:\n",
            "train Loss: 0.4340 Acc: 0.8733\n",
            "\n",
            "Epoch 4067/4999:\n",
            "train Loss: 0.4339 Acc: 0.8733\n",
            "\n",
            "Epoch 4068/4999:\n",
            "train Loss: 0.4339 Acc: 0.8733\n",
            "\n",
            "Epoch 4069/4999:\n",
            "train Loss: 0.4339 Acc: 0.8733\n",
            "\n",
            "Epoch 4070/4999:\n",
            "train Loss: 0.4338 Acc: 0.8733\n",
            "\n",
            "Epoch 4071/4999:\n",
            "train Loss: 0.4338 Acc: 0.8733\n",
            "\n",
            "Epoch 4072/4999:\n",
            "train Loss: 0.4338 Acc: 0.8733\n",
            "\n",
            "Epoch 4073/4999:\n",
            "train Loss: 0.4338 Acc: 0.8733\n",
            "\n",
            "Epoch 4074/4999:\n",
            "train Loss: 0.4337 Acc: 0.8733\n",
            "\n",
            "Epoch 4075/4999:\n",
            "train Loss: 0.4337 Acc: 0.8733\n",
            "\n",
            "Epoch 4076/4999:\n",
            "train Loss: 0.4337 Acc: 0.8733\n",
            "\n",
            "Epoch 4077/4999:\n",
            "train Loss: 0.4337 Acc: 0.8733\n",
            "\n",
            "Epoch 4078/4999:\n",
            "train Loss: 0.4336 Acc: 0.8733\n",
            "\n",
            "Epoch 4079/4999:\n",
            "train Loss: 0.4336 Acc: 0.8733\n",
            "\n",
            "Epoch 4080/4999:\n",
            "train Loss: 0.4336 Acc: 0.8733\n",
            "\n",
            "Epoch 4081/4999:\n",
            "train Loss: 0.4335 Acc: 0.8733\n",
            "\n",
            "Epoch 4082/4999:\n",
            "train Loss: 0.4335 Acc: 0.8733\n",
            "\n",
            "Epoch 4083/4999:\n",
            "train Loss: 0.4335 Acc: 0.8733\n",
            "\n",
            "Epoch 4084/4999:\n",
            "train Loss: 0.4335 Acc: 0.8733\n",
            "\n",
            "Epoch 4085/4999:\n",
            "train Loss: 0.4334 Acc: 0.8733\n",
            "\n",
            "Epoch 4086/4999:\n",
            "train Loss: 0.4334 Acc: 0.8733\n",
            "\n",
            "Epoch 4087/4999:\n",
            "train Loss: 0.4334 Acc: 0.8733\n",
            "\n",
            "Epoch 4088/4999:\n",
            "train Loss: 0.4333 Acc: 0.8733\n",
            "\n",
            "Epoch 4089/4999:\n",
            "train Loss: 0.4333 Acc: 0.8733\n",
            "\n",
            "Epoch 4090/4999:\n",
            "train Loss: 0.4333 Acc: 0.8733\n",
            "\n",
            "Epoch 4091/4999:\n",
            "train Loss: 0.4333 Acc: 0.8733\n",
            "\n",
            "Epoch 4092/4999:\n",
            "train Loss: 0.4332 Acc: 0.8733\n",
            "\n",
            "Epoch 4093/4999:\n",
            "train Loss: 0.4332 Acc: 0.8733\n",
            "\n",
            "Epoch 4094/4999:\n",
            "train Loss: 0.4332 Acc: 0.8733\n",
            "\n",
            "Epoch 4095/4999:\n",
            "train Loss: 0.4331 Acc: 0.8733\n",
            "\n",
            "Epoch 4096/4999:\n",
            "train Loss: 0.4331 Acc: 0.8733\n",
            "\n",
            "Epoch 4097/4999:\n",
            "train Loss: 0.4331 Acc: 0.8733\n",
            "\n",
            "Epoch 4098/4999:\n",
            "train Loss: 0.4331 Acc: 0.8733\n",
            "\n",
            "Epoch 4099/4999:\n",
            "train Loss: 0.4330 Acc: 0.8733\n",
            "\n",
            "Epoch 4100/4999:\n",
            "train Loss: 0.4330 Acc: 0.8733\n",
            "\n",
            "Epoch 4101/4999:\n",
            "train Loss: 0.4330 Acc: 0.8733\n",
            "\n",
            "Epoch 4102/4999:\n",
            "train Loss: 0.4329 Acc: 0.8733\n",
            "\n",
            "Epoch 4103/4999:\n",
            "train Loss: 0.4329 Acc: 0.8733\n",
            "\n",
            "Epoch 4104/4999:\n",
            "train Loss: 0.4329 Acc: 0.8733\n",
            "\n",
            "Epoch 4105/4999:\n",
            "train Loss: 0.4329 Acc: 0.8733\n",
            "\n",
            "Epoch 4106/4999:\n",
            "train Loss: 0.4328 Acc: 0.8733\n",
            "\n",
            "Epoch 4107/4999:\n",
            "train Loss: 0.4328 Acc: 0.8733\n",
            "\n",
            "Epoch 4108/4999:\n",
            "train Loss: 0.4328 Acc: 0.8733\n",
            "\n",
            "Epoch 4109/4999:\n",
            "train Loss: 0.4328 Acc: 0.8733\n",
            "\n",
            "Epoch 4110/4999:\n",
            "train Loss: 0.4327 Acc: 0.8733\n",
            "\n",
            "Epoch 4111/4999:\n",
            "train Loss: 0.4327 Acc: 0.8733\n",
            "\n",
            "Epoch 4112/4999:\n",
            "train Loss: 0.4327 Acc: 0.8733\n",
            "\n",
            "Epoch 4113/4999:\n",
            "train Loss: 0.4326 Acc: 0.8733\n",
            "\n",
            "Epoch 4114/4999:\n",
            "train Loss: 0.4326 Acc: 0.8733\n",
            "\n",
            "Epoch 4115/4999:\n",
            "train Loss: 0.4326 Acc: 0.8733\n",
            "\n",
            "Epoch 4116/4999:\n",
            "train Loss: 0.4326 Acc: 0.8733\n",
            "\n",
            "Epoch 4117/4999:\n",
            "train Loss: 0.4325 Acc: 0.8733\n",
            "\n",
            "Epoch 4118/4999:\n",
            "train Loss: 0.4325 Acc: 0.8733\n",
            "\n",
            "Epoch 4119/4999:\n",
            "train Loss: 0.4325 Acc: 0.8733\n",
            "\n",
            "Epoch 4120/4999:\n",
            "train Loss: 0.4324 Acc: 0.8733\n",
            "\n",
            "Epoch 4121/4999:\n",
            "train Loss: 0.4324 Acc: 0.8733\n",
            "\n",
            "Epoch 4122/4999:\n",
            "train Loss: 0.4324 Acc: 0.8733\n",
            "\n",
            "Epoch 4123/4999:\n",
            "train Loss: 0.4324 Acc: 0.8733\n",
            "\n",
            "Epoch 4124/4999:\n",
            "train Loss: 0.4323 Acc: 0.8733\n",
            "\n",
            "Epoch 4125/4999:\n",
            "train Loss: 0.4323 Acc: 0.8733\n",
            "\n",
            "Epoch 4126/4999:\n",
            "train Loss: 0.4323 Acc: 0.8733\n",
            "\n",
            "Epoch 4127/4999:\n",
            "train Loss: 0.4322 Acc: 0.8733\n",
            "\n",
            "Epoch 4128/4999:\n",
            "train Loss: 0.4322 Acc: 0.8733\n",
            "\n",
            "Epoch 4129/4999:\n",
            "train Loss: 0.4322 Acc: 0.8733\n",
            "\n",
            "Epoch 4130/4999:\n",
            "train Loss: 0.4322 Acc: 0.8733\n",
            "\n",
            "Epoch 4131/4999:\n",
            "train Loss: 0.4321 Acc: 0.8733\n",
            "\n",
            "Epoch 4132/4999:\n",
            "train Loss: 0.4321 Acc: 0.8733\n",
            "\n",
            "Epoch 4133/4999:\n",
            "train Loss: 0.4321 Acc: 0.8733\n",
            "\n",
            "Epoch 4134/4999:\n",
            "train Loss: 0.4320 Acc: 0.8733\n",
            "\n",
            "Epoch 4135/4999:\n",
            "train Loss: 0.4320 Acc: 0.8733\n",
            "\n",
            "Epoch 4136/4999:\n",
            "train Loss: 0.4320 Acc: 0.8733\n",
            "\n",
            "Epoch 4137/4999:\n",
            "train Loss: 0.4320 Acc: 0.8733\n",
            "\n",
            "Epoch 4138/4999:\n",
            "train Loss: 0.4319 Acc: 0.8733\n",
            "\n",
            "Epoch 4139/4999:\n",
            "train Loss: 0.4319 Acc: 0.8733\n",
            "\n",
            "Epoch 4140/4999:\n",
            "train Loss: 0.4319 Acc: 0.8733\n",
            "\n",
            "Epoch 4141/4999:\n",
            "train Loss: 0.4319 Acc: 0.8733\n",
            "\n",
            "Epoch 4142/4999:\n",
            "train Loss: 0.4318 Acc: 0.8733\n",
            "\n",
            "Epoch 4143/4999:\n",
            "train Loss: 0.4318 Acc: 0.8733\n",
            "\n",
            "Epoch 4144/4999:\n",
            "train Loss: 0.4318 Acc: 0.8733\n",
            "\n",
            "Epoch 4145/4999:\n",
            "train Loss: 0.4317 Acc: 0.8733\n",
            "\n",
            "Epoch 4146/4999:\n",
            "train Loss: 0.4317 Acc: 0.8733\n",
            "\n",
            "Epoch 4147/4999:\n",
            "train Loss: 0.4317 Acc: 0.8733\n",
            "\n",
            "Epoch 4148/4999:\n",
            "train Loss: 0.4317 Acc: 0.8733\n",
            "\n",
            "Epoch 4149/4999:\n",
            "train Loss: 0.4316 Acc: 0.8733\n",
            "\n",
            "Epoch 4150/4999:\n",
            "train Loss: 0.4316 Acc: 0.8733\n",
            "\n",
            "Epoch 4151/4999:\n",
            "train Loss: 0.4316 Acc: 0.8733\n",
            "\n",
            "Epoch 4152/4999:\n",
            "train Loss: 0.4315 Acc: 0.8733\n",
            "\n",
            "Epoch 4153/4999:\n",
            "train Loss: 0.4315 Acc: 0.8733\n",
            "\n",
            "Epoch 4154/4999:\n",
            "train Loss: 0.4315 Acc: 0.8733\n",
            "\n",
            "Epoch 4155/4999:\n",
            "train Loss: 0.4315 Acc: 0.8733\n",
            "\n",
            "Epoch 4156/4999:\n",
            "train Loss: 0.4314 Acc: 0.8733\n",
            "\n",
            "Epoch 4157/4999:\n",
            "train Loss: 0.4314 Acc: 0.8733\n",
            "\n",
            "Epoch 4158/4999:\n",
            "train Loss: 0.4314 Acc: 0.8800\n",
            "\n",
            "Epoch 4159/4999:\n",
            "train Loss: 0.4314 Acc: 0.8800\n",
            "\n",
            "Epoch 4160/4999:\n",
            "train Loss: 0.4313 Acc: 0.8800\n",
            "\n",
            "Epoch 4161/4999:\n",
            "train Loss: 0.4313 Acc: 0.8800\n",
            "\n",
            "Epoch 4162/4999:\n",
            "train Loss: 0.4313 Acc: 0.8800\n",
            "\n",
            "Epoch 4163/4999:\n",
            "train Loss: 0.4312 Acc: 0.8800\n",
            "\n",
            "Epoch 4164/4999:\n",
            "train Loss: 0.4312 Acc: 0.8800\n",
            "\n",
            "Epoch 4165/4999:\n",
            "train Loss: 0.4312 Acc: 0.8800\n",
            "\n",
            "Epoch 4166/4999:\n",
            "train Loss: 0.4312 Acc: 0.8800\n",
            "\n",
            "Epoch 4167/4999:\n",
            "train Loss: 0.4311 Acc: 0.8800\n",
            "\n",
            "Epoch 4168/4999:\n",
            "train Loss: 0.4311 Acc: 0.8800\n",
            "\n",
            "Epoch 4169/4999:\n",
            "train Loss: 0.4311 Acc: 0.8800\n",
            "\n",
            "Epoch 4170/4999:\n",
            "train Loss: 0.4310 Acc: 0.8800\n",
            "\n",
            "Epoch 4171/4999:\n",
            "train Loss: 0.4310 Acc: 0.8800\n",
            "\n",
            "Epoch 4172/4999:\n",
            "train Loss: 0.4310 Acc: 0.8800\n",
            "\n",
            "Epoch 4173/4999:\n",
            "train Loss: 0.4310 Acc: 0.8800\n",
            "\n",
            "Epoch 4174/4999:\n",
            "train Loss: 0.4309 Acc: 0.8800\n",
            "\n",
            "Epoch 4175/4999:\n",
            "train Loss: 0.4309 Acc: 0.8800\n",
            "\n",
            "Epoch 4176/4999:\n",
            "train Loss: 0.4309 Acc: 0.8800\n",
            "\n",
            "Epoch 4177/4999:\n",
            "train Loss: 0.4308 Acc: 0.8800\n",
            "\n",
            "Epoch 4178/4999:\n",
            "train Loss: 0.4308 Acc: 0.8800\n",
            "\n",
            "Epoch 4179/4999:\n",
            "train Loss: 0.4308 Acc: 0.8800\n",
            "\n",
            "Epoch 4180/4999:\n",
            "train Loss: 0.4308 Acc: 0.8800\n",
            "\n",
            "Epoch 4181/4999:\n",
            "train Loss: 0.4307 Acc: 0.8800\n",
            "\n",
            "Epoch 4182/4999:\n",
            "train Loss: 0.4307 Acc: 0.8800\n",
            "\n",
            "Epoch 4183/4999:\n",
            "train Loss: 0.4307 Acc: 0.8800\n",
            "\n",
            "Epoch 4184/4999:\n",
            "train Loss: 0.4307 Acc: 0.8800\n",
            "\n",
            "Epoch 4185/4999:\n",
            "train Loss: 0.4306 Acc: 0.8800\n",
            "\n",
            "Epoch 4186/4999:\n",
            "train Loss: 0.4306 Acc: 0.8800\n",
            "\n",
            "Epoch 4187/4999:\n",
            "train Loss: 0.4306 Acc: 0.8800\n",
            "\n",
            "Epoch 4188/4999:\n",
            "train Loss: 0.4305 Acc: 0.8800\n",
            "\n",
            "Epoch 4189/4999:\n",
            "train Loss: 0.4305 Acc: 0.8800\n",
            "\n",
            "Epoch 4190/4999:\n",
            "train Loss: 0.4305 Acc: 0.8800\n",
            "\n",
            "Epoch 4191/4999:\n",
            "train Loss: 0.4305 Acc: 0.8800\n",
            "\n",
            "Epoch 4192/4999:\n",
            "train Loss: 0.4304 Acc: 0.8800\n",
            "\n",
            "Epoch 4193/4999:\n",
            "train Loss: 0.4304 Acc: 0.8800\n",
            "\n",
            "Epoch 4194/4999:\n",
            "train Loss: 0.4304 Acc: 0.8800\n",
            "\n",
            "Epoch 4195/4999:\n",
            "train Loss: 0.4303 Acc: 0.8800\n",
            "\n",
            "Epoch 4196/4999:\n",
            "train Loss: 0.4303 Acc: 0.8800\n",
            "\n",
            "Epoch 4197/4999:\n",
            "train Loss: 0.4303 Acc: 0.8800\n",
            "\n",
            "Epoch 4198/4999:\n",
            "train Loss: 0.4303 Acc: 0.8800\n",
            "\n",
            "Epoch 4199/4999:\n",
            "train Loss: 0.4302 Acc: 0.8800\n",
            "\n",
            "Epoch 4200/4999:\n",
            "train Loss: 0.4302 Acc: 0.8800\n",
            "\n",
            "Epoch 4201/4999:\n",
            "train Loss: 0.4302 Acc: 0.8800\n",
            "\n",
            "Epoch 4202/4999:\n",
            "train Loss: 0.4302 Acc: 0.8800\n",
            "\n",
            "Epoch 4203/4999:\n",
            "train Loss: 0.4301 Acc: 0.8800\n",
            "\n",
            "Epoch 4204/4999:\n",
            "train Loss: 0.4301 Acc: 0.8800\n",
            "\n",
            "Epoch 4205/4999:\n",
            "train Loss: 0.4301 Acc: 0.8800\n",
            "\n",
            "Epoch 4206/4999:\n",
            "train Loss: 0.4300 Acc: 0.8800\n",
            "\n",
            "Epoch 4207/4999:\n",
            "train Loss: 0.4300 Acc: 0.8800\n",
            "\n",
            "Epoch 4208/4999:\n",
            "train Loss: 0.4300 Acc: 0.8800\n",
            "\n",
            "Epoch 4209/4999:\n",
            "train Loss: 0.4300 Acc: 0.8800\n",
            "\n",
            "Epoch 4210/4999:\n",
            "train Loss: 0.4299 Acc: 0.8800\n",
            "\n",
            "Epoch 4211/4999:\n",
            "train Loss: 0.4299 Acc: 0.8800\n",
            "\n",
            "Epoch 4212/4999:\n",
            "train Loss: 0.4299 Acc: 0.8800\n",
            "\n",
            "Epoch 4213/4999:\n",
            "train Loss: 0.4298 Acc: 0.8800\n",
            "\n",
            "Epoch 4214/4999:\n",
            "train Loss: 0.4298 Acc: 0.8800\n",
            "\n",
            "Epoch 4215/4999:\n",
            "train Loss: 0.4298 Acc: 0.8800\n",
            "\n",
            "Epoch 4216/4999:\n",
            "train Loss: 0.4298 Acc: 0.8800\n",
            "\n",
            "Epoch 4217/4999:\n",
            "train Loss: 0.4297 Acc: 0.8800\n",
            "\n",
            "Epoch 4218/4999:\n",
            "train Loss: 0.4297 Acc: 0.8800\n",
            "\n",
            "Epoch 4219/4999:\n",
            "train Loss: 0.4297 Acc: 0.8800\n",
            "\n",
            "Epoch 4220/4999:\n",
            "train Loss: 0.4297 Acc: 0.8800\n",
            "\n",
            "Epoch 4221/4999:\n",
            "train Loss: 0.4296 Acc: 0.8800\n",
            "\n",
            "Epoch 4222/4999:\n",
            "train Loss: 0.4296 Acc: 0.8800\n",
            "\n",
            "Epoch 4223/4999:\n",
            "train Loss: 0.4296 Acc: 0.8800\n",
            "\n",
            "Epoch 4224/4999:\n",
            "train Loss: 0.4295 Acc: 0.8800\n",
            "\n",
            "Epoch 4225/4999:\n",
            "train Loss: 0.4295 Acc: 0.8800\n",
            "\n",
            "Epoch 4226/4999:\n",
            "train Loss: 0.4295 Acc: 0.8800\n",
            "\n",
            "Epoch 4227/4999:\n",
            "train Loss: 0.4295 Acc: 0.8800\n",
            "\n",
            "Epoch 4228/4999:\n",
            "train Loss: 0.4294 Acc: 0.8800\n",
            "\n",
            "Epoch 4229/4999:\n",
            "train Loss: 0.4294 Acc: 0.8800\n",
            "\n",
            "Epoch 4230/4999:\n",
            "train Loss: 0.4294 Acc: 0.8800\n",
            "\n",
            "Epoch 4231/4999:\n",
            "train Loss: 0.4293 Acc: 0.8800\n",
            "\n",
            "Epoch 4232/4999:\n",
            "train Loss: 0.4293 Acc: 0.8800\n",
            "\n",
            "Epoch 4233/4999:\n",
            "train Loss: 0.4293 Acc: 0.8800\n",
            "\n",
            "Epoch 4234/4999:\n",
            "train Loss: 0.4293 Acc: 0.8800\n",
            "\n",
            "Epoch 4235/4999:\n",
            "train Loss: 0.4292 Acc: 0.8800\n",
            "\n",
            "Epoch 4236/4999:\n",
            "train Loss: 0.4292 Acc: 0.8800\n",
            "\n",
            "Epoch 4237/4999:\n",
            "train Loss: 0.4292 Acc: 0.8800\n",
            "\n",
            "Epoch 4238/4999:\n",
            "train Loss: 0.4292 Acc: 0.8800\n",
            "\n",
            "Epoch 4239/4999:\n",
            "train Loss: 0.4291 Acc: 0.8800\n",
            "\n",
            "Epoch 4240/4999:\n",
            "train Loss: 0.4291 Acc: 0.8800\n",
            "\n",
            "Epoch 4241/4999:\n",
            "train Loss: 0.4291 Acc: 0.8800\n",
            "\n",
            "Epoch 4242/4999:\n",
            "train Loss: 0.4290 Acc: 0.8800\n",
            "\n",
            "Epoch 4243/4999:\n",
            "train Loss: 0.4290 Acc: 0.8800\n",
            "\n",
            "Epoch 4244/4999:\n",
            "train Loss: 0.4290 Acc: 0.8800\n",
            "\n",
            "Epoch 4245/4999:\n",
            "train Loss: 0.4290 Acc: 0.8800\n",
            "\n",
            "Epoch 4246/4999:\n",
            "train Loss: 0.4289 Acc: 0.8800\n",
            "\n",
            "Epoch 4247/4999:\n",
            "train Loss: 0.4289 Acc: 0.8800\n",
            "\n",
            "Epoch 4248/4999:\n",
            "train Loss: 0.4289 Acc: 0.8800\n",
            "\n",
            "Epoch 4249/4999:\n",
            "train Loss: 0.4288 Acc: 0.8800\n",
            "\n",
            "Epoch 4250/4999:\n",
            "train Loss: 0.4288 Acc: 0.8800\n",
            "\n",
            "Epoch 4251/4999:\n",
            "train Loss: 0.4288 Acc: 0.8800\n",
            "\n",
            "Epoch 4252/4999:\n",
            "train Loss: 0.4288 Acc: 0.8800\n",
            "\n",
            "Epoch 4253/4999:\n",
            "train Loss: 0.4287 Acc: 0.8800\n",
            "\n",
            "Epoch 4254/4999:\n",
            "train Loss: 0.4287 Acc: 0.8800\n",
            "\n",
            "Epoch 4255/4999:\n",
            "train Loss: 0.4287 Acc: 0.8800\n",
            "\n",
            "Epoch 4256/4999:\n",
            "train Loss: 0.4287 Acc: 0.8800\n",
            "\n",
            "Epoch 4257/4999:\n",
            "train Loss: 0.4286 Acc: 0.8800\n",
            "\n",
            "Epoch 4258/4999:\n",
            "train Loss: 0.4286 Acc: 0.8800\n",
            "\n",
            "Epoch 4259/4999:\n",
            "train Loss: 0.4286 Acc: 0.8800\n",
            "\n",
            "Epoch 4260/4999:\n",
            "train Loss: 0.4285 Acc: 0.8800\n",
            "\n",
            "Epoch 4261/4999:\n",
            "train Loss: 0.4285 Acc: 0.8800\n",
            "\n",
            "Epoch 4262/4999:\n",
            "train Loss: 0.4285 Acc: 0.8800\n",
            "\n",
            "Epoch 4263/4999:\n",
            "train Loss: 0.4285 Acc: 0.8800\n",
            "\n",
            "Epoch 4264/4999:\n",
            "train Loss: 0.4284 Acc: 0.8800\n",
            "\n",
            "Epoch 4265/4999:\n",
            "train Loss: 0.4284 Acc: 0.8867\n",
            "\n",
            "Epoch 4266/4999:\n",
            "train Loss: 0.4284 Acc: 0.8867\n",
            "\n",
            "Epoch 4267/4999:\n",
            "train Loss: 0.4283 Acc: 0.8867\n",
            "\n",
            "Epoch 4268/4999:\n",
            "train Loss: 0.4283 Acc: 0.8867\n",
            "\n",
            "Epoch 4269/4999:\n",
            "train Loss: 0.4283 Acc: 0.8867\n",
            "\n",
            "Epoch 4270/4999:\n",
            "train Loss: 0.4283 Acc: 0.8867\n",
            "\n",
            "Epoch 4271/4999:\n",
            "train Loss: 0.4282 Acc: 0.8867\n",
            "\n",
            "Epoch 4272/4999:\n",
            "train Loss: 0.4282 Acc: 0.8867\n",
            "\n",
            "Epoch 4273/4999:\n",
            "train Loss: 0.4282 Acc: 0.8867\n",
            "\n",
            "Epoch 4274/4999:\n",
            "train Loss: 0.4282 Acc: 0.8867\n",
            "\n",
            "Epoch 4275/4999:\n",
            "train Loss: 0.4281 Acc: 0.8867\n",
            "\n",
            "Epoch 4276/4999:\n",
            "train Loss: 0.4281 Acc: 0.8867\n",
            "\n",
            "Epoch 4277/4999:\n",
            "train Loss: 0.4281 Acc: 0.8867\n",
            "\n",
            "Epoch 4278/4999:\n",
            "train Loss: 0.4280 Acc: 0.8867\n",
            "\n",
            "Epoch 4279/4999:\n",
            "train Loss: 0.4280 Acc: 0.8867\n",
            "\n",
            "Epoch 4280/4999:\n",
            "train Loss: 0.4280 Acc: 0.8867\n",
            "\n",
            "Epoch 4281/4999:\n",
            "train Loss: 0.4280 Acc: 0.8867\n",
            "\n",
            "Epoch 4282/4999:\n",
            "train Loss: 0.4279 Acc: 0.8867\n",
            "\n",
            "Epoch 4283/4999:\n",
            "train Loss: 0.4279 Acc: 0.8867\n",
            "\n",
            "Epoch 4284/4999:\n",
            "train Loss: 0.4279 Acc: 0.8867\n",
            "\n",
            "Epoch 4285/4999:\n",
            "train Loss: 0.4279 Acc: 0.8867\n",
            "\n",
            "Epoch 4286/4999:\n",
            "train Loss: 0.4278 Acc: 0.8867\n",
            "\n",
            "Epoch 4287/4999:\n",
            "train Loss: 0.4278 Acc: 0.8867\n",
            "\n",
            "Epoch 4288/4999:\n",
            "train Loss: 0.4278 Acc: 0.8867\n",
            "\n",
            "Epoch 4289/4999:\n",
            "train Loss: 0.4277 Acc: 0.8867\n",
            "\n",
            "Epoch 4290/4999:\n",
            "train Loss: 0.4277 Acc: 0.8867\n",
            "\n",
            "Epoch 4291/4999:\n",
            "train Loss: 0.4277 Acc: 0.8867\n",
            "\n",
            "Epoch 4292/4999:\n",
            "train Loss: 0.4277 Acc: 0.8867\n",
            "\n",
            "Epoch 4293/4999:\n",
            "train Loss: 0.4276 Acc: 0.8867\n",
            "\n",
            "Epoch 4294/4999:\n",
            "train Loss: 0.4276 Acc: 0.8867\n",
            "\n",
            "Epoch 4295/4999:\n",
            "train Loss: 0.4276 Acc: 0.8867\n",
            "\n",
            "Epoch 4296/4999:\n",
            "train Loss: 0.4275 Acc: 0.8867\n",
            "\n",
            "Epoch 4297/4999:\n",
            "train Loss: 0.4275 Acc: 0.8867\n",
            "\n",
            "Epoch 4298/4999:\n",
            "train Loss: 0.4275 Acc: 0.8867\n",
            "\n",
            "Epoch 4299/4999:\n",
            "train Loss: 0.4275 Acc: 0.8867\n",
            "\n",
            "Epoch 4300/4999:\n",
            "train Loss: 0.4274 Acc: 0.8867\n",
            "\n",
            "Epoch 4301/4999:\n",
            "train Loss: 0.4274 Acc: 0.8867\n",
            "\n",
            "Epoch 4302/4999:\n",
            "train Loss: 0.4274 Acc: 0.8867\n",
            "\n",
            "Epoch 4303/4999:\n",
            "train Loss: 0.4274 Acc: 0.8867\n",
            "\n",
            "Epoch 4304/4999:\n",
            "train Loss: 0.4273 Acc: 0.8867\n",
            "\n",
            "Epoch 4305/4999:\n",
            "train Loss: 0.4273 Acc: 0.8867\n",
            "\n",
            "Epoch 4306/4999:\n",
            "train Loss: 0.4273 Acc: 0.8867\n",
            "\n",
            "Epoch 4307/4999:\n",
            "train Loss: 0.4272 Acc: 0.8867\n",
            "\n",
            "Epoch 4308/4999:\n",
            "train Loss: 0.4272 Acc: 0.8867\n",
            "\n",
            "Epoch 4309/4999:\n",
            "train Loss: 0.4272 Acc: 0.8867\n",
            "\n",
            "Epoch 4310/4999:\n",
            "train Loss: 0.4272 Acc: 0.8867\n",
            "\n",
            "Epoch 4311/4999:\n",
            "train Loss: 0.4271 Acc: 0.8867\n",
            "\n",
            "Epoch 4312/4999:\n",
            "train Loss: 0.4271 Acc: 0.8867\n",
            "\n",
            "Epoch 4313/4999:\n",
            "train Loss: 0.4271 Acc: 0.8867\n",
            "\n",
            "Epoch 4314/4999:\n",
            "train Loss: 0.4271 Acc: 0.8867\n",
            "\n",
            "Epoch 4315/4999:\n",
            "train Loss: 0.4270 Acc: 0.8867\n",
            "\n",
            "Epoch 4316/4999:\n",
            "train Loss: 0.4270 Acc: 0.8867\n",
            "\n",
            "Epoch 4317/4999:\n",
            "train Loss: 0.4270 Acc: 0.8867\n",
            "\n",
            "Epoch 4318/4999:\n",
            "train Loss: 0.4269 Acc: 0.8867\n",
            "\n",
            "Epoch 4319/4999:\n",
            "train Loss: 0.4269 Acc: 0.8867\n",
            "\n",
            "Epoch 4320/4999:\n",
            "train Loss: 0.4269 Acc: 0.8867\n",
            "\n",
            "Epoch 4321/4999:\n",
            "train Loss: 0.4269 Acc: 0.8867\n",
            "\n",
            "Epoch 4322/4999:\n",
            "train Loss: 0.4268 Acc: 0.8867\n",
            "\n",
            "Epoch 4323/4999:\n",
            "train Loss: 0.4268 Acc: 0.8867\n",
            "\n",
            "Epoch 4324/4999:\n",
            "train Loss: 0.4268 Acc: 0.8867\n",
            "\n",
            "Epoch 4325/4999:\n",
            "train Loss: 0.4267 Acc: 0.8867\n",
            "\n",
            "Epoch 4326/4999:\n",
            "train Loss: 0.4267 Acc: 0.8867\n",
            "\n",
            "Epoch 4327/4999:\n",
            "train Loss: 0.4267 Acc: 0.8867\n",
            "\n",
            "Epoch 4328/4999:\n",
            "train Loss: 0.4267 Acc: 0.8867\n",
            "\n",
            "Epoch 4329/4999:\n",
            "train Loss: 0.4266 Acc: 0.8867\n",
            "\n",
            "Epoch 4330/4999:\n",
            "train Loss: 0.4266 Acc: 0.8867\n",
            "\n",
            "Epoch 4331/4999:\n",
            "train Loss: 0.4266 Acc: 0.8867\n",
            "\n",
            "Epoch 4332/4999:\n",
            "train Loss: 0.4266 Acc: 0.8867\n",
            "\n",
            "Epoch 4333/4999:\n",
            "train Loss: 0.4265 Acc: 0.8867\n",
            "\n",
            "Epoch 4334/4999:\n",
            "train Loss: 0.4265 Acc: 0.8867\n",
            "\n",
            "Epoch 4335/4999:\n",
            "train Loss: 0.4265 Acc: 0.8867\n",
            "\n",
            "Epoch 4336/4999:\n",
            "train Loss: 0.4264 Acc: 0.8867\n",
            "\n",
            "Epoch 4337/4999:\n",
            "train Loss: 0.4264 Acc: 0.8867\n",
            "\n",
            "Epoch 4338/4999:\n",
            "train Loss: 0.4264 Acc: 0.8867\n",
            "\n",
            "Epoch 4339/4999:\n",
            "train Loss: 0.4264 Acc: 0.8867\n",
            "\n",
            "Epoch 4340/4999:\n",
            "train Loss: 0.4263 Acc: 0.8867\n",
            "\n",
            "Epoch 4341/4999:\n",
            "train Loss: 0.4263 Acc: 0.8867\n",
            "\n",
            "Epoch 4342/4999:\n",
            "train Loss: 0.4263 Acc: 0.8867\n",
            "\n",
            "Epoch 4343/4999:\n",
            "train Loss: 0.4263 Acc: 0.8867\n",
            "\n",
            "Epoch 4344/4999:\n",
            "train Loss: 0.4262 Acc: 0.8867\n",
            "\n",
            "Epoch 4345/4999:\n",
            "train Loss: 0.4262 Acc: 0.8867\n",
            "\n",
            "Epoch 4346/4999:\n",
            "train Loss: 0.4262 Acc: 0.8867\n",
            "\n",
            "Epoch 4347/4999:\n",
            "train Loss: 0.4261 Acc: 0.8867\n",
            "\n",
            "Epoch 4348/4999:\n",
            "train Loss: 0.4261 Acc: 0.8867\n",
            "\n",
            "Epoch 4349/4999:\n",
            "train Loss: 0.4261 Acc: 0.8867\n",
            "\n",
            "Epoch 4350/4999:\n",
            "train Loss: 0.4261 Acc: 0.8867\n",
            "\n",
            "Epoch 4351/4999:\n",
            "train Loss: 0.4260 Acc: 0.8867\n",
            "\n",
            "Epoch 4352/4999:\n",
            "train Loss: 0.4260 Acc: 0.8867\n",
            "\n",
            "Epoch 4353/4999:\n",
            "train Loss: 0.4260 Acc: 0.8867\n",
            "\n",
            "Epoch 4354/4999:\n",
            "train Loss: 0.4260 Acc: 0.8867\n",
            "\n",
            "Epoch 4355/4999:\n",
            "train Loss: 0.4259 Acc: 0.8867\n",
            "\n",
            "Epoch 4356/4999:\n",
            "train Loss: 0.4259 Acc: 0.8867\n",
            "\n",
            "Epoch 4357/4999:\n",
            "train Loss: 0.4259 Acc: 0.8867\n",
            "\n",
            "Epoch 4358/4999:\n",
            "train Loss: 0.4258 Acc: 0.8867\n",
            "\n",
            "Epoch 4359/4999:\n",
            "train Loss: 0.4258 Acc: 0.8867\n",
            "\n",
            "Epoch 4360/4999:\n",
            "train Loss: 0.4258 Acc: 0.8867\n",
            "\n",
            "Epoch 4361/4999:\n",
            "train Loss: 0.4258 Acc: 0.8867\n",
            "\n",
            "Epoch 4362/4999:\n",
            "train Loss: 0.4257 Acc: 0.8867\n",
            "\n",
            "Epoch 4363/4999:\n",
            "train Loss: 0.4257 Acc: 0.8867\n",
            "\n",
            "Epoch 4364/4999:\n",
            "train Loss: 0.4257 Acc: 0.8867\n",
            "\n",
            "Epoch 4365/4999:\n",
            "train Loss: 0.4256 Acc: 0.8867\n",
            "\n",
            "Epoch 4366/4999:\n",
            "train Loss: 0.4256 Acc: 0.8867\n",
            "\n",
            "Epoch 4367/4999:\n",
            "train Loss: 0.4256 Acc: 0.8867\n",
            "\n",
            "Epoch 4368/4999:\n",
            "train Loss: 0.4256 Acc: 0.8867\n",
            "\n",
            "Epoch 4369/4999:\n",
            "train Loss: 0.4255 Acc: 0.8867\n",
            "\n",
            "Epoch 4370/4999:\n",
            "train Loss: 0.4255 Acc: 0.8867\n",
            "\n",
            "Epoch 4371/4999:\n",
            "train Loss: 0.4255 Acc: 0.8867\n",
            "\n",
            "Epoch 4372/4999:\n",
            "train Loss: 0.4255 Acc: 0.8867\n",
            "\n",
            "Epoch 4373/4999:\n",
            "train Loss: 0.4254 Acc: 0.8867\n",
            "\n",
            "Epoch 4374/4999:\n",
            "train Loss: 0.4254 Acc: 0.8867\n",
            "\n",
            "Epoch 4375/4999:\n",
            "train Loss: 0.4254 Acc: 0.8867\n",
            "\n",
            "Epoch 4376/4999:\n",
            "train Loss: 0.4253 Acc: 0.8867\n",
            "\n",
            "Epoch 4377/4999:\n",
            "train Loss: 0.4253 Acc: 0.8867\n",
            "\n",
            "Epoch 4378/4999:\n",
            "train Loss: 0.4253 Acc: 0.8867\n",
            "\n",
            "Epoch 4379/4999:\n",
            "train Loss: 0.4253 Acc: 0.8867\n",
            "\n",
            "Epoch 4380/4999:\n",
            "train Loss: 0.4252 Acc: 0.8867\n",
            "\n",
            "Epoch 4381/4999:\n",
            "train Loss: 0.4252 Acc: 0.8867\n",
            "\n",
            "Epoch 4382/4999:\n",
            "train Loss: 0.4252 Acc: 0.8867\n",
            "\n",
            "Epoch 4383/4999:\n",
            "train Loss: 0.4252 Acc: 0.8867\n",
            "\n",
            "Epoch 4384/4999:\n",
            "train Loss: 0.4251 Acc: 0.8867\n",
            "\n",
            "Epoch 4385/4999:\n",
            "train Loss: 0.4251 Acc: 0.8867\n",
            "\n",
            "Epoch 4386/4999:\n",
            "train Loss: 0.4251 Acc: 0.8867\n",
            "\n",
            "Epoch 4387/4999:\n",
            "train Loss: 0.4250 Acc: 0.8867\n",
            "\n",
            "Epoch 4388/4999:\n",
            "train Loss: 0.4250 Acc: 0.8867\n",
            "\n",
            "Epoch 4389/4999:\n",
            "train Loss: 0.4250 Acc: 0.8867\n",
            "\n",
            "Epoch 4390/4999:\n",
            "train Loss: 0.4250 Acc: 0.8867\n",
            "\n",
            "Epoch 4391/4999:\n",
            "train Loss: 0.4249 Acc: 0.8867\n",
            "\n",
            "Epoch 4392/4999:\n",
            "train Loss: 0.4249 Acc: 0.8867\n",
            "\n",
            "Epoch 4393/4999:\n",
            "train Loss: 0.4249 Acc: 0.8867\n",
            "\n",
            "Epoch 4394/4999:\n",
            "train Loss: 0.4249 Acc: 0.8867\n",
            "\n",
            "Epoch 4395/4999:\n",
            "train Loss: 0.4248 Acc: 0.8867\n",
            "\n",
            "Epoch 4396/4999:\n",
            "train Loss: 0.4248 Acc: 0.8867\n",
            "\n",
            "Epoch 4397/4999:\n",
            "train Loss: 0.4248 Acc: 0.8867\n",
            "\n",
            "Epoch 4398/4999:\n",
            "train Loss: 0.4247 Acc: 0.8867\n",
            "\n",
            "Epoch 4399/4999:\n",
            "train Loss: 0.4247 Acc: 0.8867\n",
            "\n",
            "Epoch 4400/4999:\n",
            "train Loss: 0.4247 Acc: 0.8867\n",
            "\n",
            "Epoch 4401/4999:\n",
            "train Loss: 0.4247 Acc: 0.8867\n",
            "\n",
            "Epoch 4402/4999:\n",
            "train Loss: 0.4246 Acc: 0.8867\n",
            "\n",
            "Epoch 4403/4999:\n",
            "train Loss: 0.4246 Acc: 0.8867\n",
            "\n",
            "Epoch 4404/4999:\n",
            "train Loss: 0.4246 Acc: 0.8867\n",
            "\n",
            "Epoch 4405/4999:\n",
            "train Loss: 0.4246 Acc: 0.8867\n",
            "\n",
            "Epoch 4406/4999:\n",
            "train Loss: 0.4245 Acc: 0.8867\n",
            "\n",
            "Epoch 4407/4999:\n",
            "train Loss: 0.4245 Acc: 0.8867\n",
            "\n",
            "Epoch 4408/4999:\n",
            "train Loss: 0.4245 Acc: 0.8867\n",
            "\n",
            "Epoch 4409/4999:\n",
            "train Loss: 0.4244 Acc: 0.8867\n",
            "\n",
            "Epoch 4410/4999:\n",
            "train Loss: 0.4244 Acc: 0.8867\n",
            "\n",
            "Epoch 4411/4999:\n",
            "train Loss: 0.4244 Acc: 0.8867\n",
            "\n",
            "Epoch 4412/4999:\n",
            "train Loss: 0.4244 Acc: 0.8867\n",
            "\n",
            "Epoch 4413/4999:\n",
            "train Loss: 0.4243 Acc: 0.8867\n",
            "\n",
            "Epoch 4414/4999:\n",
            "train Loss: 0.4243 Acc: 0.8867\n",
            "\n",
            "Epoch 4415/4999:\n",
            "train Loss: 0.4243 Acc: 0.8867\n",
            "\n",
            "Epoch 4416/4999:\n",
            "train Loss: 0.4243 Acc: 0.8867\n",
            "\n",
            "Epoch 4417/4999:\n",
            "train Loss: 0.4242 Acc: 0.8867\n",
            "\n",
            "Epoch 4418/4999:\n",
            "train Loss: 0.4242 Acc: 0.8867\n",
            "\n",
            "Epoch 4419/4999:\n",
            "train Loss: 0.4242 Acc: 0.8867\n",
            "\n",
            "Epoch 4420/4999:\n",
            "train Loss: 0.4241 Acc: 0.8867\n",
            "\n",
            "Epoch 4421/4999:\n",
            "train Loss: 0.4241 Acc: 0.8867\n",
            "\n",
            "Epoch 4422/4999:\n",
            "train Loss: 0.4241 Acc: 0.8867\n",
            "\n",
            "Epoch 4423/4999:\n",
            "train Loss: 0.4241 Acc: 0.8867\n",
            "\n",
            "Epoch 4424/4999:\n",
            "train Loss: 0.4240 Acc: 0.8867\n",
            "\n",
            "Epoch 4425/4999:\n",
            "train Loss: 0.4240 Acc: 0.8867\n",
            "\n",
            "Epoch 4426/4999:\n",
            "train Loss: 0.4240 Acc: 0.8867\n",
            "\n",
            "Epoch 4427/4999:\n",
            "train Loss: 0.4240 Acc: 0.8867\n",
            "\n",
            "Epoch 4428/4999:\n",
            "train Loss: 0.4239 Acc: 0.8867\n",
            "\n",
            "Epoch 4429/4999:\n",
            "train Loss: 0.4239 Acc: 0.8867\n",
            "\n",
            "Epoch 4430/4999:\n",
            "train Loss: 0.4239 Acc: 0.8867\n",
            "\n",
            "Epoch 4431/4999:\n",
            "train Loss: 0.4238 Acc: 0.8867\n",
            "\n",
            "Epoch 4432/4999:\n",
            "train Loss: 0.4238 Acc: 0.8867\n",
            "\n",
            "Epoch 4433/4999:\n",
            "train Loss: 0.4238 Acc: 0.8867\n",
            "\n",
            "Epoch 4434/4999:\n",
            "train Loss: 0.4238 Acc: 0.8867\n",
            "\n",
            "Epoch 4435/4999:\n",
            "train Loss: 0.4237 Acc: 0.8867\n",
            "\n",
            "Epoch 4436/4999:\n",
            "train Loss: 0.4237 Acc: 0.8867\n",
            "\n",
            "Epoch 4437/4999:\n",
            "train Loss: 0.4237 Acc: 0.8867\n",
            "\n",
            "Epoch 4438/4999:\n",
            "train Loss: 0.4237 Acc: 0.8867\n",
            "\n",
            "Epoch 4439/4999:\n",
            "train Loss: 0.4236 Acc: 0.8867\n",
            "\n",
            "Epoch 4440/4999:\n",
            "train Loss: 0.4236 Acc: 0.8867\n",
            "\n",
            "Epoch 4441/4999:\n",
            "train Loss: 0.4236 Acc: 0.8867\n",
            "\n",
            "Epoch 4442/4999:\n",
            "train Loss: 0.4235 Acc: 0.8867\n",
            "\n",
            "Epoch 4443/4999:\n",
            "train Loss: 0.4235 Acc: 0.8867\n",
            "\n",
            "Epoch 4444/4999:\n",
            "train Loss: 0.4235 Acc: 0.8867\n",
            "\n",
            "Epoch 4445/4999:\n",
            "train Loss: 0.4235 Acc: 0.8867\n",
            "\n",
            "Epoch 4446/4999:\n",
            "train Loss: 0.4234 Acc: 0.8867\n",
            "\n",
            "Epoch 4447/4999:\n",
            "train Loss: 0.4234 Acc: 0.8867\n",
            "\n",
            "Epoch 4448/4999:\n",
            "train Loss: 0.4234 Acc: 0.8867\n",
            "\n",
            "Epoch 4449/4999:\n",
            "train Loss: 0.4234 Acc: 0.8867\n",
            "\n",
            "Epoch 4450/4999:\n",
            "train Loss: 0.4233 Acc: 0.8867\n",
            "\n",
            "Epoch 4451/4999:\n",
            "train Loss: 0.4233 Acc: 0.8867\n",
            "\n",
            "Epoch 4452/4999:\n",
            "train Loss: 0.4233 Acc: 0.8867\n",
            "\n",
            "Epoch 4453/4999:\n",
            "train Loss: 0.4232 Acc: 0.8867\n",
            "\n",
            "Epoch 4454/4999:\n",
            "train Loss: 0.4232 Acc: 0.8867\n",
            "\n",
            "Epoch 4455/4999:\n",
            "train Loss: 0.4232 Acc: 0.8867\n",
            "\n",
            "Epoch 4456/4999:\n",
            "train Loss: 0.4232 Acc: 0.8867\n",
            "\n",
            "Epoch 4457/4999:\n",
            "train Loss: 0.4231 Acc: 0.8867\n",
            "\n",
            "Epoch 4458/4999:\n",
            "train Loss: 0.4231 Acc: 0.8867\n",
            "\n",
            "Epoch 4459/4999:\n",
            "train Loss: 0.4231 Acc: 0.8867\n",
            "\n",
            "Epoch 4460/4999:\n",
            "train Loss: 0.4231 Acc: 0.8867\n",
            "\n",
            "Epoch 4461/4999:\n",
            "train Loss: 0.4230 Acc: 0.8867\n",
            "\n",
            "Epoch 4462/4999:\n",
            "train Loss: 0.4230 Acc: 0.8867\n",
            "\n",
            "Epoch 4463/4999:\n",
            "train Loss: 0.4230 Acc: 0.8867\n",
            "\n",
            "Epoch 4464/4999:\n",
            "train Loss: 0.4229 Acc: 0.8867\n",
            "\n",
            "Epoch 4465/4999:\n",
            "train Loss: 0.4229 Acc: 0.8867\n",
            "\n",
            "Epoch 4466/4999:\n",
            "train Loss: 0.4229 Acc: 0.8867\n",
            "\n",
            "Epoch 4467/4999:\n",
            "train Loss: 0.4229 Acc: 0.8867\n",
            "\n",
            "Epoch 4468/4999:\n",
            "train Loss: 0.4228 Acc: 0.8867\n",
            "\n",
            "Epoch 4469/4999:\n",
            "train Loss: 0.4228 Acc: 0.8867\n",
            "\n",
            "Epoch 4470/4999:\n",
            "train Loss: 0.4228 Acc: 0.8867\n",
            "\n",
            "Epoch 4471/4999:\n",
            "train Loss: 0.4228 Acc: 0.8867\n",
            "\n",
            "Epoch 4472/4999:\n",
            "train Loss: 0.4227 Acc: 0.8867\n",
            "\n",
            "Epoch 4473/4999:\n",
            "train Loss: 0.4227 Acc: 0.8867\n",
            "\n",
            "Epoch 4474/4999:\n",
            "train Loss: 0.4227 Acc: 0.8867\n",
            "\n",
            "Epoch 4475/4999:\n",
            "train Loss: 0.4226 Acc: 0.8867\n",
            "\n",
            "Epoch 4476/4999:\n",
            "train Loss: 0.4226 Acc: 0.8867\n",
            "\n",
            "Epoch 4477/4999:\n",
            "train Loss: 0.4226 Acc: 0.8867\n",
            "\n",
            "Epoch 4478/4999:\n",
            "train Loss: 0.4226 Acc: 0.8867\n",
            "\n",
            "Epoch 4479/4999:\n",
            "train Loss: 0.4225 Acc: 0.8867\n",
            "\n",
            "Epoch 4480/4999:\n",
            "train Loss: 0.4225 Acc: 0.8867\n",
            "\n",
            "Epoch 4481/4999:\n",
            "train Loss: 0.4225 Acc: 0.8867\n",
            "\n",
            "Epoch 4482/4999:\n",
            "train Loss: 0.4225 Acc: 0.8867\n",
            "\n",
            "Epoch 4483/4999:\n",
            "train Loss: 0.4224 Acc: 0.8867\n",
            "\n",
            "Epoch 4484/4999:\n",
            "train Loss: 0.4224 Acc: 0.8867\n",
            "\n",
            "Epoch 4485/4999:\n",
            "train Loss: 0.4224 Acc: 0.8867\n",
            "\n",
            "Epoch 4486/4999:\n",
            "train Loss: 0.4223 Acc: 0.8867\n",
            "\n",
            "Epoch 4487/4999:\n",
            "train Loss: 0.4223 Acc: 0.8867\n",
            "\n",
            "Epoch 4488/4999:\n",
            "train Loss: 0.4223 Acc: 0.8867\n",
            "\n",
            "Epoch 4489/4999:\n",
            "train Loss: 0.4223 Acc: 0.8867\n",
            "\n",
            "Epoch 4490/4999:\n",
            "train Loss: 0.4222 Acc: 0.8867\n",
            "\n",
            "Epoch 4491/4999:\n",
            "train Loss: 0.4222 Acc: 0.8867\n",
            "\n",
            "Epoch 4492/4999:\n",
            "train Loss: 0.4222 Acc: 0.8867\n",
            "\n",
            "Epoch 4493/4999:\n",
            "train Loss: 0.4222 Acc: 0.8867\n",
            "\n",
            "Epoch 4494/4999:\n",
            "train Loss: 0.4221 Acc: 0.8867\n",
            "\n",
            "Epoch 4495/4999:\n",
            "train Loss: 0.4221 Acc: 0.8867\n",
            "\n",
            "Epoch 4496/4999:\n",
            "train Loss: 0.4221 Acc: 0.8867\n",
            "\n",
            "Epoch 4497/4999:\n",
            "train Loss: 0.4220 Acc: 0.8867\n",
            "\n",
            "Epoch 4498/4999:\n",
            "train Loss: 0.4220 Acc: 0.8867\n",
            "\n",
            "Epoch 4499/4999:\n",
            "train Loss: 0.4220 Acc: 0.8867\n",
            "\n",
            "Epoch 4500/4999:\n",
            "train Loss: 0.4220 Acc: 0.8867\n",
            "\n",
            "Epoch 4501/4999:\n",
            "train Loss: 0.4219 Acc: 0.8867\n",
            "\n",
            "Epoch 4502/4999:\n",
            "train Loss: 0.4219 Acc: 0.8867\n",
            "\n",
            "Epoch 4503/4999:\n",
            "train Loss: 0.4219 Acc: 0.8867\n",
            "\n",
            "Epoch 4504/4999:\n",
            "train Loss: 0.4219 Acc: 0.8867\n",
            "\n",
            "Epoch 4505/4999:\n",
            "train Loss: 0.4218 Acc: 0.8867\n",
            "\n",
            "Epoch 4506/4999:\n",
            "train Loss: 0.4218 Acc: 0.8867\n",
            "\n",
            "Epoch 4507/4999:\n",
            "train Loss: 0.4218 Acc: 0.8867\n",
            "\n",
            "Epoch 4508/4999:\n",
            "train Loss: 0.4218 Acc: 0.8867\n",
            "\n",
            "Epoch 4509/4999:\n",
            "train Loss: 0.4217 Acc: 0.8867\n",
            "\n",
            "Epoch 4510/4999:\n",
            "train Loss: 0.4217 Acc: 0.8867\n",
            "\n",
            "Epoch 4511/4999:\n",
            "train Loss: 0.4217 Acc: 0.8867\n",
            "\n",
            "Epoch 4512/4999:\n",
            "train Loss: 0.4216 Acc: 0.8867\n",
            "\n",
            "Epoch 4513/4999:\n",
            "train Loss: 0.4216 Acc: 0.8867\n",
            "\n",
            "Epoch 4514/4999:\n",
            "train Loss: 0.4216 Acc: 0.8867\n",
            "\n",
            "Epoch 4515/4999:\n",
            "train Loss: 0.4216 Acc: 0.8867\n",
            "\n",
            "Epoch 4516/4999:\n",
            "train Loss: 0.4215 Acc: 0.8867\n",
            "\n",
            "Epoch 4517/4999:\n",
            "train Loss: 0.4215 Acc: 0.8867\n",
            "\n",
            "Epoch 4518/4999:\n",
            "train Loss: 0.4215 Acc: 0.8867\n",
            "\n",
            "Epoch 4519/4999:\n",
            "train Loss: 0.4215 Acc: 0.8867\n",
            "\n",
            "Epoch 4520/4999:\n",
            "train Loss: 0.4214 Acc: 0.8867\n",
            "\n",
            "Epoch 4521/4999:\n",
            "train Loss: 0.4214 Acc: 0.8867\n",
            "\n",
            "Epoch 4522/4999:\n",
            "train Loss: 0.4214 Acc: 0.8867\n",
            "\n",
            "Epoch 4523/4999:\n",
            "train Loss: 0.4213 Acc: 0.8867\n",
            "\n",
            "Epoch 4524/4999:\n",
            "train Loss: 0.4213 Acc: 0.8867\n",
            "\n",
            "Epoch 4525/4999:\n",
            "train Loss: 0.4213 Acc: 0.8867\n",
            "\n",
            "Epoch 4526/4999:\n",
            "train Loss: 0.4213 Acc: 0.8867\n",
            "\n",
            "Epoch 4527/4999:\n",
            "train Loss: 0.4212 Acc: 0.8867\n",
            "\n",
            "Epoch 4528/4999:\n",
            "train Loss: 0.4212 Acc: 0.8867\n",
            "\n",
            "Epoch 4529/4999:\n",
            "train Loss: 0.4212 Acc: 0.8867\n",
            "\n",
            "Epoch 4530/4999:\n",
            "train Loss: 0.4212 Acc: 0.8867\n",
            "\n",
            "Epoch 4531/4999:\n",
            "train Loss: 0.4211 Acc: 0.8867\n",
            "\n",
            "Epoch 4532/4999:\n",
            "train Loss: 0.4211 Acc: 0.8867\n",
            "\n",
            "Epoch 4533/4999:\n",
            "train Loss: 0.4211 Acc: 0.8867\n",
            "\n",
            "Epoch 4534/4999:\n",
            "train Loss: 0.4210 Acc: 0.8867\n",
            "\n",
            "Epoch 4535/4999:\n",
            "train Loss: 0.4210 Acc: 0.8867\n",
            "\n",
            "Epoch 4536/4999:\n",
            "train Loss: 0.4210 Acc: 0.8867\n",
            "\n",
            "Epoch 4537/4999:\n",
            "train Loss: 0.4210 Acc: 0.8867\n",
            "\n",
            "Epoch 4538/4999:\n",
            "train Loss: 0.4209 Acc: 0.8867\n",
            "\n",
            "Epoch 4539/4999:\n",
            "train Loss: 0.4209 Acc: 0.8867\n",
            "\n",
            "Epoch 4540/4999:\n",
            "train Loss: 0.4209 Acc: 0.8867\n",
            "\n",
            "Epoch 4541/4999:\n",
            "train Loss: 0.4209 Acc: 0.8867\n",
            "\n",
            "Epoch 4542/4999:\n",
            "train Loss: 0.4208 Acc: 0.8867\n",
            "\n",
            "Epoch 4543/4999:\n",
            "train Loss: 0.4208 Acc: 0.8867\n",
            "\n",
            "Epoch 4544/4999:\n",
            "train Loss: 0.4208 Acc: 0.8867\n",
            "\n",
            "Epoch 4545/4999:\n",
            "train Loss: 0.4208 Acc: 0.8867\n",
            "\n",
            "Epoch 4546/4999:\n",
            "train Loss: 0.4207 Acc: 0.8867\n",
            "\n",
            "Epoch 4547/4999:\n",
            "train Loss: 0.4207 Acc: 0.8867\n",
            "\n",
            "Epoch 4548/4999:\n",
            "train Loss: 0.4207 Acc: 0.8867\n",
            "\n",
            "Epoch 4549/4999:\n",
            "train Loss: 0.4206 Acc: 0.8867\n",
            "\n",
            "Epoch 4550/4999:\n",
            "train Loss: 0.4206 Acc: 0.8867\n",
            "\n",
            "Epoch 4551/4999:\n",
            "train Loss: 0.4206 Acc: 0.8867\n",
            "\n",
            "Epoch 4552/4999:\n",
            "train Loss: 0.4206 Acc: 0.8867\n",
            "\n",
            "Epoch 4553/4999:\n",
            "train Loss: 0.4205 Acc: 0.8867\n",
            "\n",
            "Epoch 4554/4999:\n",
            "train Loss: 0.4205 Acc: 0.8867\n",
            "\n",
            "Epoch 4555/4999:\n",
            "train Loss: 0.4205 Acc: 0.8867\n",
            "\n",
            "Epoch 4556/4999:\n",
            "train Loss: 0.4205 Acc: 0.8867\n",
            "\n",
            "Epoch 4557/4999:\n",
            "train Loss: 0.4204 Acc: 0.8867\n",
            "\n",
            "Epoch 4558/4999:\n",
            "train Loss: 0.4204 Acc: 0.8867\n",
            "\n",
            "Epoch 4559/4999:\n",
            "train Loss: 0.4204 Acc: 0.8867\n",
            "\n",
            "Epoch 4560/4999:\n",
            "train Loss: 0.4203 Acc: 0.8867\n",
            "\n",
            "Epoch 4561/4999:\n",
            "train Loss: 0.4203 Acc: 0.8867\n",
            "\n",
            "Epoch 4562/4999:\n",
            "train Loss: 0.4203 Acc: 0.8867\n",
            "\n",
            "Epoch 4563/4999:\n",
            "train Loss: 0.4203 Acc: 0.8867\n",
            "\n",
            "Epoch 4564/4999:\n",
            "train Loss: 0.4202 Acc: 0.8867\n",
            "\n",
            "Epoch 4565/4999:\n",
            "train Loss: 0.4202 Acc: 0.8867\n",
            "\n",
            "Epoch 4566/4999:\n",
            "train Loss: 0.4202 Acc: 0.8867\n",
            "\n",
            "Epoch 4567/4999:\n",
            "train Loss: 0.4202 Acc: 0.8867\n",
            "\n",
            "Epoch 4568/4999:\n",
            "train Loss: 0.4201 Acc: 0.8867\n",
            "\n",
            "Epoch 4569/4999:\n",
            "train Loss: 0.4201 Acc: 0.8867\n",
            "\n",
            "Epoch 4570/4999:\n",
            "train Loss: 0.4201 Acc: 0.8867\n",
            "\n",
            "Epoch 4571/4999:\n",
            "train Loss: 0.4201 Acc: 0.8867\n",
            "\n",
            "Epoch 4572/4999:\n",
            "train Loss: 0.4200 Acc: 0.8867\n",
            "\n",
            "Epoch 4573/4999:\n",
            "train Loss: 0.4200 Acc: 0.8867\n",
            "\n",
            "Epoch 4574/4999:\n",
            "train Loss: 0.4200 Acc: 0.8867\n",
            "\n",
            "Epoch 4575/4999:\n",
            "train Loss: 0.4199 Acc: 0.8867\n",
            "\n",
            "Epoch 4576/4999:\n",
            "train Loss: 0.4199 Acc: 0.8867\n",
            "\n",
            "Epoch 4577/4999:\n",
            "train Loss: 0.4199 Acc: 0.8867\n",
            "\n",
            "Epoch 4578/4999:\n",
            "train Loss: 0.4199 Acc: 0.8867\n",
            "\n",
            "Epoch 4579/4999:\n",
            "train Loss: 0.4198 Acc: 0.8867\n",
            "\n",
            "Epoch 4580/4999:\n",
            "train Loss: 0.4198 Acc: 0.8867\n",
            "\n",
            "Epoch 4581/4999:\n",
            "train Loss: 0.4198 Acc: 0.8867\n",
            "\n",
            "Epoch 4582/4999:\n",
            "train Loss: 0.4198 Acc: 0.8867\n",
            "\n",
            "Epoch 4583/4999:\n",
            "train Loss: 0.4197 Acc: 0.8867\n",
            "\n",
            "Epoch 4584/4999:\n",
            "train Loss: 0.4197 Acc: 0.8867\n",
            "\n",
            "Epoch 4585/4999:\n",
            "train Loss: 0.4197 Acc: 0.8867\n",
            "\n",
            "Epoch 4586/4999:\n",
            "train Loss: 0.4196 Acc: 0.8867\n",
            "\n",
            "Epoch 4587/4999:\n",
            "train Loss: 0.4196 Acc: 0.8867\n",
            "\n",
            "Epoch 4588/4999:\n",
            "train Loss: 0.4196 Acc: 0.8867\n",
            "\n",
            "Epoch 4589/4999:\n",
            "train Loss: 0.4196 Acc: 0.8867\n",
            "\n",
            "Epoch 4590/4999:\n",
            "train Loss: 0.4195 Acc: 0.8867\n",
            "\n",
            "Epoch 4591/4999:\n",
            "train Loss: 0.4195 Acc: 0.8867\n",
            "\n",
            "Epoch 4592/4999:\n",
            "train Loss: 0.4195 Acc: 0.8867\n",
            "\n",
            "Epoch 4593/4999:\n",
            "train Loss: 0.4195 Acc: 0.8867\n",
            "\n",
            "Epoch 4594/4999:\n",
            "train Loss: 0.4194 Acc: 0.8867\n",
            "\n",
            "Epoch 4595/4999:\n",
            "train Loss: 0.4194 Acc: 0.8867\n",
            "\n",
            "Epoch 4596/4999:\n",
            "train Loss: 0.4194 Acc: 0.8867\n",
            "\n",
            "Epoch 4597/4999:\n",
            "train Loss: 0.4194 Acc: 0.8867\n",
            "\n",
            "Epoch 4598/4999:\n",
            "train Loss: 0.4193 Acc: 0.8867\n",
            "\n",
            "Epoch 4599/4999:\n",
            "train Loss: 0.4193 Acc: 0.8867\n",
            "\n",
            "Epoch 4600/4999:\n",
            "train Loss: 0.4193 Acc: 0.8867\n",
            "\n",
            "Epoch 4601/4999:\n",
            "train Loss: 0.4192 Acc: 0.8867\n",
            "\n",
            "Epoch 4602/4999:\n",
            "train Loss: 0.4192 Acc: 0.8867\n",
            "\n",
            "Epoch 4603/4999:\n",
            "train Loss: 0.4192 Acc: 0.8867\n",
            "\n",
            "Epoch 4604/4999:\n",
            "train Loss: 0.4192 Acc: 0.8867\n",
            "\n",
            "Epoch 4605/4999:\n",
            "train Loss: 0.4191 Acc: 0.8867\n",
            "\n",
            "Epoch 4606/4999:\n",
            "train Loss: 0.4191 Acc: 0.8867\n",
            "\n",
            "Epoch 4607/4999:\n",
            "train Loss: 0.4191 Acc: 0.8867\n",
            "\n",
            "Epoch 4608/4999:\n",
            "train Loss: 0.4191 Acc: 0.8867\n",
            "\n",
            "Epoch 4609/4999:\n",
            "train Loss: 0.4190 Acc: 0.8867\n",
            "\n",
            "Epoch 4610/4999:\n",
            "train Loss: 0.4190 Acc: 0.8867\n",
            "\n",
            "Epoch 4611/4999:\n",
            "train Loss: 0.4190 Acc: 0.8867\n",
            "\n",
            "Epoch 4612/4999:\n",
            "train Loss: 0.4189 Acc: 0.8867\n",
            "\n",
            "Epoch 4613/4999:\n",
            "train Loss: 0.4189 Acc: 0.8867\n",
            "\n",
            "Epoch 4614/4999:\n",
            "train Loss: 0.4189 Acc: 0.8867\n",
            "\n",
            "Epoch 4615/4999:\n",
            "train Loss: 0.4189 Acc: 0.8867\n",
            "\n",
            "Epoch 4616/4999:\n",
            "train Loss: 0.4188 Acc: 0.8867\n",
            "\n",
            "Epoch 4617/4999:\n",
            "train Loss: 0.4188 Acc: 0.8867\n",
            "\n",
            "Epoch 4618/4999:\n",
            "train Loss: 0.4188 Acc: 0.8867\n",
            "\n",
            "Epoch 4619/4999:\n",
            "train Loss: 0.4188 Acc: 0.8867\n",
            "\n",
            "Epoch 4620/4999:\n",
            "train Loss: 0.4187 Acc: 0.8867\n",
            "\n",
            "Epoch 4621/4999:\n",
            "train Loss: 0.4187 Acc: 0.8867\n",
            "\n",
            "Epoch 4622/4999:\n",
            "train Loss: 0.4187 Acc: 0.8867\n",
            "\n",
            "Epoch 4623/4999:\n",
            "train Loss: 0.4187 Acc: 0.8867\n",
            "\n",
            "Epoch 4624/4999:\n",
            "train Loss: 0.4186 Acc: 0.8867\n",
            "\n",
            "Epoch 4625/4999:\n",
            "train Loss: 0.4186 Acc: 0.8867\n",
            "\n",
            "Epoch 4626/4999:\n",
            "train Loss: 0.4186 Acc: 0.8867\n",
            "\n",
            "Epoch 4627/4999:\n",
            "train Loss: 0.4185 Acc: 0.8867\n",
            "\n",
            "Epoch 4628/4999:\n",
            "train Loss: 0.4185 Acc: 0.8867\n",
            "\n",
            "Epoch 4629/4999:\n",
            "train Loss: 0.4185 Acc: 0.8867\n",
            "\n",
            "Epoch 4630/4999:\n",
            "train Loss: 0.4185 Acc: 0.8867\n",
            "\n",
            "Epoch 4631/4999:\n",
            "train Loss: 0.4184 Acc: 0.8867\n",
            "\n",
            "Epoch 4632/4999:\n",
            "train Loss: 0.4184 Acc: 0.8867\n",
            "\n",
            "Epoch 4633/4999:\n",
            "train Loss: 0.4184 Acc: 0.8867\n",
            "\n",
            "Epoch 4634/4999:\n",
            "train Loss: 0.4184 Acc: 0.8867\n",
            "\n",
            "Epoch 4635/4999:\n",
            "train Loss: 0.4183 Acc: 0.8867\n",
            "\n",
            "Epoch 4636/4999:\n",
            "train Loss: 0.4183 Acc: 0.8867\n",
            "\n",
            "Epoch 4637/4999:\n",
            "train Loss: 0.4183 Acc: 0.8867\n",
            "\n",
            "Epoch 4638/4999:\n",
            "train Loss: 0.4183 Acc: 0.8867\n",
            "\n",
            "Epoch 4639/4999:\n",
            "train Loss: 0.4182 Acc: 0.8867\n",
            "\n",
            "Epoch 4640/4999:\n",
            "train Loss: 0.4182 Acc: 0.8867\n",
            "\n",
            "Epoch 4641/4999:\n",
            "train Loss: 0.4182 Acc: 0.8867\n",
            "\n",
            "Epoch 4642/4999:\n",
            "train Loss: 0.4181 Acc: 0.8867\n",
            "\n",
            "Epoch 4643/4999:\n",
            "train Loss: 0.4181 Acc: 0.8867\n",
            "\n",
            "Epoch 4644/4999:\n",
            "train Loss: 0.4181 Acc: 0.8867\n",
            "\n",
            "Epoch 4645/4999:\n",
            "train Loss: 0.4181 Acc: 0.8867\n",
            "\n",
            "Epoch 4646/4999:\n",
            "train Loss: 0.4180 Acc: 0.8867\n",
            "\n",
            "Epoch 4647/4999:\n",
            "train Loss: 0.4180 Acc: 0.8867\n",
            "\n",
            "Epoch 4648/4999:\n",
            "train Loss: 0.4180 Acc: 0.8867\n",
            "\n",
            "Epoch 4649/4999:\n",
            "train Loss: 0.4180 Acc: 0.8867\n",
            "\n",
            "Epoch 4650/4999:\n",
            "train Loss: 0.4179 Acc: 0.8867\n",
            "\n",
            "Epoch 4651/4999:\n",
            "train Loss: 0.4179 Acc: 0.8867\n",
            "\n",
            "Epoch 4652/4999:\n",
            "train Loss: 0.4179 Acc: 0.8867\n",
            "\n",
            "Epoch 4653/4999:\n",
            "train Loss: 0.4178 Acc: 0.8867\n",
            "\n",
            "Epoch 4654/4999:\n",
            "train Loss: 0.4178 Acc: 0.8867\n",
            "\n",
            "Epoch 4655/4999:\n",
            "train Loss: 0.4178 Acc: 0.8867\n",
            "\n",
            "Epoch 4656/4999:\n",
            "train Loss: 0.4178 Acc: 0.8867\n",
            "\n",
            "Epoch 4657/4999:\n",
            "train Loss: 0.4177 Acc: 0.8867\n",
            "\n",
            "Epoch 4658/4999:\n",
            "train Loss: 0.4177 Acc: 0.8867\n",
            "\n",
            "Epoch 4659/4999:\n",
            "train Loss: 0.4177 Acc: 0.8867\n",
            "\n",
            "Epoch 4660/4999:\n",
            "train Loss: 0.4177 Acc: 0.8867\n",
            "\n",
            "Epoch 4661/4999:\n",
            "train Loss: 0.4176 Acc: 0.8867\n",
            "\n",
            "Epoch 4662/4999:\n",
            "train Loss: 0.4176 Acc: 0.8867\n",
            "\n",
            "Epoch 4663/4999:\n",
            "train Loss: 0.4176 Acc: 0.8867\n",
            "\n",
            "Epoch 4664/4999:\n",
            "train Loss: 0.4176 Acc: 0.8867\n",
            "\n",
            "Epoch 4665/4999:\n",
            "train Loss: 0.4175 Acc: 0.8867\n",
            "\n",
            "Epoch 4666/4999:\n",
            "train Loss: 0.4175 Acc: 0.8867\n",
            "\n",
            "Epoch 4667/4999:\n",
            "train Loss: 0.4175 Acc: 0.8867\n",
            "\n",
            "Epoch 4668/4999:\n",
            "train Loss: 0.4174 Acc: 0.8867\n",
            "\n",
            "Epoch 4669/4999:\n",
            "train Loss: 0.4174 Acc: 0.8867\n",
            "\n",
            "Epoch 4670/4999:\n",
            "train Loss: 0.4174 Acc: 0.8867\n",
            "\n",
            "Epoch 4671/4999:\n",
            "train Loss: 0.4174 Acc: 0.8867\n",
            "\n",
            "Epoch 4672/4999:\n",
            "train Loss: 0.4173 Acc: 0.8867\n",
            "\n",
            "Epoch 4673/4999:\n",
            "train Loss: 0.4173 Acc: 0.8867\n",
            "\n",
            "Epoch 4674/4999:\n",
            "train Loss: 0.4173 Acc: 0.8867\n",
            "\n",
            "Epoch 4675/4999:\n",
            "train Loss: 0.4173 Acc: 0.8867\n",
            "\n",
            "Epoch 4676/4999:\n",
            "train Loss: 0.4172 Acc: 0.8867\n",
            "\n",
            "Epoch 4677/4999:\n",
            "train Loss: 0.4172 Acc: 0.8867\n",
            "\n",
            "Epoch 4678/4999:\n",
            "train Loss: 0.4172 Acc: 0.8867\n",
            "\n",
            "Epoch 4679/4999:\n",
            "train Loss: 0.4172 Acc: 0.8867\n",
            "\n",
            "Epoch 4680/4999:\n",
            "train Loss: 0.4171 Acc: 0.8867\n",
            "\n",
            "Epoch 4681/4999:\n",
            "train Loss: 0.4171 Acc: 0.8867\n",
            "\n",
            "Epoch 4682/4999:\n",
            "train Loss: 0.4171 Acc: 0.8867\n",
            "\n",
            "Epoch 4683/4999:\n",
            "train Loss: 0.4170 Acc: 0.8867\n",
            "\n",
            "Epoch 4684/4999:\n",
            "train Loss: 0.4170 Acc: 0.8867\n",
            "\n",
            "Epoch 4685/4999:\n",
            "train Loss: 0.4170 Acc: 0.8867\n",
            "\n",
            "Epoch 4686/4999:\n",
            "train Loss: 0.4170 Acc: 0.8867\n",
            "\n",
            "Epoch 4687/4999:\n",
            "train Loss: 0.4169 Acc: 0.8867\n",
            "\n",
            "Epoch 4688/4999:\n",
            "train Loss: 0.4169 Acc: 0.8867\n",
            "\n",
            "Epoch 4689/4999:\n",
            "train Loss: 0.4169 Acc: 0.8867\n",
            "\n",
            "Epoch 4690/4999:\n",
            "train Loss: 0.4169 Acc: 0.8867\n",
            "\n",
            "Epoch 4691/4999:\n",
            "train Loss: 0.4168 Acc: 0.8867\n",
            "\n",
            "Epoch 4692/4999:\n",
            "train Loss: 0.4168 Acc: 0.8867\n",
            "\n",
            "Epoch 4693/4999:\n",
            "train Loss: 0.4168 Acc: 0.8867\n",
            "\n",
            "Epoch 4694/4999:\n",
            "train Loss: 0.4168 Acc: 0.8867\n",
            "\n",
            "Epoch 4695/4999:\n",
            "train Loss: 0.4167 Acc: 0.8867\n",
            "\n",
            "Epoch 4696/4999:\n",
            "train Loss: 0.4167 Acc: 0.8867\n",
            "\n",
            "Epoch 4697/4999:\n",
            "train Loss: 0.4167 Acc: 0.8867\n",
            "\n",
            "Epoch 4698/4999:\n",
            "train Loss: 0.4166 Acc: 0.8867\n",
            "\n",
            "Epoch 4699/4999:\n",
            "train Loss: 0.4166 Acc: 0.8867\n",
            "\n",
            "Epoch 4700/4999:\n",
            "train Loss: 0.4166 Acc: 0.8867\n",
            "\n",
            "Epoch 4701/4999:\n",
            "train Loss: 0.4166 Acc: 0.8867\n",
            "\n",
            "Epoch 4702/4999:\n",
            "train Loss: 0.4165 Acc: 0.8867\n",
            "\n",
            "Epoch 4703/4999:\n",
            "train Loss: 0.4165 Acc: 0.8867\n",
            "\n",
            "Epoch 4704/4999:\n",
            "train Loss: 0.4165 Acc: 0.8867\n",
            "\n",
            "Epoch 4705/4999:\n",
            "train Loss: 0.4165 Acc: 0.8867\n",
            "\n",
            "Epoch 4706/4999:\n",
            "train Loss: 0.4164 Acc: 0.8867\n",
            "\n",
            "Epoch 4707/4999:\n",
            "train Loss: 0.4164 Acc: 0.8867\n",
            "\n",
            "Epoch 4708/4999:\n",
            "train Loss: 0.4164 Acc: 0.8867\n",
            "\n",
            "Epoch 4709/4999:\n",
            "train Loss: 0.4164 Acc: 0.8867\n",
            "\n",
            "Epoch 4710/4999:\n",
            "train Loss: 0.4163 Acc: 0.8867\n",
            "\n",
            "Epoch 4711/4999:\n",
            "train Loss: 0.4163 Acc: 0.8867\n",
            "\n",
            "Epoch 4712/4999:\n",
            "train Loss: 0.4163 Acc: 0.8867\n",
            "\n",
            "Epoch 4713/4999:\n",
            "train Loss: 0.4162 Acc: 0.8867\n",
            "\n",
            "Epoch 4714/4999:\n",
            "train Loss: 0.4162 Acc: 0.8867\n",
            "\n",
            "Epoch 4715/4999:\n",
            "train Loss: 0.4162 Acc: 0.8867\n",
            "\n",
            "Epoch 4716/4999:\n",
            "train Loss: 0.4162 Acc: 0.8867\n",
            "\n",
            "Epoch 4717/4999:\n",
            "train Loss: 0.4161 Acc: 0.8867\n",
            "\n",
            "Epoch 4718/4999:\n",
            "train Loss: 0.4161 Acc: 0.8867\n",
            "\n",
            "Epoch 4719/4999:\n",
            "train Loss: 0.4161 Acc: 0.8867\n",
            "\n",
            "Epoch 4720/4999:\n",
            "train Loss: 0.4161 Acc: 0.8867\n",
            "\n",
            "Epoch 4721/4999:\n",
            "train Loss: 0.4160 Acc: 0.8867\n",
            "\n",
            "Epoch 4722/4999:\n",
            "train Loss: 0.4160 Acc: 0.8867\n",
            "\n",
            "Epoch 4723/4999:\n",
            "train Loss: 0.4160 Acc: 0.8867\n",
            "\n",
            "Epoch 4724/4999:\n",
            "train Loss: 0.4160 Acc: 0.8867\n",
            "\n",
            "Epoch 4725/4999:\n",
            "train Loss: 0.4159 Acc: 0.8867\n",
            "\n",
            "Epoch 4726/4999:\n",
            "train Loss: 0.4159 Acc: 0.8867\n",
            "\n",
            "Epoch 4727/4999:\n",
            "train Loss: 0.4159 Acc: 0.8867\n",
            "\n",
            "Epoch 4728/4999:\n",
            "train Loss: 0.4159 Acc: 0.8867\n",
            "\n",
            "Epoch 4729/4999:\n",
            "train Loss: 0.4158 Acc: 0.8867\n",
            "\n",
            "Epoch 4730/4999:\n",
            "train Loss: 0.4158 Acc: 0.8867\n",
            "\n",
            "Epoch 4731/4999:\n",
            "train Loss: 0.4158 Acc: 0.8867\n",
            "\n",
            "Epoch 4732/4999:\n",
            "train Loss: 0.4157 Acc: 0.8867\n",
            "\n",
            "Epoch 4733/4999:\n",
            "train Loss: 0.4157 Acc: 0.8867\n",
            "\n",
            "Epoch 4734/4999:\n",
            "train Loss: 0.4157 Acc: 0.8867\n",
            "\n",
            "Epoch 4735/4999:\n",
            "train Loss: 0.4157 Acc: 0.8867\n",
            "\n",
            "Epoch 4736/4999:\n",
            "train Loss: 0.4156 Acc: 0.8867\n",
            "\n",
            "Epoch 4737/4999:\n",
            "train Loss: 0.4156 Acc: 0.8867\n",
            "\n",
            "Epoch 4738/4999:\n",
            "train Loss: 0.4156 Acc: 0.8867\n",
            "\n",
            "Epoch 4739/4999:\n",
            "train Loss: 0.4156 Acc: 0.8867\n",
            "\n",
            "Epoch 4740/4999:\n",
            "train Loss: 0.4155 Acc: 0.8867\n",
            "\n",
            "Epoch 4741/4999:\n",
            "train Loss: 0.4155 Acc: 0.8867\n",
            "\n",
            "Epoch 4742/4999:\n",
            "train Loss: 0.4155 Acc: 0.8867\n",
            "\n",
            "Epoch 4743/4999:\n",
            "train Loss: 0.4155 Acc: 0.8867\n",
            "\n",
            "Epoch 4744/4999:\n",
            "train Loss: 0.4154 Acc: 0.8867\n",
            "\n",
            "Epoch 4745/4999:\n",
            "train Loss: 0.4154 Acc: 0.8867\n",
            "\n",
            "Epoch 4746/4999:\n",
            "train Loss: 0.4154 Acc: 0.8867\n",
            "\n",
            "Epoch 4747/4999:\n",
            "train Loss: 0.4153 Acc: 0.8867\n",
            "\n",
            "Epoch 4748/4999:\n",
            "train Loss: 0.4153 Acc: 0.8867\n",
            "\n",
            "Epoch 4749/4999:\n",
            "train Loss: 0.4153 Acc: 0.8867\n",
            "\n",
            "Epoch 4750/4999:\n",
            "train Loss: 0.4153 Acc: 0.8867\n",
            "\n",
            "Epoch 4751/4999:\n",
            "train Loss: 0.4152 Acc: 0.8867\n",
            "\n",
            "Epoch 4752/4999:\n",
            "train Loss: 0.4152 Acc: 0.8867\n",
            "\n",
            "Epoch 4753/4999:\n",
            "train Loss: 0.4152 Acc: 0.8867\n",
            "\n",
            "Epoch 4754/4999:\n",
            "train Loss: 0.4152 Acc: 0.8867\n",
            "\n",
            "Epoch 4755/4999:\n",
            "train Loss: 0.4151 Acc: 0.8867\n",
            "\n",
            "Epoch 4756/4999:\n",
            "train Loss: 0.4151 Acc: 0.8867\n",
            "\n",
            "Epoch 4757/4999:\n",
            "train Loss: 0.4151 Acc: 0.8867\n",
            "\n",
            "Epoch 4758/4999:\n",
            "train Loss: 0.4151 Acc: 0.8867\n",
            "\n",
            "Epoch 4759/4999:\n",
            "train Loss: 0.4150 Acc: 0.8867\n",
            "\n",
            "Epoch 4760/4999:\n",
            "train Loss: 0.4150 Acc: 0.8867\n",
            "\n",
            "Epoch 4761/4999:\n",
            "train Loss: 0.4150 Acc: 0.8867\n",
            "\n",
            "Epoch 4762/4999:\n",
            "train Loss: 0.4149 Acc: 0.8867\n",
            "\n",
            "Epoch 4763/4999:\n",
            "train Loss: 0.4149 Acc: 0.8867\n",
            "\n",
            "Epoch 4764/4999:\n",
            "train Loss: 0.4149 Acc: 0.8867\n",
            "\n",
            "Epoch 4765/4999:\n",
            "train Loss: 0.4149 Acc: 0.8867\n",
            "\n",
            "Epoch 4766/4999:\n",
            "train Loss: 0.4148 Acc: 0.8867\n",
            "\n",
            "Epoch 4767/4999:\n",
            "train Loss: 0.4148 Acc: 0.8867\n",
            "\n",
            "Epoch 4768/4999:\n",
            "train Loss: 0.4148 Acc: 0.8867\n",
            "\n",
            "Epoch 4769/4999:\n",
            "train Loss: 0.4148 Acc: 0.8867\n",
            "\n",
            "Epoch 4770/4999:\n",
            "train Loss: 0.4147 Acc: 0.8867\n",
            "\n",
            "Epoch 4771/4999:\n",
            "train Loss: 0.4147 Acc: 0.8867\n",
            "\n",
            "Epoch 4772/4999:\n",
            "train Loss: 0.4147 Acc: 0.8867\n",
            "\n",
            "Epoch 4773/4999:\n",
            "train Loss: 0.4147 Acc: 0.8867\n",
            "\n",
            "Epoch 4774/4999:\n",
            "train Loss: 0.4146 Acc: 0.8867\n",
            "\n",
            "Epoch 4775/4999:\n",
            "train Loss: 0.4146 Acc: 0.8867\n",
            "\n",
            "Epoch 4776/4999:\n",
            "train Loss: 0.4146 Acc: 0.8867\n",
            "\n",
            "Epoch 4777/4999:\n",
            "train Loss: 0.4146 Acc: 0.8867\n",
            "\n",
            "Epoch 4778/4999:\n",
            "train Loss: 0.4145 Acc: 0.8867\n",
            "\n",
            "Epoch 4779/4999:\n",
            "train Loss: 0.4145 Acc: 0.8867\n",
            "\n",
            "Epoch 4780/4999:\n",
            "train Loss: 0.4145 Acc: 0.8867\n",
            "\n",
            "Epoch 4781/4999:\n",
            "train Loss: 0.4144 Acc: 0.8867\n",
            "\n",
            "Epoch 4782/4999:\n",
            "train Loss: 0.4144 Acc: 0.8867\n",
            "\n",
            "Epoch 4783/4999:\n",
            "train Loss: 0.4144 Acc: 0.8867\n",
            "\n",
            "Epoch 4784/4999:\n",
            "train Loss: 0.4144 Acc: 0.8867\n",
            "\n",
            "Epoch 4785/4999:\n",
            "train Loss: 0.4143 Acc: 0.8867\n",
            "\n",
            "Epoch 4786/4999:\n",
            "train Loss: 0.4143 Acc: 0.8867\n",
            "\n",
            "Epoch 4787/4999:\n",
            "train Loss: 0.4143 Acc: 0.8867\n",
            "\n",
            "Epoch 4788/4999:\n",
            "train Loss: 0.4143 Acc: 0.8867\n",
            "\n",
            "Epoch 4789/4999:\n",
            "train Loss: 0.4142 Acc: 0.8867\n",
            "\n",
            "Epoch 4790/4999:\n",
            "train Loss: 0.4142 Acc: 0.8867\n",
            "\n",
            "Epoch 4791/4999:\n",
            "train Loss: 0.4142 Acc: 0.8867\n",
            "\n",
            "Epoch 4792/4999:\n",
            "train Loss: 0.4142 Acc: 0.8867\n",
            "\n",
            "Epoch 4793/4999:\n",
            "train Loss: 0.4141 Acc: 0.8867\n",
            "\n",
            "Epoch 4794/4999:\n",
            "train Loss: 0.4141 Acc: 0.8867\n",
            "\n",
            "Epoch 4795/4999:\n",
            "train Loss: 0.4141 Acc: 0.8867\n",
            "\n",
            "Epoch 4796/4999:\n",
            "train Loss: 0.4140 Acc: 0.8867\n",
            "\n",
            "Epoch 4797/4999:\n",
            "train Loss: 0.4140 Acc: 0.8867\n",
            "\n",
            "Epoch 4798/4999:\n",
            "train Loss: 0.4140 Acc: 0.8867\n",
            "\n",
            "Epoch 4799/4999:\n",
            "train Loss: 0.4140 Acc: 0.8867\n",
            "\n",
            "Epoch 4800/4999:\n",
            "train Loss: 0.4139 Acc: 0.8867\n",
            "\n",
            "Epoch 4801/4999:\n",
            "train Loss: 0.4139 Acc: 0.8867\n",
            "\n",
            "Epoch 4802/4999:\n",
            "train Loss: 0.4139 Acc: 0.8867\n",
            "\n",
            "Epoch 4803/4999:\n",
            "train Loss: 0.4139 Acc: 0.8867\n",
            "\n",
            "Epoch 4804/4999:\n",
            "train Loss: 0.4138 Acc: 0.8867\n",
            "\n",
            "Epoch 4805/4999:\n",
            "train Loss: 0.4138 Acc: 0.8867\n",
            "\n",
            "Epoch 4806/4999:\n",
            "train Loss: 0.4138 Acc: 0.8867\n",
            "\n",
            "Epoch 4807/4999:\n",
            "train Loss: 0.4138 Acc: 0.8867\n",
            "\n",
            "Epoch 4808/4999:\n",
            "train Loss: 0.4137 Acc: 0.8867\n",
            "\n",
            "Epoch 4809/4999:\n",
            "train Loss: 0.4137 Acc: 0.8867\n",
            "\n",
            "Epoch 4810/4999:\n",
            "train Loss: 0.4137 Acc: 0.8867\n",
            "\n",
            "Epoch 4811/4999:\n",
            "train Loss: 0.4137 Acc: 0.8867\n",
            "\n",
            "Epoch 4812/4999:\n",
            "train Loss: 0.4136 Acc: 0.8867\n",
            "\n",
            "Epoch 4813/4999:\n",
            "train Loss: 0.4136 Acc: 0.8867\n",
            "\n",
            "Epoch 4814/4999:\n",
            "train Loss: 0.4136 Acc: 0.8867\n",
            "\n",
            "Epoch 4815/4999:\n",
            "train Loss: 0.4135 Acc: 0.8867\n",
            "\n",
            "Epoch 4816/4999:\n",
            "train Loss: 0.4135 Acc: 0.8867\n",
            "\n",
            "Epoch 4817/4999:\n",
            "train Loss: 0.4135 Acc: 0.8867\n",
            "\n",
            "Epoch 4818/4999:\n",
            "train Loss: 0.4135 Acc: 0.8867\n",
            "\n",
            "Epoch 4819/4999:\n",
            "train Loss: 0.4134 Acc: 0.8867\n",
            "\n",
            "Epoch 4820/4999:\n",
            "train Loss: 0.4134 Acc: 0.8867\n",
            "\n",
            "Epoch 4821/4999:\n",
            "train Loss: 0.4134 Acc: 0.8867\n",
            "\n",
            "Epoch 4822/4999:\n",
            "train Loss: 0.4134 Acc: 0.8867\n",
            "\n",
            "Epoch 4823/4999:\n",
            "train Loss: 0.4133 Acc: 0.8867\n",
            "\n",
            "Epoch 4824/4999:\n",
            "train Loss: 0.4133 Acc: 0.8867\n",
            "\n",
            "Epoch 4825/4999:\n",
            "train Loss: 0.4133 Acc: 0.8867\n",
            "\n",
            "Epoch 4826/4999:\n",
            "train Loss: 0.4133 Acc: 0.8867\n",
            "\n",
            "Epoch 4827/4999:\n",
            "train Loss: 0.4132 Acc: 0.8867\n",
            "\n",
            "Epoch 4828/4999:\n",
            "train Loss: 0.4132 Acc: 0.8867\n",
            "\n",
            "Epoch 4829/4999:\n",
            "train Loss: 0.4132 Acc: 0.8867\n",
            "\n",
            "Epoch 4830/4999:\n",
            "train Loss: 0.4132 Acc: 0.8867\n",
            "\n",
            "Epoch 4831/4999:\n",
            "train Loss: 0.4131 Acc: 0.8867\n",
            "\n",
            "Epoch 4832/4999:\n",
            "train Loss: 0.4131 Acc: 0.8867\n",
            "\n",
            "Epoch 4833/4999:\n",
            "train Loss: 0.4131 Acc: 0.8867\n",
            "\n",
            "Epoch 4834/4999:\n",
            "train Loss: 0.4130 Acc: 0.8867\n",
            "\n",
            "Epoch 4835/4999:\n",
            "train Loss: 0.4130 Acc: 0.8867\n",
            "\n",
            "Epoch 4836/4999:\n",
            "train Loss: 0.4130 Acc: 0.8867\n",
            "\n",
            "Epoch 4837/4999:\n",
            "train Loss: 0.4130 Acc: 0.8867\n",
            "\n",
            "Epoch 4838/4999:\n",
            "train Loss: 0.4129 Acc: 0.8867\n",
            "\n",
            "Epoch 4839/4999:\n",
            "train Loss: 0.4129 Acc: 0.8867\n",
            "\n",
            "Epoch 4840/4999:\n",
            "train Loss: 0.4129 Acc: 0.8867\n",
            "\n",
            "Epoch 4841/4999:\n",
            "train Loss: 0.4129 Acc: 0.8867\n",
            "\n",
            "Epoch 4842/4999:\n",
            "train Loss: 0.4128 Acc: 0.8867\n",
            "\n",
            "Epoch 4843/4999:\n",
            "train Loss: 0.4128 Acc: 0.8867\n",
            "\n",
            "Epoch 4844/4999:\n",
            "train Loss: 0.4128 Acc: 0.8867\n",
            "\n",
            "Epoch 4845/4999:\n",
            "train Loss: 0.4128 Acc: 0.8867\n",
            "\n",
            "Epoch 4846/4999:\n",
            "train Loss: 0.4127 Acc: 0.8867\n",
            "\n",
            "Epoch 4847/4999:\n",
            "train Loss: 0.4127 Acc: 0.8867\n",
            "\n",
            "Epoch 4848/4999:\n",
            "train Loss: 0.4127 Acc: 0.8867\n",
            "\n",
            "Epoch 4849/4999:\n",
            "train Loss: 0.4127 Acc: 0.8867\n",
            "\n",
            "Epoch 4850/4999:\n",
            "train Loss: 0.4126 Acc: 0.8867\n",
            "\n",
            "Epoch 4851/4999:\n",
            "train Loss: 0.4126 Acc: 0.8867\n",
            "\n",
            "Epoch 4852/4999:\n",
            "train Loss: 0.4126 Acc: 0.8867\n",
            "\n",
            "Epoch 4853/4999:\n",
            "train Loss: 0.4125 Acc: 0.8867\n",
            "\n",
            "Epoch 4854/4999:\n",
            "train Loss: 0.4125 Acc: 0.8867\n",
            "\n",
            "Epoch 4855/4999:\n",
            "train Loss: 0.4125 Acc: 0.8867\n",
            "\n",
            "Epoch 4856/4999:\n",
            "train Loss: 0.4125 Acc: 0.8867\n",
            "\n",
            "Epoch 4857/4999:\n",
            "train Loss: 0.4124 Acc: 0.8867\n",
            "\n",
            "Epoch 4858/4999:\n",
            "train Loss: 0.4124 Acc: 0.8867\n",
            "\n",
            "Epoch 4859/4999:\n",
            "train Loss: 0.4124 Acc: 0.8867\n",
            "\n",
            "Epoch 4860/4999:\n",
            "train Loss: 0.4124 Acc: 0.8867\n",
            "\n",
            "Epoch 4861/4999:\n",
            "train Loss: 0.4123 Acc: 0.8867\n",
            "\n",
            "Epoch 4862/4999:\n",
            "train Loss: 0.4123 Acc: 0.8867\n",
            "\n",
            "Epoch 4863/4999:\n",
            "train Loss: 0.4123 Acc: 0.8867\n",
            "\n",
            "Epoch 4864/4999:\n",
            "train Loss: 0.4123 Acc: 0.8867\n",
            "\n",
            "Epoch 4865/4999:\n",
            "train Loss: 0.4122 Acc: 0.8867\n",
            "\n",
            "Epoch 4866/4999:\n",
            "train Loss: 0.4122 Acc: 0.8867\n",
            "\n",
            "Epoch 4867/4999:\n",
            "train Loss: 0.4122 Acc: 0.8867\n",
            "\n",
            "Epoch 4868/4999:\n",
            "train Loss: 0.4122 Acc: 0.8867\n",
            "\n",
            "Epoch 4869/4999:\n",
            "train Loss: 0.4121 Acc: 0.8867\n",
            "\n",
            "Epoch 4870/4999:\n",
            "train Loss: 0.4121 Acc: 0.8867\n",
            "\n",
            "Epoch 4871/4999:\n",
            "train Loss: 0.4121 Acc: 0.8867\n",
            "\n",
            "Epoch 4872/4999:\n",
            "train Loss: 0.4120 Acc: 0.8867\n",
            "\n",
            "Epoch 4873/4999:\n",
            "train Loss: 0.4120 Acc: 0.8867\n",
            "\n",
            "Epoch 4874/4999:\n",
            "train Loss: 0.4120 Acc: 0.8867\n",
            "\n",
            "Epoch 4875/4999:\n",
            "train Loss: 0.4120 Acc: 0.8867\n",
            "\n",
            "Epoch 4876/4999:\n",
            "train Loss: 0.4119 Acc: 0.8867\n",
            "\n",
            "Epoch 4877/4999:\n",
            "train Loss: 0.4119 Acc: 0.8867\n",
            "\n",
            "Epoch 4878/4999:\n",
            "train Loss: 0.4119 Acc: 0.8867\n",
            "\n",
            "Epoch 4879/4999:\n",
            "train Loss: 0.4119 Acc: 0.8867\n",
            "\n",
            "Epoch 4880/4999:\n",
            "train Loss: 0.4118 Acc: 0.8867\n",
            "\n",
            "Epoch 4881/4999:\n",
            "train Loss: 0.4118 Acc: 0.8867\n",
            "\n",
            "Epoch 4882/4999:\n",
            "train Loss: 0.4118 Acc: 0.8867\n",
            "\n",
            "Epoch 4883/4999:\n",
            "train Loss: 0.4118 Acc: 0.8867\n",
            "\n",
            "Epoch 4884/4999:\n",
            "train Loss: 0.4117 Acc: 0.8867\n",
            "\n",
            "Epoch 4885/4999:\n",
            "train Loss: 0.4117 Acc: 0.8867\n",
            "\n",
            "Epoch 4886/4999:\n",
            "train Loss: 0.4117 Acc: 0.8867\n",
            "\n",
            "Epoch 4887/4999:\n",
            "train Loss: 0.4117 Acc: 0.8867\n",
            "\n",
            "Epoch 4888/4999:\n",
            "train Loss: 0.4116 Acc: 0.8867\n",
            "\n",
            "Epoch 4889/4999:\n",
            "train Loss: 0.4116 Acc: 0.8867\n",
            "\n",
            "Epoch 4890/4999:\n",
            "train Loss: 0.4116 Acc: 0.8867\n",
            "\n",
            "Epoch 4891/4999:\n",
            "train Loss: 0.4115 Acc: 0.8867\n",
            "\n",
            "Epoch 4892/4999:\n",
            "train Loss: 0.4115 Acc: 0.8867\n",
            "\n",
            "Epoch 4893/4999:\n",
            "train Loss: 0.4115 Acc: 0.8867\n",
            "\n",
            "Epoch 4894/4999:\n",
            "train Loss: 0.4115 Acc: 0.8867\n",
            "\n",
            "Epoch 4895/4999:\n",
            "train Loss: 0.4114 Acc: 0.8867\n",
            "\n",
            "Epoch 4896/4999:\n",
            "train Loss: 0.4114 Acc: 0.8867\n",
            "\n",
            "Epoch 4897/4999:\n",
            "train Loss: 0.4114 Acc: 0.8867\n",
            "\n",
            "Epoch 4898/4999:\n",
            "train Loss: 0.4114 Acc: 0.8867\n",
            "\n",
            "Epoch 4899/4999:\n",
            "train Loss: 0.4113 Acc: 0.8867\n",
            "\n",
            "Epoch 4900/4999:\n",
            "train Loss: 0.4113 Acc: 0.8867\n",
            "\n",
            "Epoch 4901/4999:\n",
            "train Loss: 0.4113 Acc: 0.8867\n",
            "\n",
            "Epoch 4902/4999:\n",
            "train Loss: 0.4113 Acc: 0.8867\n",
            "\n",
            "Epoch 4903/4999:\n",
            "train Loss: 0.4112 Acc: 0.8867\n",
            "\n",
            "Epoch 4904/4999:\n",
            "train Loss: 0.4112 Acc: 0.8867\n",
            "\n",
            "Epoch 4905/4999:\n",
            "train Loss: 0.4112 Acc: 0.8867\n",
            "\n",
            "Epoch 4906/4999:\n",
            "train Loss: 0.4112 Acc: 0.8867\n",
            "\n",
            "Epoch 4907/4999:\n",
            "train Loss: 0.4111 Acc: 0.8867\n",
            "\n",
            "Epoch 4908/4999:\n",
            "train Loss: 0.4111 Acc: 0.8867\n",
            "\n",
            "Epoch 4909/4999:\n",
            "train Loss: 0.4111 Acc: 0.8867\n",
            "\n",
            "Epoch 4910/4999:\n",
            "train Loss: 0.4111 Acc: 0.8867\n",
            "\n",
            "Epoch 4911/4999:\n",
            "train Loss: 0.4110 Acc: 0.8867\n",
            "\n",
            "Epoch 4912/4999:\n",
            "train Loss: 0.4110 Acc: 0.8867\n",
            "\n",
            "Epoch 4913/4999:\n",
            "train Loss: 0.4110 Acc: 0.8867\n",
            "\n",
            "Epoch 4914/4999:\n",
            "train Loss: 0.4109 Acc: 0.8867\n",
            "\n",
            "Epoch 4915/4999:\n",
            "train Loss: 0.4109 Acc: 0.8867\n",
            "\n",
            "Epoch 4916/4999:\n",
            "train Loss: 0.4109 Acc: 0.8867\n",
            "\n",
            "Epoch 4917/4999:\n",
            "train Loss: 0.4109 Acc: 0.8867\n",
            "\n",
            "Epoch 4918/4999:\n",
            "train Loss: 0.4108 Acc: 0.8867\n",
            "\n",
            "Epoch 4919/4999:\n",
            "train Loss: 0.4108 Acc: 0.8867\n",
            "\n",
            "Epoch 4920/4999:\n",
            "train Loss: 0.4108 Acc: 0.8867\n",
            "\n",
            "Epoch 4921/4999:\n",
            "train Loss: 0.4108 Acc: 0.8867\n",
            "\n",
            "Epoch 4922/4999:\n",
            "train Loss: 0.4107 Acc: 0.8867\n",
            "\n",
            "Epoch 4923/4999:\n",
            "train Loss: 0.4107 Acc: 0.8867\n",
            "\n",
            "Epoch 4924/4999:\n",
            "train Loss: 0.4107 Acc: 0.8867\n",
            "\n",
            "Epoch 4925/4999:\n",
            "train Loss: 0.4107 Acc: 0.8867\n",
            "\n",
            "Epoch 4926/4999:\n",
            "train Loss: 0.4106 Acc: 0.8867\n",
            "\n",
            "Epoch 4927/4999:\n",
            "train Loss: 0.4106 Acc: 0.8867\n",
            "\n",
            "Epoch 4928/4999:\n",
            "train Loss: 0.4106 Acc: 0.8867\n",
            "\n",
            "Epoch 4929/4999:\n",
            "train Loss: 0.4106 Acc: 0.8867\n",
            "\n",
            "Epoch 4930/4999:\n",
            "train Loss: 0.4105 Acc: 0.8867\n",
            "\n",
            "Epoch 4931/4999:\n",
            "train Loss: 0.4105 Acc: 0.8867\n",
            "\n",
            "Epoch 4932/4999:\n",
            "train Loss: 0.4105 Acc: 0.8867\n",
            "\n",
            "Epoch 4933/4999:\n",
            "train Loss: 0.4105 Acc: 0.8867\n",
            "\n",
            "Epoch 4934/4999:\n",
            "train Loss: 0.4104 Acc: 0.8867\n",
            "\n",
            "Epoch 4935/4999:\n",
            "train Loss: 0.4104 Acc: 0.8867\n",
            "\n",
            "Epoch 4936/4999:\n",
            "train Loss: 0.4104 Acc: 0.8867\n",
            "\n",
            "Epoch 4937/4999:\n",
            "train Loss: 0.4103 Acc: 0.8867\n",
            "\n",
            "Epoch 4938/4999:\n",
            "train Loss: 0.4103 Acc: 0.8867\n",
            "\n",
            "Epoch 4939/4999:\n",
            "train Loss: 0.4103 Acc: 0.8867\n",
            "\n",
            "Epoch 4940/4999:\n",
            "train Loss: 0.4103 Acc: 0.8867\n",
            "\n",
            "Epoch 4941/4999:\n",
            "train Loss: 0.4102 Acc: 0.8867\n",
            "\n",
            "Epoch 4942/4999:\n",
            "train Loss: 0.4102 Acc: 0.8867\n",
            "\n",
            "Epoch 4943/4999:\n",
            "train Loss: 0.4102 Acc: 0.8867\n",
            "\n",
            "Epoch 4944/4999:\n",
            "train Loss: 0.4102 Acc: 0.8867\n",
            "\n",
            "Epoch 4945/4999:\n",
            "train Loss: 0.4101 Acc: 0.8867\n",
            "\n",
            "Epoch 4946/4999:\n",
            "train Loss: 0.4101 Acc: 0.8867\n",
            "\n",
            "Epoch 4947/4999:\n",
            "train Loss: 0.4101 Acc: 0.8867\n",
            "\n",
            "Epoch 4948/4999:\n",
            "train Loss: 0.4101 Acc: 0.8867\n",
            "\n",
            "Epoch 4949/4999:\n",
            "train Loss: 0.4100 Acc: 0.8867\n",
            "\n",
            "Epoch 4950/4999:\n",
            "train Loss: 0.4100 Acc: 0.8867\n",
            "\n",
            "Epoch 4951/4999:\n",
            "train Loss: 0.4100 Acc: 0.8867\n",
            "\n",
            "Epoch 4952/4999:\n",
            "train Loss: 0.4100 Acc: 0.8867\n",
            "\n",
            "Epoch 4953/4999:\n",
            "train Loss: 0.4099 Acc: 0.8867\n",
            "\n",
            "Epoch 4954/4999:\n",
            "train Loss: 0.4099 Acc: 0.8867\n",
            "\n",
            "Epoch 4955/4999:\n",
            "train Loss: 0.4099 Acc: 0.8867\n",
            "\n",
            "Epoch 4956/4999:\n",
            "train Loss: 0.4099 Acc: 0.8867\n",
            "\n",
            "Epoch 4957/4999:\n",
            "train Loss: 0.4098 Acc: 0.8867\n",
            "\n",
            "Epoch 4958/4999:\n",
            "train Loss: 0.4098 Acc: 0.8867\n",
            "\n",
            "Epoch 4959/4999:\n",
            "train Loss: 0.4098 Acc: 0.8867\n",
            "\n",
            "Epoch 4960/4999:\n",
            "train Loss: 0.4097 Acc: 0.8867\n",
            "\n",
            "Epoch 4961/4999:\n",
            "train Loss: 0.4097 Acc: 0.8867\n",
            "\n",
            "Epoch 4962/4999:\n",
            "train Loss: 0.4097 Acc: 0.8867\n",
            "\n",
            "Epoch 4963/4999:\n",
            "train Loss: 0.4097 Acc: 0.8867\n",
            "\n",
            "Epoch 4964/4999:\n",
            "train Loss: 0.4096 Acc: 0.8867\n",
            "\n",
            "Epoch 4965/4999:\n",
            "train Loss: 0.4096 Acc: 0.8867\n",
            "\n",
            "Epoch 4966/4999:\n",
            "train Loss: 0.4096 Acc: 0.8867\n",
            "\n",
            "Epoch 4967/4999:\n",
            "train Loss: 0.4096 Acc: 0.8867\n",
            "\n",
            "Epoch 4968/4999:\n",
            "train Loss: 0.4095 Acc: 0.8867\n",
            "\n",
            "Epoch 4969/4999:\n",
            "train Loss: 0.4095 Acc: 0.8867\n",
            "\n",
            "Epoch 4970/4999:\n",
            "train Loss: 0.4095 Acc: 0.8867\n",
            "\n",
            "Epoch 4971/4999:\n",
            "train Loss: 0.4095 Acc: 0.8867\n",
            "\n",
            "Epoch 4972/4999:\n",
            "train Loss: 0.4094 Acc: 0.8867\n",
            "\n",
            "Epoch 4973/4999:\n",
            "train Loss: 0.4094 Acc: 0.8867\n",
            "\n",
            "Epoch 4974/4999:\n",
            "train Loss: 0.4094 Acc: 0.8867\n",
            "\n",
            "Epoch 4975/4999:\n",
            "train Loss: 0.4094 Acc: 0.8867\n",
            "\n",
            "Epoch 4976/4999:\n",
            "train Loss: 0.4093 Acc: 0.8867\n",
            "\n",
            "Epoch 4977/4999:\n",
            "train Loss: 0.4093 Acc: 0.8867\n",
            "\n",
            "Epoch 4978/4999:\n",
            "train Loss: 0.4093 Acc: 0.8867\n",
            "\n",
            "Epoch 4979/4999:\n",
            "train Loss: 0.4093 Acc: 0.8867\n",
            "\n",
            "Epoch 4980/4999:\n",
            "train Loss: 0.4092 Acc: 0.8867\n",
            "\n",
            "Epoch 4981/4999:\n",
            "train Loss: 0.4092 Acc: 0.8867\n",
            "\n",
            "Epoch 4982/4999:\n",
            "train Loss: 0.4092 Acc: 0.8867\n",
            "\n",
            "Epoch 4983/4999:\n",
            "train Loss: 0.4091 Acc: 0.8867\n",
            "\n",
            "Epoch 4984/4999:\n",
            "train Loss: 0.4091 Acc: 0.8867\n",
            "\n",
            "Epoch 4985/4999:\n",
            "train Loss: 0.4091 Acc: 0.8867\n",
            "\n",
            "Epoch 4986/4999:\n",
            "train Loss: 0.4091 Acc: 0.8867\n",
            "\n",
            "Epoch 4987/4999:\n",
            "train Loss: 0.4090 Acc: 0.8867\n",
            "\n",
            "Epoch 4988/4999:\n",
            "train Loss: 0.4090 Acc: 0.8867\n",
            "\n",
            "Epoch 4989/4999:\n",
            "train Loss: 0.4090 Acc: 0.8867\n",
            "\n",
            "Epoch 4990/4999:\n",
            "train Loss: 0.4090 Acc: 0.8867\n",
            "\n",
            "Epoch 4991/4999:\n",
            "train Loss: 0.4089 Acc: 0.8867\n",
            "\n",
            "Epoch 4992/4999:\n",
            "train Loss: 0.4089 Acc: 0.8867\n",
            "\n",
            "Epoch 4993/4999:\n",
            "train Loss: 0.4089 Acc: 0.8867\n",
            "\n",
            "Epoch 4994/4999:\n",
            "train Loss: 0.4089 Acc: 0.8867\n",
            "\n",
            "Epoch 4995/4999:\n",
            "train Loss: 0.4088 Acc: 0.8867\n",
            "\n",
            "Epoch 4996/4999:\n",
            "train Loss: 0.4088 Acc: 0.8867\n",
            "\n",
            "Epoch 4997/4999:\n",
            "train Loss: 0.4088 Acc: 0.8867\n",
            "\n",
            "Epoch 4998/4999:\n",
            "train Loss: 0.4088 Acc: 0.8867\n",
            "\n",
            "Epoch 4999/4999:\n",
            "train Loss: 0.4087 Acc: 0.8867\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WuMo4M8AkzrD",
        "colab_type": "code",
        "outputId": "17e6b94e-cd9a-4cb1-d4f3-91909bed655f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "net.W_2.shape\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([10, 5, 8, 8])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oRYhGX0WPKUQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OK38TywePKUU",
        "colab_type": "code",
        "outputId": "5fe46c70-cb9a-48b3-d289-0f28d33632dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        }
      },
      "source": [
        "# Loss\n",
        "plt.plot(range(num_epochs), train_loss, val_loss)\n",
        "plt.legend(['train', 'val'])\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('cross entropy loss')\n",
        "plt.title('loss')"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'loss')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 110
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oE2UJmSmPKUX",
        "colab_type": "code",
        "outputId": "d289551a-70b5-4e42-f00b-78cb37a8db57",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        }
      },
      "source": [
        "# accuracy\n",
        "plt.plot(range(num_epochs), train_acc, val_acc)\n",
        "plt.legend(['train', 'val'])\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('accuracy')\n",
        "plt.title('accuracy')"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'accuracy')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 111
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAcwUlEQVR4nO3de5xVdb3/8dcbGBhAlKtgDDqYxMXL8TJyMMwss0BL7aRhXjIr6VdZZqfOwV/nV+bpPI7lqU490uOlLDUTES9xOhiiAp4KlEHRAFEuigyKDFdBHeTy+f2x19BmHGAPzNp7Zq/38/GYB2t913ev9fkOe+Y967LXUkRgZmbZ1aHUBZiZWWk5CMzMMs5BYGaWcQ4CM7OMcxCYmWWcg8DMLOMcBGZmGecgMDPLOAeBWYqU458za9P8BrVMkDRB0jJJmyUtkvTJvGVXSHo+b9mJSfsgSQ9Iqpe0TtIvkvZrJf027/XVkkJSp2R+pqR/k/Rn4C3gSEmX521juaQvNanvXEnzJb2R1DlG0gWS5jXp901Jv0/vO2VZ1KnUBZgVyTLgA8Bq4ALgt5KOAk4FrgXOA2qB9wLbJHUE/gA8DlwK7ABqWrC9S4GxwAuAgKHAx4HlwGnAw5LmRsTTkkYCdwLnA48BhwE9gJeAWyQNj4jn89b7g/35BpjtifcILBMi4r6IeDUidkbEvcASYCTwReBHETE3cpZGxIpk2XuAb0fEmxHREBF/asEmfxMRCyNie0Rsi4j/iYhlyTZmAY+QCyaALwC3R8T0pL5VEbE4IrYC9wKXAEg6GqgmF1BmrcZBYJkg6bPJoZeNkjYCxwB9gUHk9haaGgSsiIjt+7nJlU22P1bSHEnrk+2flWy/cVvN1QBwB3CRJJHbG5iUBIRZq3EQWNmTdARwG3Al0CciegILyB2yWUnucFBTK4HDG4/7N/Em0C1vfkAzfXbd1ldSF+B+4D+A/sn2pybbb9xWczUQEXOAd8jtPVwE3NX8KM32n4PAsqA7uV/M9QCSLie3RwDwS+Bbkk5KrvA5KgmOp4DXgOsldZdUKWl08pr5wGmSDpd0CHDNPrbfGeiSbH+7pLHAR/OW/wq4XNIZkjpIGihpWN7yO4FfANtaeHjKrCAOAit7EbEI+DEwG3gdOBb4c7LsPuDfgN8Bm4GHgN4RsQP4BHAU8ApQB4xLXjOd3LH754B57OOYfURsBr4OTAI2kPvLfkre8qeAy4GfApuAWcAReau4i1xw/RazFMgPpjFr2yR1BdYAJ0bEklLXY+XHewRmbd+XgbkOAUuLP0dg1oZJepncSeXzSlyKlTEfGjIzyzgfGjIzy7h2d2iob9++UV1dXeoyzMzalXnz5q2NiH7NLWt3QVBdXU1tbW2pyzAza1ckrdjTMh8aMjPLOAeBmVnGOQjMzDLOQWBmlnEOAjOzjHMQmJllnIPAzCzj2t3nCMzMDtTTr2xg5uI1pS6jxc4Y3p+/G9Sz1dfrIDCzsrVjZ7Czmfup/eiPi5mzfD1SMy9qww49uNJBYGZWqJfXvsmYnz1Bw7adzS4/69gB3HTxSUWuqm1yEJhZSb2zfSe3PrGMzVu3t+p6V65/i4ZtO/nsKUdwaI8u71p+5ojmHjWdTQ4CsyYatu1gx07fnr1Y5q3YwH888iIVHUWHVj5Wc9ghlfzjR4dySNeKVl1vuXEQmOX544LX+D+/fbrUZWTSH772AYYO6FHqMjLJQWCZFRHcNHMZa7ds3dX27MqNAFwzdli7O5HYnvXs2pn39T+o1GVkloPAMmXr9h28tXUHAK+sf4sbpr1AZUUHKjr+7SM1o4/qw5c++N5SlWhWdA4Cy4wdO4NTfziD+s1bd2v/1WUnM/qoviWqyqz0HARWthq27eCnj77Ilobc1SjvbN9J/eatfPy4w6g5ohcA3bp0YuTg3qUs06zkHARWtv53yVpumbWcgys70blT7tDPew6pZPxpR3JcVet/KMesvXIQWFlauf4trrgz90jTB77yfo461FejmO2Jg8DahQ1vvsNPpr9Iw7YdBfWvT64E+tz7q3lvP1+NYrY3DgIriYhg1ca3aeY2MM16fPEa7pqzgkN7dKFTh8Ku6xw2oAdXnTEE+TpQs71yEFhJ3DRzGTdMe6FFr5HgkatPo2e3zilVZZZNDgIrmtffaODHj7zA1u07mb9yI727d+b/njW84NcPOLjSIWCWAgeBtchrm97mza2FHadvatrC1UyqraOqV1c6dRDnHT+Q80+qauUKzaylUg0CSWOAnwEdgV9GxPVNlh8O3AH0TPpMiIipadZk+2/x6jcY85//e0Dr6NRBTL/6g3Tt3LGVqjKzA5VaEEjqCNwInAnUAXMlTYmIRXnd/gWYFBH/JWkEMBWoTqsm23+vrHuL70/J/ddNGDuM9/Tsul/rGdiz0iFg1sakuUcwElgaEcsBJE0EzgXygyCAg5PpQ4BXU6zHWmhzwzZWrn8bgCnPvsrs5esYObg3nz3lCLp19lFFs3KR5k/zQGBl3nwd8PdN+lwLPCLpa0B34CMp1mMt9MU7annypfW75isrOjDxilF0KPDyTTNrH0r9Z91ngN9ExI8lnQLcJemYiNjt2XKSxgPjAQ4//PASlJk99859hSdfWs/oo/pw6ahqAAb17uoQMCtDaQbBKmBQ3nxV0pbvC8AYgIiYLakS6Ausye8UEbcCtwLU1NT40VEp2LkzWLx6M+/syGXwzbOWA3DZKdV89Gg/0s+snKUZBHOBIZIGkwuAC4GLmvR5BTgD+I2k4UAlUJ9iTbYH0xau5st37/5krstOOcIhYJYBqQVBRGyXdCUwjdylobdHxEJJ1wG1ETEF+EfgNklXkztx/LmIQm86YK1pzvJ1ANx8yYl06dQRBCce3qvEVZlZMaR6jiD5TMDUJm3fzZteBIxOs4b2bPuOnTy3ahPbd6Sfja9tagDgY0cP8L15zDKm1CeLbS+mPPsq35z0bNG2d1zVIQ4BswxyELQRN89axuOLdztHzmubctfw3/n5kXQswtU6vl2zWTY5CEps246dzFuxgV//+SV2Bry3X/ddywb27MoZw/pz2vv6lbBCMyt3DoISe+iZVXx78nMAXPmho/jWx4aWuCIzyxoHQQlFBNdOWQjApC+dwnFVh5S4IjPLIgfBPry89k2Wr92Syrobtu3kzXd2MKh3V0YO7p3KNszM9sVBsA+X/fopVqx7K9VtfOesEamu38xsbxwEezDrxXpumLaYlevf4h9OHMhlp1Snsp3OnTowbECPVNZtZlYIB0EzIoIfPryYJWs2c+aI/lz+/sEc6+P3ZlamHATNePH1LSx67Q36HtSFWy6tKXU5Zmap6lDqAtqitVu2AnD9Pxxb4krMzNKXmT2CJa9vZtFrbxTU97m6TQAM7LV/j2M0M2tPMhMEjy9ew78/vLjg/hUdRf+DK1OsyMysbchMEIw7eRBnjuhfcP+Du1bQu3vnFCsyM2sbMhMEPbt1pmc3/2I3M2vKJ4vNzDLOQWBmlnEOAjOzjHMQmJllnIPAzCzjHARmZhnnIDAzyzgHgZlZxjkIzMwyzkFgZpZxDgIzs4xzEJiZZZyDwMws4xwEZmYZ5yAwM8s4B4GZWcY5CMzMMs5BYGaWcQ4CM7OMcxCYmWWcg8DMLONSDQJJYyS9IGmppAl76PNpSYskLZT0uzTrMTOzd+uU1ooldQRuBM4E6oC5kqZExKK8PkOAa4DREbFB0qFp1WNmZs1Lc49gJLA0IpZHxDvARODcJn2uAG6MiA0AEbEmxXrMzKwZaQbBQGBl3nxd0pbvfcD7JP1Z0hxJY5pbkaTxkmol1dbX16dUrplZNpX6ZHEnYAhwOvAZ4DZJPZt2iohbI6ImImr69etX5BLNzMpbmkGwChiUN1+VtOWrA6ZExLaIeAl4kVwwmJlZkaQZBHOBIZIGS+oMXAhMadLnIXJ7A0jqS+5Q0fIUazIzsyZSC4KI2A5cCUwDngcmRcRCSddJOifpNg1YJ2kRMAP4dkSsS6smMzN7N0VEqWtokZqamqitrS11GWZm7YqkeRFR09yyUp8sNjOzEnMQmJllnIPAzCzjHARmZhnnIDAzyzgHgZlZxjkIzMwyzkFgZpZxDgIzs4wrKAgkPSDpbEkODjOzMlPoL/abgIuAJZKulzQ0xZrMzKyICgqCiHg0Ii4GTgReBh6V9BdJl0uqSLNAMzNLV8GHeiT1AT4HfBF4BvgZuWCYnkplZmZWFAU9vF7Sg8BQ4C7gExHxWrLoXkm+FaiZtXnbtm2jrq6OhoaGUpeSqsrKSqqqqqioKPxgTUFBAPw8ImY0t2BPtzU1M2tL6urq6NGjB9XV1UgqdTmpiAjWrVtHXV0dgwcPLvh1hR4aGpH/LGFJvSR9paVFmpmVSkNDA3369CnbEACQRJ8+fVq811NoEFwRERsbZyJiA3BFi7ZkZlZi5RwCjfZnjIUGQUflrV1SR6Bzi7dmZpZRGzdu5Kabbmrx68466yw2bty4744HoNAg+CO5E8NnSDoDuCdpMzOzAuwpCLZv377X102dOpWePXvutc+BKvRk8T8DXwK+nMxPB36ZSkVmZmVowoQJLFu2jOOPP56KigoqKyvp1asXixcv5sUXX+S8885j5cqVNDQ0cNVVVzF+/HgAqqurqa2tZcuWLYwdO5ZTTz2Vv/zlLwwcOJDf//73dO3a9YBrKygIImIn8F/Jl5lZu/b9/17IolffaNV1jnjPwXzvE0fvcfn111/PggULmD9/PjNnzuTss89mwYIFu67uuf322+nduzdvv/02J598Mp/61Kfo06fPbutYsmQJ99xzD7fddhuf/vSnuf/++7nkkksOuPZCP0cwBPh3YARQ2dgeEUcecAVmZhk0cuTI3S7x/PnPf86DDz4IwMqVK1myZMm7gmDw4MEcf/zxAJx00km8/PLLrVJLoYeGfg18D/gp8CHgcnznUjNrp/b2l3uxdO/efdf0zJkzefTRR5k9ezbdunXj9NNPb/YS0C5duuya7tixI2+//Xar1FLoL/OuEfEYoIhYERHXAme3SgVmZhnQo0cPNm/e3OyyTZs20atXL7p168bixYuZM2dOUWsrdI9ga3IL6iWSrgRWAQelV5aZWXnp06cPo0eP5phjjqFr1670799/17IxY8Zw8803M3z4cIYOHcqoUaOKWpsiYt+dpJOB54GewL8CBwM3RERxYwuoqamJ2lrf3sjMWub5559n+PDhpS6jKJobq6R5e7ol0D73CJIPj42LiG8BW8idHzAzszKxz3MEEbEDOLUItZiZWQkUeo7gGUlTgPuANxsbI+KBVKoyM7OiKTQIKoF1wIfz2gJwEJiZtXOFfrLY5wXMzMpUoZ8s/jW5PYDdRMTnW70iMzMrqkIPDf0hb7oS+CTwauuXY2ZmAAcddBBbtmwpyrYKPTR0f/68pHuAP6VSkZmZFVWhewRNDQEObc1CzMzK2YQJExg0aBBf/epXAbj22mvp1KkTM2bMYMOGDWzbto0f/OAHnHvuuUWvrdBzBJvZ/RzBanLPKDAza38engCr/9q66xxwLIy9fo+Lx40bxze+8Y1dQTBp0iSmTZvG17/+dQ4++GDWrl3LqFGjOOecc4r+SM1CDw312J+VSxoD/AzoCPwyIpr9Lkn6FDAZODkifP8IMys7J5xwAmvWrOHVV1+lvr6eXr16MWDAAK6++mqeeOIJOnTowKpVq3j99dcZMGBAUWsrdI/gk8DjEbEpme8JnB4RD+3lNR2BG4EzgTpgrqQpEbGoSb8ewFXAk/s3BDOzFtrLX+5puuCCC5g8eTKrV69m3Lhx3H333dTX1zNv3jwqKiqorq5u9vbTaSv0NtTfawwBgIjYSO75BHszElgaEcsj4h1gItDcwa9/BX4IFH/0ZmZFNG7cOCZOnMjkyZO54IIL2LRpE4ceeigVFRXMmDGDFStWlKSuQoOguX772psYCKzMm69L2naRdCIwKCL+Z28rkjReUq2k2vr6+kLqNTNrc44++mg2b97MwIEDOeyww7j44oupra3l2GOP5c4772TYsGElqavQq4ZqJf2E3KEegK8C8w5kw8nzDX4CfG5ffSPiVuBWyN2G+kC2a2ZWSn/9699OUvft25fZs2c3269YnyGAwvcIvga8A9xL7hBPA7kw2JtVwKC8+aqkrVEP4BhgpqSXgVHAFEnN3i/bzMzSUehVQ28CE1q47rnAEEmDyQXAhcBFeevcBPRtnJc0E/iWrxoyMyuugvYIJE1PrhRqnO8ladreXhMR24ErgWnknm42KSIWSrpO0jkHUrSZmbWeQs8R9E2uFAIgIjZI2ucniyNiKjC1Sdt399D39AJrMTPbLxFR9A9rFVshjx9uqtBzBDslHd44I6maZu5GambWVlVWVrJu3br9+kXZXkQE69ato7KyskWvK3SP4DvAnyTNAgR8ABjfshLNzEqnqqqKuro6yv0S9MrKSqqqqlr0mkJPFv8xuZpnPPAM8BDwdosrNDMrkYqKCgYPHlzqMtqkQm8x8UVyt4GoAuaTu9RzNrs/utLMzNqhQs8RXAWcDKyIiA8BJwAb9/4SMzNrDwoNgoaIaACQ1CUiFgND0yvLzMyKpdCTxXXJ5wgeAqZL2gCU5u5IZmbWqgo9WfzJZPJaSTOAQ4A/plaVmZkVTYsfVRkRs9IoxMzMSqPQcwRmZlamHARmZhnnIDAzyzgHgZlZxjkIzMwyzkFgZpZxDgIzs4xzEJiZZZyDwMws4xwEZmYZ5yAwM8s4B4GZWcY5CMzMMs5BYGaWcQ4CM7OMcxCYmWWcg8DMLOMcBGZmGecgMDPLOAeBmVnGOQjMzDLOQWBmlnEOAjOzjHMQmJllnIPAzCzjHARmZhmXahBIGiPpBUlLJU1oZvk3JS2S9JykxyQdkWY9Zmb2bqkFgaSOwI3AWGAE8BlJI5p0ewaoiYjjgMnAj9Kqx8zMmpfmHsFIYGlELI+Id4CJwLn5HSJiRkS8lczOAapSrMfMzJqRZhAMBFbmzdclbXvyBeDh5hZIGi+pVlJtfX19K5ZoZmZt4mSxpEuAGuCG5pZHxK0RURMRNf369StucWZmZa5TiuteBQzKm69K2nYj6SPAd4APRsTWFOsxM7NmpLlHMBcYImmwpM7AhcCU/A6STgBuAc6JiDUp1mJmZnuQWhBExHbgSmAa8DwwKSIWSrpO0jlJtxuAg4D7JM2XNGUPqzMzs5SkeWiIiJgKTG3S9t286Y+kuX0zM9u3NnGy2MzMSsdBYGaWcQ4CM7OMcxCYmWWcg8DMLOMcBGZmGecgMDPLOAeBmVnGOQjMzDLOQWBmlnEOAjOzjHMQmJllnIPAzCzjHARmZhnnIDAzyzgHgZlZxjkIzMwyzkFgZpZxDgIzs4xzEJiZZZyDwMws4xwEZmYZ5yAwM8s4B4GZWcY5CMzMMs5BYGaWcQ4CM7OMcxCYmWWcg8DMLOMcBGZmGecgMDPLOAeBmVnGOQjMzDLOQWBmlnEOAjOzjHMQmJllXKpBIGmMpBckLZU0oZnlXSTdmyx/UlJ1mvWYmdm7pRYEkjoCNwJjgRHAZySNaNLtC8CGiDgK+Cnww7TqMTOz5nVKcd0jgaURsRxA0kTgXGBRXp9zgWuT6cnALyQpIqLVq3n6Lpj9i1ZfrZlZ0Xzwn+CYT7X6atMMgoHAyrz5OuDv99QnIrZL2gT0Adbmd5I0HhgPcPjhh+9fNd16Q7+h+/daM7O2oLJnKqtNMwhaTUTcCtwKUFNTs397C8POzn2Zmdlu0jxZvAoYlDdflbQ120dSJ+AQYF2KNZmZWRNpBsFcYIikwZI6AxcCU5r0mQJclkyfDzyeyvkBMzPbo9QODSXH/K8EpgEdgdsjYqGk64DaiJgC/Aq4S9JSYD25sDAzsyJK9RxBREwFpjZp+27edANwQZo1mJnZ3vmTxWZmGecgMDPLOAeBmVnGOQjMzDJO7e1qTUn1wIr9fHlfmnxqOQM85mzwmLPhQMZ8RET0a25BuwuCAyGpNiJqSl1HMXnM2eAxZ0NaY/ahITOzjHMQmJllXNaC4NZSF1ACHnM2eMzZkMqYM3WOwMzM3i1rewRmZtaEg8DMLOMyEwSSxkh6QdJSSRNKXc+BkHS7pDWSFuS19ZY0XdKS5N9eSbsk/TwZ93OSTsx7zWVJ/yWSLmtuW22BpEGSZkhaJGmhpKuS9nIec6WkpyQ9m4z5+0n7YElPJmO7N7nFO5K6JPNLk+XVeeu6Jml/QdLHSjOiwknqKOkZSX9I5st6zJJelvRXSfMl1SZtxX1vR0TZf5G7DfYy4EigM/AsMKLUdR3AeE4DTgQW5LX9CJiQTE8AfphMnwU8DAgYBTyZtPcGlif/9kqme5V6bHsY72HAicl0D+BFYESZj1nAQcl0BfBkMpZJwIVJ+83Al5PprwA3J9MXAvcm0yOS93sXYHDyc9Cx1OPbx9i/CfwO+EMyX9ZjBl4G+jZpK+p7Oyt7BCOBpRGxPCLeASYC55a4pv0WEU+Qe35DvnOBO5LpO4Dz8trvjJw5QE9JhwEfA6ZHxPqI2ABMB8akX33LRcRrEfF0Mr0ZeJ7c867LecwREVuS2YrkK4APA5OT9qZjbvxeTAbOkKSkfWJEbI2Il4Cl5H4e2iRJVcDZwC+TeVHmY96Dor63sxIEA4GVefN1SVs56R8RryXTq4H+yfSext4uvyfJ7v8J5P5CLusxJ4dI5gNryP1gLwM2RsT2pEt+/bvGlizfBPShnY0Z+E/gn4CdyXwfyn/MATwiaZ6k8UlbUd/b7eLh9dYyERGSyu66YEkHAfcD34iIN3J//OWU45gjYgdwvKSewIPAsBKXlCpJHwfWRMQ8SaeXup4iOjUiVkk6FJguaXH+wmK8t7OyR7AKGJQ3X5W0lZPXk11Ekn/XJO17Gnu7+p5IqiAXAndHxANJc1mPuVFEbARmAKeQOxTQ+Adcfv27xpYsPwRYR/sa82jgHEkvkzt8+2HgZ5T3mImIVcm/a8gF/kiK/N7OShDMBYYkVx90JndiaUqJa2ptU4DGKwUuA36f1/7Z5GqDUcCmZJdzGvBRSb2SKxI+mrS1Oclx318Bz0fET/IWlfOY+yV7AkjqCpxJ7tzIDOD8pFvTMTd+L84HHo/cWcQpwIXJFTaDgSHAU8UZRctExDURURUR1eR+Rh+PiIsp4zFL6i6pR+M0uffkAor93i71GfNifZE72/4iueOs3yl1PQc4lnuA14Bt5I4FfoHcsdHHgCXAo0DvpK+AG5Nx/xWoyVvP58mdSFsKXF7qce1lvKeSO476HDA/+TqrzMd8HPBMMuYFwHeT9iPJ/VJbCtwHdEnaK5P5pcnyI/PW9Z3ke/ECMLbUYytw/Kfzt6uGynbMydieTb4WNv5uKvZ727eYMDPLuKwcGjIzsz1wEJiZZZyDwMws4xwEZmYZ5yAwM8s4B4FZEUk6vfGummZthYPAzCzjHARmzZB0iXLPA5gv6ZbkBnBbJP1UuecDPCapX9L3eElzkvvDP5h37/ijJD2q3DMFnpb03mT1B0maLGmxpLuVf9MksxJwEJg1IWk4MA4YHRHHAzuAi4HuQG1EHA3MAr6XvORO4J8j4jhyn/ZsbL8buDEi/g54P7lPg0Pu7qnfIHff/CPJ3WPHrGR891GzdzsDOAmYm/yx3pXcTb92AvcmfX4LPCDpEKBnRMxK2u8A7kvuHzMwIh4EiIgGgGR9T0VEXTI/H6gG/pT+sMya5yAwezcBd0TENbs1Sv+vSb/9vT/L1rzpHfjn0ErMh4bM3u0x4Pzk/vCNz489gtzPS+NdMC8C/hQRm4ANkj6QtF8KzIrck9TqJJ2XrKOLpG5FHYVZgfyXiFkTEbFI0r+Qe2pUB3J3ef0q8CYwMlm2htx5BMjdJvjm5Bf9cuDypP1S4BZJ1yXruKCIwzArmO8+alYgSVsi4qBS12HW2nxoyMws47xHYGaWcd4jMDPLOAeBmVnGOQjMzDLOQWBmlnEOAjOzjPv/MsiVm7y4NokAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rqQH0IP5PKUa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SsAfPaPxPKUd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k5CX9GzmPKUq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}