{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Идея заключается в том, чтобы в качестве свертки использовать не случайно инициализированную матрицу,  а матрицу посчитанную по всей трейн выборке с использованием PCA\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Статья: **Image noise types recognition using CNN with PCA**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](img/pcanet.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0. все изображения привести к виду (m, m) \n",
    "\n",
    "1. Пусть у нас N изображений каждая (m, m). Вытаскиваем из одного изображения патчи размера $(k_a, k_a)$ вокруг каждого пикселя со stride = 1 на $a$ той итерации. \n",
    "\n",
    "2. Центрируем патчи: для каждого патча вычисляем среднее и вычитаем из каждого элемента патча среднее значение, для i-того изображения:\n",
    "$\\overline{X_i} = [\\overline{x_1}, ..., \\overline{x_N}] \\subset \\mathbb{R}^{k^2 x m^2}$\n",
    "\n",
    "3. Проделываем это для N обучающих изображений: $X = [\\overline{X_1}, ..., \\overline{X_N}] \\subset \\mathbb{R}^{k^2 x Nm^2}$\n",
    "\n",
    "4. для $ XX^T$ находим L **первых собственных векторов**, каждый из которых имеет размерность $ \\mathbb{R}^{k^2}$, после этого делаем reshape до $ \\mathbb{R}^{k x k}$ и получаем L искомых фильтров"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Важно учесть, что первый фильтр работает с изображениями напрямую -> его можно просчитать заранее, в то время как остальные фильтры готовятся после предыдущего слоя!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1,  2,  3,  4],\n",
       "       [ 5,  6,  7,  8,  9],\n",
       "       [10, 11, 12, 13, 14],\n",
       "       [15, 16, 17, 18, 19]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_image = np.arange(20).reshape(4,5)\n",
    "test_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  1,  2,  3,  4,  0,  0,  0],\n",
       "       [ 0,  0,  0,  5,  6,  7,  8,  9,  0,  0,  0],\n",
       "       [ 0,  0,  0, 10, 11, 12, 13, 14,  0,  0,  0],\n",
       "       [ 0,  0,  0, 15, 16, 17, 18, 19,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.pad(test_image, (3, 3), 'constant', constant_values=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  0  0  0  0  0  0]\n",
      " [ 0  0  1  2  3  4  0]\n",
      " [ 0  5  6  7  8  9  0]\n",
      " [ 0 10 11 12 13 14  0]\n",
      " [ 0 15 16 17 18 19  0]\n",
      " [ 0  0  0  0  0  0  0]]\n",
      "[[0 0 0]\n",
      " [0 0 1]\n",
      " [0 5 6]]\n",
      "\n",
      "[[0 0 0]\n",
      " [0 1 2]\n",
      " [5 6 7]]\n",
      "\n",
      "[[0 0 0]\n",
      " [1 2 3]\n",
      " [6 7 8]]\n",
      "\n",
      "[[0 0 0]\n",
      " [2 3 4]\n",
      " [7 8 9]]\n",
      "\n",
      "[[0 0 0]\n",
      " [3 4 0]\n",
      " [8 9 0]]\n",
      "\n",
      "[[ 0  0  1]\n",
      " [ 0  5  6]\n",
      " [ 0 10 11]]\n",
      "\n",
      "[[ 0  1  2]\n",
      " [ 5  6  7]\n",
      " [10 11 12]]\n",
      "\n",
      "[[ 1  2  3]\n",
      " [ 6  7  8]\n",
      " [11 12 13]]\n",
      "\n",
      "[[ 2  3  4]\n",
      " [ 7  8  9]\n",
      " [12 13 14]]\n",
      "\n",
      "[[ 3  4  0]\n",
      " [ 8  9  0]\n",
      " [13 14  0]]\n",
      "\n",
      "[[ 0  5  6]\n",
      " [ 0 10 11]\n",
      " [ 0 15 16]]\n",
      "\n",
      "[[ 5  6  7]\n",
      " [10 11 12]\n",
      " [15 16 17]]\n",
      "\n",
      "[[ 6  7  8]\n",
      " [11 12 13]\n",
      " [16 17 18]]\n",
      "\n",
      "[[ 7  8  9]\n",
      " [12 13 14]\n",
      " [17 18 19]]\n",
      "\n",
      "[[ 8  9  0]\n",
      " [13 14  0]\n",
      " [18 19  0]]\n",
      "\n",
      "[[ 0 10 11]\n",
      " [ 0 15 16]\n",
      " [ 0  0  0]]\n",
      "\n",
      "[[10 11 12]\n",
      " [15 16 17]\n",
      " [ 0  0  0]]\n",
      "\n",
      "[[11 12 13]\n",
      " [16 17 18]\n",
      " [ 0  0  0]]\n",
      "\n",
      "[[12 13 14]\n",
      " [17 18 19]\n",
      " [ 0  0  0]]\n",
      "\n",
      "[[13 14  0]\n",
      " [18 19  0]\n",
      " [ 0  0  0]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 1: get patches k x k, где k - НЕЧЕТНЫЕ, чтобы можно было приложить к центру изображения\n",
    "# TO DO: написать тесты\n",
    "\n",
    "def get_patches(k, image) -> np.ndarray:\n",
    "    padded_image = np.pad(image, (k // 2, k // 2), 'constant', constant_values=0) # можно не 0\n",
    "    \n",
    "    print(padded_image)\n",
    "    for i in range(image.shape[0]):\n",
    "        for j in range(image.shape[1]):\n",
    "            patch = padded_image[i:i+k, j:j+k]\n",
    "            print(patch)\n",
    "            print()\n",
    "            \n",
    "get_patches(3, test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 20)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_centered_patches(k, image) -> np.ndarray:\n",
    "    padded_image = np.pad(image, (k // 2, k // 2), 'constant', constant_values=0) # можно не 0\n",
    "    X_im = []\n",
    "    # print(padded_image)\n",
    "    for i in range(image.shape[0]):\n",
    "        for j in range(image.shape[1]):\n",
    "            patch_matrix = padded_image[i:i+k, j:j+k]\n",
    "            patch_vector = (patch_matrix.flatten()).astype(np.float32)\n",
    "            #mean = np.mean(patch_vector)\n",
    "            #patch_vector -= mean\n",
    "            #print(patch_vector)\n",
    "            X_im.append(patch_vector)\n",
    "    return np.array(X_im).T\n",
    "\n",
    "            \n",
    "get_centered_patches(3, test_image).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: проделать это с N изображениями, и собрать единую ДВУМЕРНУЮ матрицу\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2]\n",
      " [3 4]]\n",
      "\n",
      "[[5 6]\n",
      " [7 8]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 5, 6],\n",
       "       [3, 4, 7, 8]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# numpy concatenate вроде как самый быстрый вариант, так как нужно будет это сделать для N изображений, где N - большое число\n",
    "\n",
    "a = np.array([[1, 2], [3, 4]])\n",
    "b = np.array([[5, 6], [7, 8]])\n",
    "print(a)\n",
    "print()\n",
    "print(b)\n",
    "np.concatenate((a,b), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9, 2457600)\n",
      "         41807441 function calls (41806241 primitive calls) in 54.812 seconds\n",
      "\n",
      "   Ordered by: standard name\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "      600    0.001    0.000    0.005    0.000 <__array_function__ internals>:2(around)\n",
      "  2457600    1.591    0.000   35.796    0.000 <__array_function__ internals>:2(mean)\n",
      "      600    0.001    0.000    0.056    0.000 <__array_function__ internals>:2(pad)\n",
      "      600    0.001    0.000    0.007    0.000 <__array_function__ internals>:2(round_)\n",
      "      600   12.196    0.020   54.199    0.090 <ipython-input-72-9cbab2703260>:1(get_centered_patches)\n",
      "        1    0.000    0.000   54.812   54.812 <string>:1(<module>)\n",
      "        1    0.584    0.584   54.812   54.812 <timed exec>:3(compute_n_images)\n",
      "     1200    0.001    0.000    0.004    0.000 _asarray.py:16(asarray)\n",
      "  2457600    0.672    0.000    1.382    0.000 _asarray.py:88(asanyarray)\n",
      "  2457600   16.787    0.000   29.157    0.000 _methods.py:134(_mean)\n",
      "  2457600    3.090    0.000    3.365    0.000 _methods.py:50(_count_reduce_items)\n",
      "     1800    0.002    0.000    0.002    0.000 arraypad.py:112(<genexpr>)\n",
      "     1800    0.001    0.000    0.001    0.000 arraypad.py:123(<genexpr>)\n",
      "     1200    0.005    0.000    0.007    0.000 arraypad.py:131(_set_pad_area)\n",
      "     2400    0.001    0.000    0.001    0.000 arraypad.py:35(_slice_at_axis)\n",
      "     1200    0.006    0.000    0.016    0.000 arraypad.py:459(_as_pairs)\n",
      "      600    0.000    0.000    0.000    0.000 arraypad.py:526(_pad_dispatcher)\n",
      "      600    0.012    0.000    0.052    0.000 arraypad.py:534(pad)\n",
      "     1200    0.002    0.000    0.002    0.000 arraypad.py:60(_view_roi)\n",
      "      600    0.008    0.000    0.012    0.000 arraypad.py:88(_pad_simple)\n",
      "     1200    0.000    0.000    0.000    0.000 fromnumeric.py:3126(_around_dispatcher)\n",
      "      600    0.001    0.000    0.003    0.000 fromnumeric.py:3130(around)\n",
      "  2457600    0.355    0.000    0.355    0.000 fromnumeric.py:3227(_mean_dispatcher)\n",
      "  2457600    3.293    0.000   32.450    0.000 fromnumeric.py:3231(mean)\n",
      "      600    0.001    0.000    0.005    0.000 fromnumeric.py:3590(round_)\n",
      "      600    0.001    0.000    0.002    0.000 fromnumeric.py:55(_wrapfunc)\n",
      "        3    0.000    0.000    0.000    0.000 iostream.py:197(schedule)\n",
      "        2    0.000    0.000    0.000    0.000 iostream.py:309(_is_master_process)\n",
      "        2    0.000    0.000    0.000    0.000 iostream.py:322(_schedule_flush)\n",
      "        2    0.000    0.000    0.000    0.000 iostream.py:384(write)\n",
      "        3    0.000    0.000    0.000    0.000 iostream.py:93(_event_pipe)\n",
      "        3    0.000    0.000    0.000    0.000 socket.py:342(send)\n",
      "        3    0.000    0.000    0.000    0.000 threading.py:1050(_wait_for_tstate_lock)\n",
      "        3    0.000    0.000    0.000    0.000 threading.py:1092(is_alive)\n",
      "        3    0.000    0.000    0.000    0.000 threading.py:507(is_set)\n",
      "      600    0.000    0.000    0.000    0.000 {built-in method builtins.callable}\n",
      "        1    0.000    0.000   54.812   54.812 {built-in method builtins.exec}\n",
      "      600    0.000    0.000    0.000    0.000 {built-in method builtins.getattr}\n",
      "  2457600    0.563    0.000    0.563    0.000 {built-in method builtins.hasattr}\n",
      "  4915202    0.709    0.000    0.709    0.000 {built-in method builtins.isinstance}\n",
      "  4915200    0.612    0.000    0.612    0.000 {built-in method builtins.issubclass}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method builtins.print}\n",
      "  2460600    1.568    0.000    1.568    0.000 {built-in method numpy.array}\n",
      "2459400/2458200    1.403    0.000   33.905    0.000 {built-in method numpy.core._multiarray_umath.implement_array_function}\n",
      "      600    0.001    0.000    0.001    0.000 {built-in method numpy.empty}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method numpy.zeros}\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method posix.getpid}\n",
      "        3    0.000    0.000    0.000    0.000 {method 'acquire' of '_thread.lock' objects}\n",
      "        3    0.000    0.000    0.000    0.000 {method 'append' of 'collections.deque' objects}\n",
      "  2457600    0.282    0.000    0.282    0.000 {method 'append' of 'list' objects}\n",
      "  2458200    2.056    0.000    2.056    0.000 {method 'astype' of 'numpy.ndarray' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "  2457600    2.961    0.000    2.961    0.000 {method 'flatten' of 'numpy.ndarray' objects}\n",
      "      600    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}\n",
      "      600    0.028    0.000    0.028    0.000 {method 'rand' of 'numpy.random.mtrand.RandomState' objects}\n",
      "     1200    0.001    0.000    0.001    0.000 {method 'ravel' of 'numpy.ndarray' objects}\n",
      "  2457600    6.013    0.000    6.013    0.000 {method 'reduce' of 'numpy.ufunc' objects}\n",
      "      600    0.001    0.000    0.001    0.000 {method 'round' of 'numpy.ndarray' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'seed' of 'numpy.random.mtrand.RandomState' objects}\n",
      "\n",
      "\n",
      "CPU times: user 54.6 s, sys: 118 ms, total: 54.8 s\n",
      "Wall time: 54.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import cProfile\n",
    "\n",
    "def compute_n_images():\n",
    "    k = 3\n",
    "    N = 600\n",
    "    m = 64\n",
    "\n",
    "    np.random.seed(0)\n",
    "\n",
    "    all_patches = np.zeros((k ** 2, N * m ** 2))\n",
    "    for i in range(N):\n",
    "        #image_arr = Image.open()\n",
    "        #gray = to_gray(image_arr)\n",
    "        gray_im = np.random.rand(m, m)\n",
    "        image_patches = get_centered_patches_profiled(k, gray_im) # k ** 2 x m ** 2\n",
    "        #print(image_patches)\n",
    "        # print(image_patches.shape, m**2)\n",
    "        all_patches[:, i:i+m**2] = image_patches\n",
    "\n",
    "    print(all_patches.shape)\n",
    "    #print(all_patches)\n",
    "    #del all_patches\n",
    "\n",
    "cProfile.run('compute_n_images()')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_centered_patches_profiled(k, image) -> np.ndarray:\n",
    "    padded_image = np.pad(image, (k // 2, k // 2), 'constant', constant_values=0) # можно не 0\n",
    "    X_im = []\n",
    "    #padded_image.astype(np.float32)\n",
    "    # print(padded_image)\n",
    "    for i in range(image.shape[0]):\n",
    "        for j in range(image.shape[1]):\n",
    "            patch_matrix = padded_image[i:i+k, j:j+k]\n",
    "            X_im.append(patch_matrix)\n",
    "\n",
    "    X_im = np.array(X_im, dtype=np.float32).T # k x k x m^2\n",
    "    X_im = X_im.reshape(-1, X_im.shape[2])\n",
    "    patch_mean = np.mean(X_im, axis=0)\n",
    "\n",
    "    X_im -= patch_mean.reshape(-1, patch_mean.shape[0])\n",
    "    return X_im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matprint(mat, fmt=\"g\"):\n",
    "    col_maxes = [max([len((\"{:\"+fmt+\"}\").format(x)) for x in col]) for col in mat.T]\n",
    "    for x in mat:\n",
    "        for i, y in enumerate(x):\n",
    "            print((\"{:\"+str(col_maxes[i])+fmt+\"}\").format(y), end=\"  \")\n",
    "        print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  0  0  0  0   0   0   1   2   3   0   5   6   7   8   0  10  11  12  13  \n",
      "0  0  1  2  3   0   5   6   7   8   0  10  11  12  13   0  15  16  17  18  \n",
      "0  5  6  7  8   0  10  11  12  13   0  15  16  17  18   0   0   0   0   0  \n",
      "0  0  0  0  0   0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  \n",
      "0  1  2  3  4   5   6   7   8   9  10  11  12  13  14  15  16  17  18  19  \n",
      "5  6  7  8  9  10  11  12  13  14  15  16  17  18  19   0   0   0   0   0  \n",
      "0  0  0  0  0   1   2   3   4   0   6   7   8   9   0  11  12  13  14   0  \n",
      "1  2  3  4  0   6   7   8   9   0  11  12  13  14   0  16  17  18  19   0  \n",
      "6  7  8  9  0  11  12  13  14   0  16  17  18  19   0   0   0   0   0   0  \n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(precision=2)\n",
    "patches1 = get_centered_patches_profiled(3, test_image)\n",
    "matprint(patches1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  0  0  0  0   0   0   1   2   3   0   5   6   7   8   0  10  11  12  13  \n",
      "0  0  0  0  0   0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  \n",
      "0  0  0  0  0   1   2   3   4   0   6   7   8   9   0  11  12  13  14   0  \n",
      "0  0  1  2  3   0   5   6   7   8   0  10  11  12  13   0  15  16  17  18  \n",
      "0  1  2  3  4   5   6   7   8   9  10  11  12  13  14  15  16  17  18  19  \n",
      "1  2  3  4  0   6   7   8   9   0  11  12  13  14   0  16  17  18  19   0  \n",
      "0  5  6  7  8   0  10  11  12  13   0  15  16  17  18   0   0   0   0   0  \n",
      "5  6  7  8  9  10  11  12  13  14  15  16  17  18  19   0   0   0   0   0  \n",
      "6  7  8  9  0  11  12  13  14   0  16  17  18  19   0   0   0   0   0   0  \n"
     ]
    }
   ],
   "source": [
    "patches2 = get_centered_patches(3, test_image)\n",
    "matprint(patches2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-5.29819069e-08,  1.05963814e-07,  0.00000000e+00, -1.58945724e-07,\n",
       "       -1.85436676e-07, -1.05963814e-07,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  2.64909545e-07,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  1.05963814e-07,\n",
       "        0.00000000e+00, -3.17891448e-07,  3.17891448e-07, -5.29819069e-08],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patches2.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 5. 0. 1. 6. 0. 2. 7.]\n"
     ]
    }
   ],
   "source": [
    "print(patches1[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 1. 2. 5. 6. 7.]\n"
     ]
    }
   ],
   "source": [
    "print(patches2[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9, 2457600)\n",
      "         2494841 function calls (2493641 primitive calls) in 2.968 seconds\n",
      "\n",
      "   Ordered by: standard name\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "      600    0.001    0.000    0.003    0.000 <__array_function__ internals>:2(around)\n",
      "      600    0.001    0.000    0.030    0.000 <__array_function__ internals>:2(mean)\n",
      "      600    0.001    0.000    0.047    0.000 <__array_function__ internals>:2(pad)\n",
      "      600    0.001    0.000    0.005    0.000 <__array_function__ internals>:2(round_)\n",
      "      600    1.626    0.003    2.922    0.005 <ipython-input-137-b873b8a1d142>:1(get_centered_patches_profiled)\n",
      "        1    0.000    0.000    2.968    2.968 <string>:1(<module>)\n",
      "        1    0.020    0.020    2.968    2.968 <timed exec>:3(compute_n_images)\n",
      "     1200    0.000    0.000    0.003    0.000 _asarray.py:16(asarray)\n",
      "      600    0.000    0.000    0.001    0.000 _asarray.py:88(asanyarray)\n",
      "      600    0.011    0.000    0.025    0.000 _methods.py:134(_mean)\n",
      "      600    0.001    0.000    0.002    0.000 _methods.py:50(_count_reduce_items)\n",
      "     1800    0.001    0.000    0.001    0.000 arraypad.py:112(<genexpr>)\n",
      "     1800    0.001    0.000    0.001    0.000 arraypad.py:123(<genexpr>)\n",
      "     1200    0.005    0.000    0.006    0.000 arraypad.py:131(_set_pad_area)\n",
      "     2400    0.001    0.000    0.001    0.000 arraypad.py:35(_slice_at_axis)\n",
      "     1200    0.005    0.000    0.013    0.000 arraypad.py:459(_as_pairs)\n",
      "      600    0.000    0.000    0.000    0.000 arraypad.py:526(_pad_dispatcher)\n",
      "      600    0.009    0.000    0.044    0.000 arraypad.py:534(pad)\n",
      "     1200    0.002    0.000    0.002    0.000 arraypad.py:60(_view_roi)\n",
      "      600    0.006    0.000    0.010    0.000 arraypad.py:88(_pad_simple)\n",
      "     1200    0.000    0.000    0.000    0.000 fromnumeric.py:3126(_around_dispatcher)\n",
      "      600    0.001    0.000    0.002    0.000 fromnumeric.py:3130(around)\n",
      "      600    0.000    0.000    0.000    0.000 fromnumeric.py:3227(_mean_dispatcher)\n",
      "      600    0.002    0.000    0.028    0.000 fromnumeric.py:3231(mean)\n",
      "      600    0.001    0.000    0.004    0.000 fromnumeric.py:3590(round_)\n",
      "      600    0.001    0.000    0.001    0.000 fromnumeric.py:55(_wrapfunc)\n",
      "        3    0.000    0.000    0.000    0.000 iostream.py:197(schedule)\n",
      "        2    0.000    0.000    0.000    0.000 iostream.py:309(_is_master_process)\n",
      "        2    0.000    0.000    0.000    0.000 iostream.py:322(_schedule_flush)\n",
      "        2    0.000    0.000    0.000    0.000 iostream.py:384(write)\n",
      "        3    0.000    0.000    0.000    0.000 iostream.py:93(_event_pipe)\n",
      "        3    0.000    0.000    0.000    0.000 socket.py:342(send)\n",
      "        3    0.000    0.000    0.000    0.000 threading.py:1050(_wait_for_tstate_lock)\n",
      "        3    0.000    0.000    0.000    0.000 threading.py:1092(is_alive)\n",
      "        3    0.000    0.000    0.000    0.000 threading.py:507(is_set)\n",
      "      600    0.000    0.000    0.000    0.000 {built-in method builtins.callable}\n",
      "        1    0.000    0.000    2.968    2.968 {built-in method builtins.exec}\n",
      "      600    0.000    0.000    0.000    0.000 {built-in method builtins.getattr}\n",
      "     1202    0.000    0.000    0.000    0.000 {built-in method builtins.isinstance}\n",
      "     1200    0.000    0.000    0.000    0.000 {built-in method builtins.issubclass}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method builtins.print}\n",
      "     3600    1.055    0.000    1.055    0.000 {built-in method numpy.array}\n",
      "2400/1200    0.004    0.000    0.074    0.000 {built-in method numpy.core._multiarray_umath.implement_array_function}\n",
      "      600    0.001    0.000    0.001    0.000 {built-in method numpy.empty}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method numpy.zeros}\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method posix.getpid}\n",
      "        3    0.000    0.000    0.000    0.000 {method 'acquire' of '_thread.lock' objects}\n",
      "        3    0.000    0.000    0.000    0.000 {method 'append' of 'collections.deque' objects}\n",
      "  2457600    0.150    0.000    0.150    0.000 {method 'append' of 'list' objects}\n",
      "      600    0.001    0.000    0.001    0.000 {method 'astype' of 'numpy.ndarray' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "      600    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}\n",
      "      600    0.026    0.000    0.026    0.000 {method 'rand' of 'numpy.random.mtrand.RandomState' objects}\n",
      "     1200    0.001    0.000    0.001    0.000 {method 'ravel' of 'numpy.ndarray' objects}\n",
      "      600    0.012    0.000    0.012    0.000 {method 'reduce' of 'numpy.ufunc' objects}\n",
      "     1200    0.019    0.000    0.019    0.000 {method 'reshape' of 'numpy.ndarray' objects}\n",
      "      600    0.001    0.000    0.001    0.000 {method 'round' of 'numpy.ndarray' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'seed' of 'numpy.random.mtrand.RandomState' objects}\n",
      "\n",
      "\n",
      "CPU times: user 2.97 s, sys: 19.6 ms, total: 2.99 s\n",
      "Wall time: 2.99 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import cProfile\n",
    "\n",
    "def compute_n_images():\n",
    "    k = 3\n",
    "    N = 600\n",
    "    m = 64\n",
    "\n",
    "    np.random.seed(0)\n",
    "\n",
    "    all_patches = np.zeros((k ** 2, N * m ** 2))\n",
    "    for i in range(N):\n",
    "        #image_arr = Image.open()\n",
    "        #gray = to_gray(image_arr)\n",
    "        gray_im = np.random.rand(m, m)\n",
    "        image_patches = get_centered_patches_profiled(k, gray_im) # k ** 2 x m ** 2\n",
    "        #print(image_patches)\n",
    "        # print(image_patches.shape, m**2)\n",
    "        all_patches[:, i:i+m**2] = image_patches\n",
    "\n",
    "    print(all_patches.shape)\n",
    "    \n",
    "    return all_patches\n",
    "\n",
    "cProfile.run('compute_n_images()')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9, 2457600)\n"
     ]
    }
   ],
   "source": [
    "all_patches = compute_n_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = all_patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step4: Извлечение фильтров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import IncrementalPCA\n",
    "n_filters = 8\n",
    "pca = PCA(n_components=n_filters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3 µs, sys: 0 ns, total: 3 µs\n",
      "Wall time: 6.91 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PCA(copy=True, iterated_power='auto', n_components=8, random_state=None,\n",
       "    svd_solver='auto', tol=0.0, whiten=False)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time\n",
    "pca.fit(X @ X.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.32, -0.3 , -0.29, -0.31,  0.37,  0.35, -0.26,  0.38,  0.39],\n",
       "       [-0.02, -0.02,  0.04,  0.02,  0.56,  0.45, -0.06, -0.42, -0.55],\n",
       "       [-0.06,  0.04,  0.29, -0.13, -0.42,  0.52, -0.17, -0.5 ,  0.42],\n",
       "       [ 0.1 , -0.17, -0.18, -0.17, -0.45,  0.5 ,  0.42,  0.34, -0.39],\n",
       "       [ 0.15,  0.59,  0.17, -0.45, -0.06,  0.04, -0.49,  0.3 , -0.25],\n",
       "       [ 0.7 ,  0.08, -0.61, -0.16,  0.06,  0.02, -0.03, -0.25,  0.2 ],\n",
       "       [-0.26,  0.3 ,  0.01, -0.6 ,  0.19, -0.16,  0.61, -0.21,  0.12],\n",
       "       [-0.45,  0.57, -0.53,  0.4 , -0.12,  0.16, -0.  , -0.04,  0.01]])"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# получаем таблицу - строка - номер фильтра, столбцы - flattend фильтр\n",
    "pca.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.32, -0.3 , -0.29],\n",
       "       [-0.31,  0.37,  0.35],\n",
       "       [-0.26,  0.38,  0.39]])"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_eigenvector = pca.components_[0].reshape(3,3)\n",
    "first_eigenvector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Архитектура будет следующей:\n",
    "1. этап - прохожусь по всем изображениям, формирую фильтры, пропускаю все изображения через эти фильтры (свертка), могу пересохранять в те же pickle на каждом этапе, например.\n",
    "Отдельно stage1, отдельно все остальные этапы:\n",
    "Для каждого нового этапа - свертка + maxpooling.\n",
    "1. прохожусь по всему train датасету, формирую фильтры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PCAFilter(filter_size, n_channels, im_size):\n",
    "    def __init__(self,):\n",
    "        self.pca = PCA(n_channels)\n",
    "        self.filter_size = filter_size\n",
    "        self.im_size = im_size\n",
    "        self.n_channels = n_channels\n",
    "        self.filters = None\n",
    "    \n",
    "    # возможно не train_paths, а train_dataset\n",
    "    def get_stage1_filters(self, train_paths):\n",
    "        N = len(train_paths)\n",
    "        m = self.im_size\n",
    "        k = self.filter_size\n",
    "        \n",
    "        # all patches of all images\n",
    "        X = np.zeros((k ** 2, N * m ** 2))\n",
    "        # заполняем матрицу, от одного изображения (k^2 x m^2), поэтому i:i+m**2\n",
    "        for i, path in enumerate(train_paths):\n",
    "            image_array = load_image(path) ########\n",
    "            image_array = image_array.resize((m, m)) ##########\n",
    "            im_patches = self.get_centered_patches(image_array)\n",
    "            X[:, i:i+m**2] = im_patches\n",
    "        \n",
    "        self.pca.fit(X @ X.T) # for incrementalPCA - partial_fit\n",
    "        \n",
    "        filters = np.zeros((n_channels, k, k))\n",
    "        \n",
    "        for i in range(n_channels):\n",
    "            filters[i, :, :] = self.pca.components_[i].reshape(k, k)\n",
    "        \n",
    "        self.filters = filters\n",
    "            \n",
    "    def get_centered_patches(self, image) -> np.ndarray:\n",
    "        k = self.filter_size\n",
    "        # по краям добавим k // 2 ячеек с нулями\n",
    "        padded_image = np.pad(image, (k // 2, k // 2), 'constant', constant_values=0) # можно не 0\n",
    "        patches = []\n",
    "\n",
    "        for i in range(image.shape[0]):\n",
    "            for j in range(image.shape[1]):\n",
    "                patch_matrix = padded_image[i:i+k, j:j+k]\n",
    "                patches.append(patch_matrix)\n",
    "\n",
    "        patches = np.array(patches, dtype=np.float32).T # k x k x m^2\n",
    "        patches = patches.reshape(-1, X_im.shape[2]) # k^2 x m^2\n",
    "        \n",
    "        patch_mean = np.mean(patches, axis=0)\n",
    "        patches -= patch_mean.reshape(-1, patch_mean.shape[0])\n",
    "        return patches  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1,  2,  3,  4],\n",
       "       [ 5,  6,  7,  8,  9],\n",
       "       [10, 11, 12, 13, 14],\n",
       "       [15, 16, 17, 18, 19]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  1,  2,  3,  4,  0],\n",
       "       [ 0,  5,  6,  7,  8,  9,  0],\n",
       "       [ 0, 10, 11, 12, 13, 14,  0],\n",
       "       [ 0, 15, 16, 17, 18, 19,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pad1_im = np.pad(test_image, (1, 1), 'constant', constant_values=0)\n",
    "pad1_im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kernel = np.eye(3)\n",
    "kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Займемся конволюцией:\n",
    "from scipy import signal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 6.,  8., 10., 12.,  4.],\n",
       "       [16., 18., 21., 24., 12.],\n",
       "       [26., 33., 36., 39., 22.],\n",
       "       [15., 26., 28., 30., 32.]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signal.convolve2d(pad1_im, kernel, mode='valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 6.,  8., 10., 12.,  4.],\n",
       "       [16., 18., 21., 24., 12.],\n",
       "       [26., 33., 36., 39., 22.],\n",
       "       [15., 26., 28., 30., 32.]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signal.convolve2d(test_image, kernel, mode='same')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import savez_compressed\n",
    "\n",
    "def convolution(filters, image, src_path, pad_size=(1, 1)):\n",
    "    h_in, w_in = image.shape\n",
    "    nchannels = filters.shape[0]\n",
    "    kernel_size = filters.shape[1:]\n",
    "    print(kernel_size)\n",
    "    \n",
    "    h_out = int((h_in + 2 * pad_size[0] - (kernel_size[0] - 1) - 1) + 1)\n",
    "    w_out = int((w_in + 2 * pad_size[1] - (kernel_size[1] - 1) - 1) + 1)\n",
    "    \n",
    "    print(image.shape, h_out, w_out)\n",
    "    print(image)\n",
    "    \n",
    "    features_map = np.zeros((nchannels, h_out, w_out))\n",
    "    for ch in range(nchannels):\n",
    "        kernel = filters[ch]\n",
    "        padded_image = np.pad(image, pad_size, 'constant', constant_values=0)\n",
    "        features_map[ch, :, :] = signal.convolve2d(padded_image, kernel, mode='valid')\n",
    "    print()\n",
    "    print(features_map)\n",
    "    #for i, path in enumerate(train_paths):\n",
    "    #    image = cv2.imread(path, 0)\n",
    "    #    for ch in range(nchannels):\n",
    "    #        kernel = filters[ch]\n",
    "    #        padded_image = np.pad(image, pad_size, 'constant', constant_values=0)\n",
    "    #        features_map[ch, :, :] = signal.convelve2d(padded_image, kernel, mode='valid')\n",
    "        # save features_map\n",
    "    #savez_compressed(src_path + '.npz', features_map)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 0., 1.]],\n",
       "\n",
       "       [[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 1.]]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filters = np.array([np.eye(3), [[0, 0, 0], [0, 0, 0], [0, 0, 1]]])\n",
    "filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 3)\n",
      "(4, 5) 2 3\n",
      "[[ 0  1  2  3  4]\n",
      " [ 5  6  7  8  9]\n",
      " [10 11 12 13 14]\n",
      " [15 16 17 18 19]]\n",
      "\n",
      "[[[18. 21. 24.]\n",
      "  [33. 36. 39.]]\n",
      "\n",
      " [[ 0.  1.  2.]\n",
      "  [ 5.  6.  7.]]]\n"
     ]
    }
   ],
   "source": [
    "convolution(filters, test_image, '1', (0, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn.functional import conv2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0,  1,  2,  3,  4],\n",
       "          [ 5,  6,  7,  8,  9],\n",
       "          [10, 11, 12, 13, 14],\n",
       "          [15, 16, 17, 18, 19]]]])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 0., 1.]],\n",
       "\n",
       "       [[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 1.]]])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(tensor, 'file.pt') and torch.load('file.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[1, 0, 0],\n",
       "          [0, 1, 0],\n",
       "          [0, 0, 1]]],\n",
       "\n",
       "\n",
       "        [[[0, 0, 0],\n",
       "          [0, 0, 0],\n",
       "          [0, 0, 1]]]])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = torch.LongTensor(filters)\n",
    "weights = weights.view(2, 1, 3, 3)\n",
    "weights.shape\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 4, 5])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image = torch.from_numpy(test_image)\n",
    "image = image.view(1, 1, *test_image.shape)\n",
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 3, 3])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 2, 3])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2d(image, weights).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torchvision import transforms, models\n",
    "\n",
    "# from PIL import Image\n",
    "# from colour_demosaicing import demosaicing_CFA_Bayer_Menon2007"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from sklearn.decomposition import PCA, IncrementalPCA\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torchvision import transforms, models\n",
    "\n",
    "\n",
    "class PCANet(torch.nn.Module):\n",
    "    def __init__(self, num_filters: list, filters_sizes: list, batch_size=256):\n",
    "        self.params = {\n",
    "            'num_filters': num_filters,\n",
    "            'filters_sizes': filters_sizes,\n",
    "        }\n",
    "        self.W_1 = None\n",
    "        self.W_2 = None\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.conv2d(x, self.W_1)\n",
    "        N, C, H, W = x.shape\n",
    "        x = x.view(-1, 1, H, W)\n",
    "        \n",
    "        x = F.conv2d(x, self.W_2)\n",
    "        N, C, H, W = x.shape\n",
    "        x = x.view(N*C, H, W)\n",
    "        \n",
    "        x_flat = x.view(N*C, H*W)\n",
    "        print(\"N = {}, C = {}, H = {}, W = {}\".format(N, C, H, W), x_flat.shape)\n",
    "        x_flat = torch.nn.Linear(H*W, 2, bias=True)(x_flat)\n",
    "        return x_flat\n",
    "            \n",
    "    @staticmethod        \n",
    "    def _extract_image_patches(imgs: torch.Tensor, filter_size, stride=1, remove_mean=True):\n",
    "        # imgs.shape = (N, C, H, W) -> (N, 1, H, W) \n",
    "        # так должно быть, но сюда могут прийти не grayscale изображения первого шага, а со второго\n",
    "        # на котором применено L1 фильтров -> L1 каналов\n",
    "        N, n_channels, H, W = imgs.shape\n",
    "        \n",
    "        if n_channels > 1:\n",
    "            # изображение вида (N, C, H, W) - N C-канальных изображений\n",
    "            # приводим к виду (N*C, 1, H, W) - N*C одно-канальных изображений\n",
    "            imgs = imgs.view(-1, 1, H, W)\n",
    "        print('images shape', imgs.shape)\n",
    "            \n",
    "        k = filter_size\n",
    "        patches = torch.nn.functional.unfold(imgs, k, padding=k//2) # (N, k^2, H*W)\n",
    "        print('patches_shape, ', patches.shape)\n",
    "        print('should be patches shape, ', (imgs.shape[0], k**2, H*W))\n",
    "        \n",
    "        if remove_mean:\n",
    "            patches -= patches.mean(dim=1, keepdim=True) # последнее измерение - количество патчей\n",
    "        \n",
    "        print('filter_size', k)\n",
    "        X = patches.view(k**2, -1) # (k^2, N*H*W)\n",
    "\n",
    "        return X\n",
    "    \n",
    "    def _convolve(self, imgs: torch.Tensor, filter_bank: torch.Tensor) -> torch.Tensor:\n",
    "        weight = filter_bank\n",
    "        output = F.conv2d(imgs, weight) #, padding=padding)\n",
    "        return output\n",
    "    \n",
    "    def _first_stage(self, imgs: torch.Tensor, train: bool) -> torch.Tensor:\n",
    "        # (N, C, H, W) image\n",
    "        # (train_size, 1, H, W) - grayscale\n",
    "        assert imgs.dim() == 4 and imgs.nelement() > 0\n",
    "\n",
    "        print('PCANet first stage...')\n",
    "\n",
    "        if train:\n",
    "            # достаем все патчи из всех N изображений\n",
    "            filter_size1 = self.params['filters_sizes'][0]\n",
    "            X = self._extract_image_patches(\n",
    "                imgs, filter_size1)\n",
    "            \n",
    "            n_filters = self.params['num_filters'][0]\n",
    "            \n",
    "            eigenvectors = self.get_pca_eigenvectors(X, n_components=n_filters, batch_size=self.batch_size)\n",
    "            self.W_1 = torch.FloatTensor(eigenvectors).view(n_filters, 1, filter_size1, filter_size1)\n",
    "         \n",
    "        I = self._convolve(imgs, self.W_1)  # (N, 1, H, W) * (L1, k1, k1) -> (N, L1, H', W')\n",
    "        return I\n",
    "    \n",
    "    @staticmethod\n",
    "    def conv_output_size(w, filter_size, padding=0, stride=1):\n",
    "        return int((w - filter_size + 2 * padding) / stride + 1)\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_pca_eigenvectors(X, n_components, batch_size=100):\n",
    "        ipca = IncrementalPCA(n_components=n_components, batch_size=batch_size)\n",
    "        print('pca fitting ...')\n",
    "        ipca.fit(X @ X.t())\n",
    "        eigenvectors = ipca.components_\n",
    "        print('eigenvectors shape:', eigenvectors.shape)\n",
    "        return eigenvectors\n",
    "        \n",
    "    def _second_stage(self, I: torch.Tensor, train):\n",
    "        print('PCANet second stage...')\n",
    "        # I: (N, L1, H, W)\n",
    "        if train:\n",
    "            N, L1, H, W = I.shape\n",
    "            I = I.view(-1, 1, H, W)\n",
    "            filter_size2 = self.params['filters_sizes'][1]\n",
    "            n_filters = self.params['num_filters'][1]\n",
    "            \n",
    "            H_new = self.conv_output_size(I.shape[2], filter_size2)\n",
    "            W_new = self.conv_output_size(I.shape[3], filter_size2)\n",
    "            \n",
    "            X = self._extract_image_patches(I, filter_size2)\n",
    "            print('X_SHAPE ', X.shape)\n",
    "            eigenvectors = self.get_pca_eigenvectors(X, n_components=n_filters, batch_size=self.batch_size)\n",
    "            self.W_2 = torch.FloatTensor(eigenvectors).view(n_filters, 1, filter_size2, filter_size2)\n",
    "        return self._convolve(I, self.W_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num_filters': [8, 8], 'filters_sizes': [5, 3]}"
      ]
     },
     "execution_count": 445,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = PCANet([8, 8],[5, 3])\n",
    "net.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = torch.randn(10, 1, 10, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCANet first stage...\n",
      "images shape torch.Size([10, 1, 10, 10])\n",
      "patches_shape,  torch.Size([10, 25, 100])\n",
      "should be patches shape,  (10, 25, 100)\n",
      "filter_size 5\n",
      "pca fitting ...\n",
      "eigenvectors shape: (8, 25)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 8, 6, 6])"
      ]
     },
     "execution_count": 447,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "I = net._first_stage(imgs=imgs, train=True)\n",
    "I.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCANet second stage...\n",
      "images shape torch.Size([80, 1, 6, 6])\n",
      "patches_shape,  torch.Size([80, 9, 36])\n",
      "should be patches shape,  (80, 9, 36)\n",
      "filter_size 3\n",
      "X_SHAPE  torch.Size([9, 2880])\n",
      "pca fitting ...\n",
      "eigenvectors shape: (8, 9)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([80, 8, 4, 4])"
      ]
     },
     "execution_count": 448,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net._second_stage(I, train=True).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 1, 10, 10])"
      ]
     },
     "execution_count": 449,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N = 80, C = 8, H = 4, W = 4 torch.Size([640, 16])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.6253,  0.6168],\n",
       "        [-0.8436, -0.8203],\n",
       "        [ 1.3822, -0.0567],\n",
       "        ...,\n",
       "        [ 0.3068, -0.6910],\n",
       "        [ 0.6599, -0.2581],\n",
       "        [ 0.9608, -0.0107]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 450,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.forward(imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2, 5, 5])"
      ]
     },
     "execution_count": 439,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S = 2 # channel dim\n",
    "W = 5 # width\n",
    "H = 5 # height\n",
    "batch_size = 2\n",
    "\n",
    "x = torch.randn(batch_size, S, W, H)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-1.7921e-01, -9.1692e-01, -4.6317e-01,  1.6869e+00,  1.4613e+00],\n",
       "          [-5.7550e-01,  5.8393e-01, -1.5300e+00,  9.7792e-01,  8.4493e-01],\n",
       "          [-4.2220e-01,  7.0116e-01, -1.4611e+00,  1.2394e+00, -1.0279e+00],\n",
       "          [ 4.7105e-01, -2.6948e-01,  4.5076e-01, -9.2152e-01,  4.1819e-01],\n",
       "          [-1.2578e+00,  1.6262e-01,  1.7925e-01,  8.2062e-01,  5.4471e-01]],\n",
       "\n",
       "         [[-5.7162e-01,  4.2349e-01,  7.7400e-01, -1.0808e+00, -1.7399e+00],\n",
       "          [-9.5978e-01, -1.2405e+00,  5.1695e-01,  1.4557e-01,  2.6387e-02],\n",
       "          [-3.9332e-01,  4.8027e-02, -1.0529e+00, -6.9203e-01,  1.4546e+00],\n",
       "          [-2.3435e+00,  1.4405e+00,  8.3949e-01,  5.8923e-01, -5.4668e-01],\n",
       "          [-1.4460e+00,  8.4668e-01, -1.4356e-01, -1.1934e-01, -1.6069e-02]]],\n",
       "\n",
       "\n",
       "        [[[ 7.5386e-01, -2.7837e+00,  2.1490e+00, -9.4989e-01, -4.0952e-01],\n",
       "          [ 1.2360e+00, -2.5064e-01,  6.0600e-03,  1.4662e-01, -2.5596e-02],\n",
       "          [ 3.1904e-02, -1.5852e+00, -6.8290e-01,  8.3062e-01, -6.3950e-01],\n",
       "          [-5.3364e-01,  1.7954e+00,  2.9856e-01, -1.5189e+00, -1.3156e+00],\n",
       "          [-1.1296e+00, -8.0584e-01,  3.5646e-01, -1.0657e+00,  1.2815e+00]],\n",
       "\n",
       "         [[-6.9517e-02,  3.4180e-01,  1.0664e+00,  1.0880e+00,  5.0670e-01],\n",
       "          [-2.6048e-01, -2.3234e-01, -1.6361e+00, -1.7934e-03, -4.1433e-01],\n",
       "          [-6.9814e-01, -1.6193e+00,  8.6711e-01,  1.2090e+00,  1.6496e-01],\n",
       "          [-5.7601e-01, -2.1971e+00, -7.2520e-01, -1.7473e-01, -2.8678e-01],\n",
       "          [-5.6339e-01,  2.6871e-01,  1.8341e+00, -1.2189e+00, -1.0842e+00]]]])"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_size = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 18, 25])"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patches = torch.nn.functional.unfold(x, patch_size, padding=patch_size//2)\n",
    "patches.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2, 5, 5])"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 1, 5, 5])"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.view(-1, 1, 5, 5).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "patches = torch.nn.functional.unfold(x.view(-1, 1, 5, 5), patch_size, padding=patch_size//2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2, 3, 3, 3, 3])"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim=1\n",
    "stride=1\n",
    "\n",
    "(x.unfold(dim + 1, patch_size, stride)\n",
    "             .unfold(dim + 2, patch_size, stride)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# извлекает блоки patch_size x patch_size. данный элемент - левый верхний в кернеле"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0445, -0.0971, -0.1128,  0.0563,  0.1979,  0.0251, -0.1666,\n",
       "          -0.1968,  0.2062,  0.3979, -0.0838, -0.4481, -0.6883, -0.3130,\n",
       "           0.0513, -0.0806, -0.0708, -0.0035,  0.4447,  0.4349, -0.0611,\n",
       "          -0.0012,  0.0804,  0.2948,  0.2349]]])"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patches.mean(dim=1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.2136,\n",
       "           0.6934,  0.7696,  1.4638,  0.0000,  0.2672, -0.3461, -2.0440,\n",
       "          -1.5522,  0.0000, -0.5958,  0.4206, -0.4511, -0.7251,  0.0000,\n",
       "           0.4785, -0.9787, -0.7833,  0.2650],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.2136,  0.6934,\n",
       "           0.7696,  1.4638,  2.4094,  0.2672, -0.3461, -2.0440, -1.5522,\n",
       "          -0.5400, -0.5958,  0.4206, -0.4511, -0.7251,  2.5252,  0.4785,\n",
       "          -0.9787, -0.7833,  0.2650,  0.4890],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.6934,  0.7696,\n",
       "           1.4638,  2.4094,  0.0000, -0.3461, -2.0440, -1.5522, -0.5400,\n",
       "           0.0000,  0.4206, -0.4511, -0.7251,  2.5252,  0.0000, -0.9787,\n",
       "          -0.7833,  0.2650,  0.4890,  0.0000],\n",
       "         [ 0.0000, -0.2136,  0.6934,  0.7696,  1.4638,  0.0000,  0.2672,\n",
       "          -0.3461, -2.0440, -1.5522,  0.0000, -0.5958,  0.4206, -0.4511,\n",
       "          -0.7251,  0.0000,  0.4785, -0.9787, -0.7833,  0.2650,  0.0000,\n",
       "           0.0987, -0.1486,  1.3228,  1.0467],\n",
       "         [-0.2136,  0.6934,  0.7696,  1.4638,  2.4094,  0.2672, -0.3461,\n",
       "          -2.0440, -1.5522, -0.5400, -0.5958,  0.4206, -0.4511, -0.7251,\n",
       "           2.5252,  0.4785, -0.9787, -0.7833,  0.2650,  0.4890,  0.0987,\n",
       "          -0.1486,  1.3228,  1.0467,  0.3131],\n",
       "         [ 0.6934,  0.7696,  1.4638,  2.4094,  0.0000, -0.3461, -2.0440,\n",
       "          -1.5522, -0.5400,  0.0000,  0.4206, -0.4511, -0.7251,  2.5252,\n",
       "           0.0000, -0.9787, -0.7833,  0.2650,  0.4890,  0.0000, -0.1486,\n",
       "           1.3228,  1.0467,  0.3131,  0.0000],\n",
       "         [ 0.0000,  0.2672, -0.3461, -2.0440, -1.5522,  0.0000, -0.5958,\n",
       "           0.4206, -0.4511, -0.7251,  0.0000,  0.4785, -0.9787, -0.7833,\n",
       "           0.2650,  0.0000,  0.0987, -0.1486,  1.3228,  1.0467,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.2672, -0.3461, -2.0440, -1.5522, -0.5400, -0.5958,  0.4206,\n",
       "          -0.4511, -0.7251,  2.5252,  0.4785, -0.9787, -0.7833,  0.2650,\n",
       "           0.4890,  0.0987, -0.1486,  1.3228,  1.0467,  0.3131,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [-0.3461, -2.0440, -1.5522, -0.5400,  0.0000,  0.4206, -0.4511,\n",
       "          -0.7251,  2.5252,  0.0000, -0.9787, -0.7833,  0.2650,  0.4890,\n",
       "           0.0000, -0.1486,  1.3228,  1.0467,  0.3131,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000]]])"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 9, 25])"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patches.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 9, 25])"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patches_centerd = patches - patches.mean(dim=1, keepdim=True)\n",
    "patches_centerd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([9, 25])"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patches.view(patch_size**2, batch_size*H**2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0445,  0.0971,  0.1128, -0.0563, -0.1979, -0.0251, -0.0469,  0.8902,\n",
       "         0.5634,  1.0659,  0.0838,  0.7153,  0.3422, -1.7310, -1.6035,  0.0806,\n",
       "        -0.5250,  0.4241, -0.8958, -1.1599,  0.0611,  0.4797, -1.0591, -1.0781,\n",
       "         0.0301])"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patches_centerd[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0445,  0.0971,  0.1128, -0.0563, -0.1979, -0.0251, -0.0469,  0.8902,\n",
       "         0.5634,  1.0659,  0.0838,  0.7153,  0.3422, -1.7310, -1.6035,  0.0806,\n",
       "        -0.5250,  0.4241, -0.8958, -1.1599,  0.0611,  0.4797, -1.0591, -1.0781,\n",
       "         0.0301])"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patches[0, 0] - patches.mean(dim=1, keepdim=True)[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA, IncrementalPCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 18, 25])"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patches_centerd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([9, 100])"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = patches.view(patch_size**2, -1)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipca = IncrementalPCA(n_components=5, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IncrementalPCA(batch_size=10, copy=True, n_components=5, whiten=False)"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ipca.fit(X@X.t())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 9)"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ipca.components_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.20935935, -0.24869507, -0.17104915],\n",
       "       [-0.11947887, -0.17755327,  0.67835001],\n",
       "       [-0.0100398 , -0.35135031,  0.48533975]])"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ipca.components_[0].reshape(patch_size, patch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(copy=True, iterated_power='auto', n_components=5, random_state=None,\n",
       "    svd_solver='auto', tol=0.0, whiten=False)"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = PCA(n_components=5)\n",
    "pca.fit(X@X.t())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.20935935, -0.24869507, -0.17104915],\n",
       "       [-0.11947887, -0.17755327,  0.67835001],\n",
       "       [-0.0100398 , -0.35135031,  0.48533975]])"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.components_[0].reshape(patch_size, patch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "# надо достать и отсортировать с.в. соответствующие отсортированным в порядке убывания с.з.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([129.20387758,  96.00793685,  89.69254703,  75.68971386,\n",
       "        65.87686794])"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ipca.singular_values_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
